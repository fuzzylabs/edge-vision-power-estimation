{"Layers": [{
  "Name": "Reformatting CopyNode for Input Tensor 0 to [CONVOLUTION]-[aten_ops.convolution.default]-[/features_0/0/convolution] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features_0/1/_native_batch_norm_legit_no_training]",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "x",
    "Location": "Device",
    "Dimensions": [1,3,224,224],
    "Format/Datatype": "Row major linear FP16 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to [CONVOLUTION]-[aten_ops.convolution.default]-[/features_0/0/convolution] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features_0/1/_native_batch_norm_legit_no_training]",
    "Location": "Device",
    "Dimensions": [1,3,224,224],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Reformat",
  "Origin": "REFORMAT",
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/features_0/0/convolution] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features_0/1/_native_batch_norm_legit_no_training]",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to [CONVOLUTION]-[aten_ops.convolution.default]-[/features_0/0/convolution] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features_0/1/_native_batch_norm_legit_no_training]",
    "Location": "Device",
    "Dimensions": [1,3,224,224],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 1) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,32,112,112],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [2,2],
  "Dilation": [1,1],
  "OutMaps": 32,
  "Groups": 1,
  "Weights": {"Type": "Half", "Count": 864},
  "Bias": {"Type": "Half", "Count": 32},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x64_stage1_warpsize4x1x1_g1_tensor16x8x16_alignc8",
  "TacticValue": "0x1bf48a356bd0c083",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features_0/1/_native_batch_norm_legit_no_training]_output from DataType.HALF to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features_0/2/_to_copy]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 1) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,32,112,112],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 2) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,32,112,112],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "PWN(/features_0/2/clamp_min_rhs + /features_0/2/clamp_min_broadcast_to_same_shape_rhs_broadcast, PWN(PWN(/features_0/2/clamp_max_rhs + /features_0/2/clamp_max_broadcast_to_same_shape_rhs_broadcast, PWN([SLICE]-[aten_ops.clamp.default]-[/features_0/2/clamp_max_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features_0/2/clamp_max])), PWN([SLICE]-[aten_ops.clamp.default]-[/features_0/2/clamp_min_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features_0/2/clamp_min])))",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 2) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,32,112,112],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "Outputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features_0/2/clamp_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,32,112,112],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 1,
  "InputArgs": ["arg0"],
  "NbOutputVars": 1,
  "OutputVars": ["var1"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 2,
  "Literals": ["6.000000e+00f", "0.000000e+00f"],
  "NbOperations": 2,
  "Operations": ["auto const var0 = pwgen::iMax(arg0, literal1);", "auto const var1 = pwgen::iMin(var0, literal0);"],
  "TacticValue": "0x000000000000000b",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [ELEMENTWISE]-[aten_ops.clamp.default]-[/features_0/2/clamp_min]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features_0/2/_to_copy_1]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features_0/2/clamp_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,32,112,112],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 11) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,32,112,112],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/features/1/conv_0/0/convolution_1] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/1/conv_0/1/_native_batch_norm_legit_no_training_1]",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 11) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,32,112,112],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 13) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,32,112,112],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 32,
  "Groups": 32,
  "Weights": {"Type": "Half", "Count": 288},
  "Bias": {"Type": "Half", "Count": 32},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm50_xmma_convolution_depthwiseHMMA_FP16NHWCx8_TR3_TS3_STRIDEH1_STRIDEW1",
  "TacticValue": "0xf9f6e2e1b0fd88e6",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/1/conv_0/1/_native_batch_norm_legit_no_training_1]_output from DataType.HALF to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/1/conv_0/2/_to_copy_2]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 13) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,32,112,112],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 14) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,32,112,112],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "PWN(/features/1/conv_0/2/clamp_1_min_rhs + /features/1/conv_0/2/clamp_1_min_broadcast_to_same_shape_rhs_broadcast, PWN(PWN(/features/1/conv_0/2/clamp_1_max_rhs + /features/1/conv_0/2/clamp_1_max_broadcast_to_same_shape_rhs_broadcast, PWN([SLICE]-[aten_ops.clamp.default]-[/features/1/conv_0/2/clamp_1_max_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/1/conv_0/2/clamp_1_max])), PWN([SLICE]-[aten_ops.clamp.default]-[/features/1/conv_0/2/clamp_1_min_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/1/conv_0/2/clamp_1_min])))",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 14) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,32,112,112],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "Outputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/1/conv_0/2/clamp_1_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,32,112,112],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 1,
  "InputArgs": ["arg0"],
  "NbOutputVars": 1,
  "OutputVars": ["var1"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 2,
  "Literals": ["6.000000e+00f", "0.000000e+00f"],
  "NbOperations": 2,
  "Operations": ["auto const var0 = pwgen::iMax(arg0, literal1);", "auto const var1 = pwgen::iMin(var0, literal0);"],
  "TacticValue": "0x000000000000000b",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/1/conv_0/2/clamp_1_min]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/1/conv_0/2/_to_copy_3]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/1/conv_0/2/clamp_1_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,32,112,112],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 23) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,32,112,112],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/features/1/conv/1/convolution_2] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/1/conv/2/_native_batch_norm_legit_no_training_2]",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 23) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,32,112,112],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 25) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,16,112,112],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 16,
  "Groups": 1,
  "Weights": {"Type": "Half", "Count": 512},
  "Bias": {"Type": "Half", "Count": 16},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x16x32_stage1_warpsize4x1x1_g1_tensor16x8x16_aligna8_alignc8",
  "TacticValue": "0x96786911782c23e1",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/features/2/conv_0/0/convolution_3] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/2/conv_0/1/_native_batch_norm_legit_no_training_3]",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 25) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,16,112,112],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 27) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,96,112,112],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 96,
  "Groups": 1,
  "Weights": {"Type": "Half", "Count": 1536},
  "Bias": {"Type": "Half", "Count": 96},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x16_aligna8_alignc8",
  "TacticValue": "0xfb0beb2dd64ff6e8",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/2/conv_0/1/_native_batch_norm_legit_no_training_3]_output from DataType.HALF to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/2/conv_0/2/_to_copy_4]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 27) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,96,112,112],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 28) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,96,112,112],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "PWN(/features/2/conv_0/2/clamp_2_min_rhs + /features/2/conv_0/2/clamp_2_min_broadcast_to_same_shape_rhs_broadcast, PWN(PWN(/features/2/conv_0/2/clamp_2_max_rhs + /features/2/conv_0/2/clamp_2_max_broadcast_to_same_shape_rhs_broadcast, PWN([SLICE]-[aten_ops.clamp.default]-[/features/2/conv_0/2/clamp_2_max_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/2/conv_0/2/clamp_2_max])), PWN([SLICE]-[aten_ops.clamp.default]-[/features/2/conv_0/2/clamp_2_min_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/2/conv_0/2/clamp_2_min])))",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 28) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,96,112,112],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/2/conv_0/2/clamp_2_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,96,112,112],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 1,
  "InputArgs": ["arg0"],
  "NbOutputVars": 1,
  "OutputVars": ["var1"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 2,
  "Literals": ["6.000000e+00f", "0.000000e+00f"],
  "NbOperations": 2,
  "Operations": ["auto const var0 = pwgen::iMax(arg0, literal1);", "auto const var1 = pwgen::iMin(var0, literal0);"],
  "TacticValue": "0x0000000000000005",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/2/conv_0/2/clamp_2_min]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/2/conv_0/2/_to_copy_5]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/2/conv_0/2/clamp_2_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,96,112,112],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 37) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,96,112,112],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/features/2/conv_1/0/convolution_4] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/2/conv_1/1/_native_batch_norm_legit_no_training_4]",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 37) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,96,112,112],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 39) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,96,56,56],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [2,2],
  "Dilation": [1,1],
  "OutMaps": 96,
  "Groups": 96,
  "Weights": {"Type": "Half", "Count": 864},
  "Bias": {"Type": "Half", "Count": 96},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm50_xmma_convolution_depthwiseHMMA_FP16NHWCx8_TR3_TS3_STRIDEH2_STRIDEW2",
  "TacticValue": "0x4a741be05296db88",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/2/conv_1/1/_native_batch_norm_legit_no_training_4]_output from DataType.HALF to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/2/conv_1/2/_to_copy_6]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 39) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,96,56,56],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 40) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,96,56,56],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "PWN(/features/2/conv_1/2/clamp_3_min_rhs + /features/2/conv_1/2/clamp_3_min_broadcast_to_same_shape_rhs_broadcast, PWN(PWN(/features/2/conv_1/2/clamp_3_max_rhs + /features/2/conv_1/2/clamp_3_max_broadcast_to_same_shape_rhs_broadcast, PWN([SLICE]-[aten_ops.clamp.default]-[/features/2/conv_1/2/clamp_3_max_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/2/conv_1/2/clamp_3_max])), PWN([SLICE]-[aten_ops.clamp.default]-[/features/2/conv_1/2/clamp_3_min_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/2/conv_1/2/clamp_3_min])))",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 40) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,96,56,56],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "Outputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/2/conv_1/2/clamp_3_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,96,56,56],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 1,
  "InputArgs": ["arg0"],
  "NbOutputVars": 1,
  "OutputVars": ["var1"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 2,
  "Literals": ["6.000000e+00f", "0.000000e+00f"],
  "NbOperations": 2,
  "Operations": ["auto const var0 = pwgen::iMax(arg0, literal1);", "auto const var1 = pwgen::iMin(var0, literal0);"],
  "TacticValue": "0x000000000000001d",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/2/conv_1/2/clamp_3_min]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/2/conv_1/2/_to_copy_7]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/2/conv_1/2/clamp_3_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,96,56,56],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 49) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,96,56,56],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/features/2/conv/2/convolution_5] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/2/conv/3/_native_batch_norm_legit_no_training_5]",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 49) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,96,56,56],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 51) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,24,56,56],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 24,
  "Groups": 1,
  "Weights": {"Type": "Half", "Count": 2304},
  "Bias": {"Type": "Half", "Count": 24},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_simple_t1r1s1",
  "TacticValue": "0x8047bcfcebface4a",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/features/3/conv_0/0/convolution_6] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/3/conv_0/1/_native_batch_norm_legit_no_training_6]",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 51) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,24,56,56],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 53) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,144,56,56],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 144,
  "Groups": 1,
  "Weights": {"Type": "Half", "Count": 3456},
  "Bias": {"Type": "Half", "Count": 144},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x16_aligna8_alignc8",
  "TacticValue": "0xfb0beb2dd64ff6e8",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/3/conv_0/1/_native_batch_norm_legit_no_training_6]_output from DataType.HALF to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/3/conv_0/2/_to_copy_8]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 53) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,144,56,56],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 54) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,144,56,56],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "PWN(/features/3/conv_0/2/clamp_4_min_rhs + /features/3/conv_0/2/clamp_4_min_broadcast_to_same_shape_rhs_broadcast, PWN(PWN(/features/3/conv_0/2/clamp_4_max_rhs + /features/3/conv_0/2/clamp_4_max_broadcast_to_same_shape_rhs_broadcast, PWN([SLICE]-[aten_ops.clamp.default]-[/features/3/conv_0/2/clamp_4_max_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/3/conv_0/2/clamp_4_max])), PWN([SLICE]-[aten_ops.clamp.default]-[/features/3/conv_0/2/clamp_4_min_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/3/conv_0/2/clamp_4_min])))",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 54) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,144,56,56],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "Outputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/3/conv_0/2/clamp_4_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,144,56,56],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 1,
  "InputArgs": ["arg0"],
  "NbOutputVars": 1,
  "OutputVars": ["var1"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 2,
  "Literals": ["6.000000e+00f", "0.000000e+00f"],
  "NbOperations": 2,
  "Operations": ["auto const var0 = pwgen::iMax(arg0, literal1);", "auto const var1 = pwgen::iMin(var0, literal0);"],
  "TacticValue": "0x000000000000000d",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/3/conv_0/2/clamp_4_min]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/3/conv_0/2/_to_copy_9]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/3/conv_0/2/clamp_4_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,144,56,56],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 63) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,144,56,56],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/features/3/conv_1/0/convolution_7] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/3/conv_1/1/_native_batch_norm_legit_no_training_7]",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 63) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,144,56,56],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 65) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,144,56,56],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 144,
  "Groups": 144,
  "Weights": {"Type": "Half", "Count": 1296},
  "Bias": {"Type": "Half", "Count": 144},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm50_xmma_convolution_depthwiseHMMA_FP16NHWCx8_TR3_TS3_STRIDEH1_STRIDEW1",
  "TacticValue": "0xf9f6e2e1b0fd88e6",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/3/conv_1/1/_native_batch_norm_legit_no_training_7]_output from DataType.HALF to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/3/conv_1/2/_to_copy_10]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 65) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,144,56,56],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 66) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,144,56,56],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "PWN(/features/3/conv_1/2/clamp_5_min_rhs + /features/3/conv_1/2/clamp_5_min_broadcast_to_same_shape_rhs_broadcast, PWN(PWN(/features/3/conv_1/2/clamp_5_max_rhs + /features/3/conv_1/2/clamp_5_max_broadcast_to_same_shape_rhs_broadcast, PWN([SLICE]-[aten_ops.clamp.default]-[/features/3/conv_1/2/clamp_5_max_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/3/conv_1/2/clamp_5_max])), PWN([SLICE]-[aten_ops.clamp.default]-[/features/3/conv_1/2/clamp_5_min_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/3/conv_1/2/clamp_5_min])))",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 66) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,144,56,56],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "Outputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/3/conv_1/2/clamp_5_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,144,56,56],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 1,
  "InputArgs": ["arg0"],
  "NbOutputVars": 1,
  "OutputVars": ["var1"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 2,
  "Literals": ["6.000000e+00f", "0.000000e+00f"],
  "NbOperations": 2,
  "Operations": ["auto const var0 = pwgen::iMax(arg0, literal1);", "auto const var1 = pwgen::iMin(var0, literal0);"],
  "TacticValue": "0x000000000000000d",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/3/conv_1/2/clamp_5_min]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/3/conv_1/2/_to_copy_11]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/3/conv_1/2/clamp_5_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,144,56,56],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 75) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,144,56,56],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/features/3/conv/2/convolution_8] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/3/conv/3/_native_batch_norm_legit_no_training_8] + [ELEMENTWISE]-[aten_ops.add.Tensor]-[/features/3/add]",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 75) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,144,56,56],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  },
  {
    "Name": "(Unnamed Layer* 51) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,24,56,56],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.add.Tensor]-[/features/3/add]_output_add.Tensor",
    "Location": "Device",
    "Dimensions": [1,24,56,56],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 24,
  "Groups": 1,
  "Weights": {"Type": "Half", "Count": 3456},
  "Bias": {"Type": "Half", "Count": 24},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 1,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x32_stage4_warpsize4x1x1_g1_tensor16x8x16_simple_t1r1s1",
  "TacticValue": "0x8047bcfcebface4a",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/features/4/conv_0/0/convolution_9] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/4/conv_0/1/_native_batch_norm_legit_no_training_9]",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.add.Tensor]-[/features/3/add]_output_add.Tensor",
    "Location": "Device",
    "Dimensions": [1,24,56,56],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 80) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,144,56,56],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 144,
  "Groups": 1,
  "Weights": {"Type": "Half", "Count": 3456},
  "Bias": {"Type": "Half", "Count": 144},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x16_stage1_warpsize4x1x1_g1_tensor16x8x16_aligna8_alignc8",
  "TacticValue": "0xfb0beb2dd64ff6e8",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/4/conv_0/1/_native_batch_norm_legit_no_training_9]_output from DataType.HALF to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/4/conv_0/2/_to_copy_12]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 80) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,144,56,56],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 81) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,144,56,56],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "PWN(/features/4/conv_0/2/clamp_6_min_rhs + /features/4/conv_0/2/clamp_6_min_broadcast_to_same_shape_rhs_broadcast, PWN(PWN(/features/4/conv_0/2/clamp_6_max_rhs + /features/4/conv_0/2/clamp_6_max_broadcast_to_same_shape_rhs_broadcast, PWN([SLICE]-[aten_ops.clamp.default]-[/features/4/conv_0/2/clamp_6_max_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/4/conv_0/2/clamp_6_max])), PWN([SLICE]-[aten_ops.clamp.default]-[/features/4/conv_0/2/clamp_6_min_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/4/conv_0/2/clamp_6_min])))",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 81) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,144,56,56],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "Outputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/4/conv_0/2/clamp_6_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,144,56,56],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 1,
  "InputArgs": ["arg0"],
  "NbOutputVars": 1,
  "OutputVars": ["var1"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 2,
  "Literals": ["6.000000e+00f", "0.000000e+00f"],
  "NbOperations": 2,
  "Operations": ["auto const var0 = pwgen::iMax(arg0, literal1);", "auto const var1 = pwgen::iMin(var0, literal0);"],
  "TacticValue": "0x000000000000000d",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/4/conv_0/2/clamp_6_min]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/4/conv_0/2/_to_copy_13]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/4/conv_0/2/clamp_6_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,144,56,56],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 90) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,144,56,56],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/features/4/conv_1/0/convolution_10] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/4/conv_1/1/_native_batch_norm_legit_no_training_10]",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 90) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,144,56,56],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 92) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,144,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [2,2],
  "Dilation": [1,1],
  "OutMaps": 144,
  "Groups": 144,
  "Weights": {"Type": "Half", "Count": 1296},
  "Bias": {"Type": "Half", "Count": 144},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm50_xmma_convolution_depthwiseHMMA_FP16NHWCx8_TR3_TS3_STRIDEH2_STRIDEW2",
  "TacticValue": "0x4a741be05296db88",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/4/conv_1/1/_native_batch_norm_legit_no_training_10]_output from DataType.HALF to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/4/conv_1/2/_to_copy_14]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 92) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,144,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 93) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,144,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "PWN(/features/4/conv_1/2/clamp_7_min_rhs + /features/4/conv_1/2/clamp_7_min_broadcast_to_same_shape_rhs_broadcast, PWN(PWN(/features/4/conv_1/2/clamp_7_max_rhs + /features/4/conv_1/2/clamp_7_max_broadcast_to_same_shape_rhs_broadcast, PWN([SLICE]-[aten_ops.clamp.default]-[/features/4/conv_1/2/clamp_7_max_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/4/conv_1/2/clamp_7_max])), PWN([SLICE]-[aten_ops.clamp.default]-[/features/4/conv_1/2/clamp_7_min_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/4/conv_1/2/clamp_7_min])))",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 93) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,144,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/4/conv_1/2/clamp_7_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,144,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 1,
  "InputArgs": ["arg0"],
  "NbOutputVars": 1,
  "OutputVars": ["var1"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 2,
  "Literals": ["6.000000e+00f", "0.000000e+00f"],
  "NbOperations": 2,
  "Operations": ["auto const var0 = pwgen::iMax(arg0, literal1);", "auto const var1 = pwgen::iMin(var0, literal0);"],
  "TacticValue": "0x000000000000001d",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/4/conv_1/2/clamp_7_min]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/4/conv_1/2/_to_copy_15]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/4/conv_1/2/clamp_7_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,144,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 102) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,144,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/features/4/conv/2/convolution_11] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/4/conv/3/_native_batch_norm_legit_no_training_11]",
  "LayerType": "CaskGemmConvolution",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 102) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,144,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 104) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,32,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 32,
  "Groups": 1,
  "Weights": {"Type": "Half", "Count": 4608},
  "Bias": {"Type": "Half", "Count": 32},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize32x32x64_stage6_warpsize2x2x1_tensor16x8x16",
  "TacticValue": "0x00000000000208d9",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/features/5/conv_0/0/convolution_12] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/5/conv_0/1/_native_batch_norm_legit_no_training_12]",
  "LayerType": "CaskGemmConvolution",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 104) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,32,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 106) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,192,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 192,
  "Groups": 1,
  "Weights": {"Type": "Half", "Count": 6144},
  "Bias": {"Type": "Half", "Count": 192},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize64x128x32_stage5_warpsize2x2x1_tensor16x8x16",
  "TacticValue": "0x0000000000020808",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/5/conv_0/1/_native_batch_norm_legit_no_training_12]_output from DataType.HALF to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/5/conv_0/2/_to_copy_16]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 106) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,192,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 107) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,192,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "PWN(/features/5/conv_0/2/clamp_8_min_rhs + /features/5/conv_0/2/clamp_8_min_broadcast_to_same_shape_rhs_broadcast, PWN(PWN(/features/5/conv_0/2/clamp_8_max_rhs + /features/5/conv_0/2/clamp_8_max_broadcast_to_same_shape_rhs_broadcast, PWN([SLICE]-[aten_ops.clamp.default]-[/features/5/conv_0/2/clamp_8_max_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/5/conv_0/2/clamp_8_max])), PWN([SLICE]-[aten_ops.clamp.default]-[/features/5/conv_0/2/clamp_8_min_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/5/conv_0/2/clamp_8_min])))",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 107) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,192,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "Outputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/5/conv_0/2/clamp_8_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,192,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 1,
  "InputArgs": ["arg0"],
  "NbOutputVars": 1,
  "OutputVars": ["var1"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 2,
  "Literals": ["6.000000e+00f", "0.000000e+00f"],
  "NbOperations": 2,
  "Operations": ["auto const var0 = pwgen::iMax(arg0, literal1);", "auto const var1 = pwgen::iMin(var0, literal0);"],
  "TacticValue": "0x000000000000001e",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/5/conv_0/2/clamp_8_min]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/5/conv_0/2/_to_copy_17]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/5/conv_0/2/clamp_8_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,192,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 116) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,192,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/features/5/conv_1/0/convolution_13] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/5/conv_1/1/_native_batch_norm_legit_no_training_13]",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 116) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,192,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 118) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,192,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 192,
  "Groups": 192,
  "Weights": {"Type": "Half", "Count": 1728},
  "Bias": {"Type": "Half", "Count": 192},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm50_xmma_convolution_depthwiseHMMA_FP16NHWCx8_TR3_TS3_STRIDEH1_STRIDEW1",
  "TacticValue": "0xf9f6e2e1b0fd88e6",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/5/conv_1/1/_native_batch_norm_legit_no_training_13]_output from DataType.HALF to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/5/conv_1/2/_to_copy_18]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 118) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,192,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 119) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,192,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "PWN(/features/5/conv_1/2/clamp_9_min_rhs + /features/5/conv_1/2/clamp_9_min_broadcast_to_same_shape_rhs_broadcast, PWN(PWN(/features/5/conv_1/2/clamp_9_max_rhs + /features/5/conv_1/2/clamp_9_max_broadcast_to_same_shape_rhs_broadcast, PWN([SLICE]-[aten_ops.clamp.default]-[/features/5/conv_1/2/clamp_9_max_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/5/conv_1/2/clamp_9_max])), PWN([SLICE]-[aten_ops.clamp.default]-[/features/5/conv_1/2/clamp_9_min_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/5/conv_1/2/clamp_9_min])))",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 119) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,192,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "Outputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/5/conv_1/2/clamp_9_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,192,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 1,
  "InputArgs": ["arg0"],
  "NbOutputVars": 1,
  "OutputVars": ["var1"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 2,
  "Literals": ["6.000000e+00f", "0.000000e+00f"],
  "NbOperations": 2,
  "Operations": ["auto const var0 = pwgen::iMax(arg0, literal1);", "auto const var1 = pwgen::iMin(var0, literal0);"],
  "TacticValue": "0x000000000000001e",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/5/conv_1/2/clamp_9_min]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/5/conv_1/2/_to_copy_19]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/5/conv_1/2/clamp_9_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,192,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 128) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,192,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/features/5/conv/2/convolution_14] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/5/conv/3/_native_batch_norm_legit_no_training_14] + [ELEMENTWISE]-[aten_ops.add.Tensor]-[/features/5/add_1]",
  "LayerType": "CaskGemmConvolution",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 128) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,192,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  },
  {
    "Name": "(Unnamed Layer* 104) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,32,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.add.Tensor]-[/features/5/add_1]_output_add.Tensor",
    "Location": "Device",
    "Dimensions": [1,32,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 32,
  "Groups": 1,
  "Weights": {"Type": "Half", "Count": 6144},
  "Bias": {"Type": "Half", "Count": 32},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 1,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize32x32x64_stage6_warpsize2x2x1_tensor16x8x16",
  "TacticValue": "0x00000000000204c1",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/features/6/conv_0/0/convolution_15] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/6/conv_0/1/_native_batch_norm_legit_no_training_15]",
  "LayerType": "CaskGemmConvolution",
  "Inputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.add.Tensor]-[/features/5/add_1]_output_add.Tensor",
    "Location": "Device",
    "Dimensions": [1,32,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 133) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,192,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 192,
  "Groups": 1,
  "Weights": {"Type": "Half", "Count": 6144},
  "Bias": {"Type": "Half", "Count": 192},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize64x128x32_stage5_warpsize2x2x1_tensor16x8x16",
  "TacticValue": "0x0000000000020808",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/6/conv_0/1/_native_batch_norm_legit_no_training_15]_output from DataType.HALF to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/6/conv_0/2/_to_copy_20]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 133) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,192,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 134) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,192,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "PWN(/features/6/conv_0/2/clamp_10_min_rhs + /features/6/conv_0/2/clamp_10_min_broadcast_to_same_shape_rhs_broadcast, PWN(PWN(/features/6/conv_0/2/clamp_10_max_rhs + /features/6/conv_0/2/clamp_10_max_broadcast_to_same_shape_rhs_broadcast, PWN([SLICE]-[aten_ops.clamp.default]-[/features/6/conv_0/2/clamp_10_max_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/6/conv_0/2/clamp_10_max])), PWN([SLICE]-[aten_ops.clamp.default]-[/features/6/conv_0/2/clamp_10_min_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/6/conv_0/2/clamp_10_min])))",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 134) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,192,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "Outputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/6/conv_0/2/clamp_10_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,192,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 1,
  "InputArgs": ["arg0"],
  "NbOutputVars": 1,
  "OutputVars": ["var1"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 2,
  "Literals": ["6.000000e+00f", "0.000000e+00f"],
  "NbOperations": 2,
  "Operations": ["auto const var0 = pwgen::iMax(arg0, literal1);", "auto const var1 = pwgen::iMin(var0, literal0);"],
  "TacticValue": "0x000000000000001e",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/6/conv_0/2/clamp_10_min]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/6/conv_0/2/_to_copy_21]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/6/conv_0/2/clamp_10_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,192,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 143) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,192,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/features/6/conv_1/0/convolution_16] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/6/conv_1/1/_native_batch_norm_legit_no_training_16]",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 143) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,192,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 145) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,192,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 192,
  "Groups": 192,
  "Weights": {"Type": "Half", "Count": 1728},
  "Bias": {"Type": "Half", "Count": 192},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm50_xmma_convolution_depthwiseHMMA_FP16NHWCx8_TR3_TS3_STRIDEH1_STRIDEW1",
  "TacticValue": "0xf9f6e2e1b0fd88e6",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/6/conv_1/1/_native_batch_norm_legit_no_training_16]_output from DataType.HALF to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/6/conv_1/2/_to_copy_22]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 145) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,192,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 146) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,192,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "PWN(/features/6/conv_1/2/clamp_11_min_rhs + /features/6/conv_1/2/clamp_11_min_broadcast_to_same_shape_rhs_broadcast, PWN(PWN(/features/6/conv_1/2/clamp_11_max_rhs + /features/6/conv_1/2/clamp_11_max_broadcast_to_same_shape_rhs_broadcast, PWN([SLICE]-[aten_ops.clamp.default]-[/features/6/conv_1/2/clamp_11_max_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/6/conv_1/2/clamp_11_max])), PWN([SLICE]-[aten_ops.clamp.default]-[/features/6/conv_1/2/clamp_11_min_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/6/conv_1/2/clamp_11_min])))",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 146) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,192,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "Outputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/6/conv_1/2/clamp_11_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,192,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 1,
  "InputArgs": ["arg0"],
  "NbOutputVars": 1,
  "OutputVars": ["var1"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 2,
  "Literals": ["6.000000e+00f", "0.000000e+00f"],
  "NbOperations": 2,
  "Operations": ["auto const var0 = pwgen::iMax(arg0, literal1);", "auto const var1 = pwgen::iMin(var0, literal0);"],
  "TacticValue": "0x000000000000001e",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/6/conv_1/2/clamp_11_min]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/6/conv_1/2/_to_copy_23]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/6/conv_1/2/clamp_11_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,192,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 155) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,192,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/features/6/conv/2/convolution_17] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/6/conv/3/_native_batch_norm_legit_no_training_17] + [ELEMENTWISE]-[aten_ops.add.Tensor]-[/features/6/add_2]",
  "LayerType": "CaskGemmConvolution",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 155) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,192,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  },
  {
    "Name": "[ELEMENTWISE]-[aten_ops.add.Tensor]-[/features/5/add_1]_output_add.Tensor",
    "Location": "Device",
    "Dimensions": [1,32,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.add.Tensor]-[/features/6/add_2]_output_add.Tensor",
    "Location": "Device",
    "Dimensions": [1,32,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 32,
  "Groups": 1,
  "Weights": {"Type": "Half", "Count": 6144},
  "Bias": {"Type": "Half", "Count": 32},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 1,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize32x32x64_stage6_warpsize2x2x1_tensor16x8x16",
  "TacticValue": "0x00000000000204c1",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/features/7/conv_0/0/convolution_18] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/7/conv_0/1/_native_batch_norm_legit_no_training_18]",
  "LayerType": "CaskGemmConvolution",
  "Inputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.add.Tensor]-[/features/6/add_2]_output_add.Tensor",
    "Location": "Device",
    "Dimensions": [1,32,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 160) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,192,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 192,
  "Groups": 1,
  "Weights": {"Type": "Half", "Count": 6144},
  "Bias": {"Type": "Half", "Count": 192},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize64x128x32_stage5_warpsize2x2x1_tensor16x8x16",
  "TacticValue": "0x0000000000020808",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/7/conv_0/1/_native_batch_norm_legit_no_training_18]_output from DataType.HALF to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/7/conv_0/2/_to_copy_24]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 160) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,192,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 161) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,192,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "PWN(/features/7/conv_0/2/clamp_12_min_rhs + /features/7/conv_0/2/clamp_12_min_broadcast_to_same_shape_rhs_broadcast, PWN(PWN(/features/7/conv_0/2/clamp_12_max_rhs + /features/7/conv_0/2/clamp_12_max_broadcast_to_same_shape_rhs_broadcast, PWN([SLICE]-[aten_ops.clamp.default]-[/features/7/conv_0/2/clamp_12_max_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/7/conv_0/2/clamp_12_max])), PWN([SLICE]-[aten_ops.clamp.default]-[/features/7/conv_0/2/clamp_12_min_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/7/conv_0/2/clamp_12_min])))",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 161) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,192,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "Outputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/7/conv_0/2/clamp_12_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,192,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 1,
  "InputArgs": ["arg0"],
  "NbOutputVars": 1,
  "OutputVars": ["var1"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 2,
  "Literals": ["6.000000e+00f", "0.000000e+00f"],
  "NbOperations": 2,
  "Operations": ["auto const var0 = pwgen::iMax(arg0, literal1);", "auto const var1 = pwgen::iMin(var0, literal0);"],
  "TacticValue": "0x000000000000001e",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/7/conv_0/2/clamp_12_min]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/7/conv_0/2/_to_copy_25]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/7/conv_0/2/clamp_12_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,192,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 170) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,192,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/features/7/conv_1/0/convolution_19] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/7/conv_1/1/_native_batch_norm_legit_no_training_19]",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 170) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,192,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 172) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,192,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [2,2],
  "Dilation": [1,1],
  "OutMaps": 192,
  "Groups": 192,
  "Weights": {"Type": "Half", "Count": 1728},
  "Bias": {"Type": "Half", "Count": 192},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm50_xmma_convolution_depthwiseHMMA_FP16NHWCx8_TR3_TS3_STRIDEH2_STRIDEW2",
  "TacticValue": "0x4a741be05296db88",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/7/conv_1/1/_native_batch_norm_legit_no_training_19]_output from DataType.HALF to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/7/conv_1/2/_to_copy_26]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 172) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,192,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 173) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,192,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "PWN(/features/7/conv_1/2/clamp_13_min_rhs + /features/7/conv_1/2/clamp_13_min_broadcast_to_same_shape_rhs_broadcast, PWN(PWN(/features/7/conv_1/2/clamp_13_max_rhs + /features/7/conv_1/2/clamp_13_max_broadcast_to_same_shape_rhs_broadcast, PWN([SLICE]-[aten_ops.clamp.default]-[/features/7/conv_1/2/clamp_13_max_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/7/conv_1/2/clamp_13_max])), PWN([SLICE]-[aten_ops.clamp.default]-[/features/7/conv_1/2/clamp_13_min_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/7/conv_1/2/clamp_13_min])))",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 173) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,192,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "Outputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/7/conv_1/2/clamp_13_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,192,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 1,
  "InputArgs": ["arg0"],
  "NbOutputVars": 1,
  "OutputVars": ["var1"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 2,
  "Literals": ["6.000000e+00f", "0.000000e+00f"],
  "NbOperations": 2,
  "Operations": ["auto const var0 = pwgen::iMax(arg0, literal1);", "auto const var1 = pwgen::iMin(var0, literal0);"],
  "TacticValue": "0x0000000000000014",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/7/conv_1/2/clamp_13_min]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/7/conv_1/2/_to_copy_27]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/7/conv_1/2/clamp_13_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,192,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 182) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,192,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/features/7/conv/2/convolution_20] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/7/conv/3/_native_batch_norm_legit_no_training_20]",
  "LayerType": "CaskGemmConvolution",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 182) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,192,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 184) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,64,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Half", "Count": 12288},
  "Bias": {"Type": "Half", "Count": 64},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize32x32x64_stage6_warpsize2x2x1_tensor16x8x16",
  "TacticValue": "0x00000000000208d9",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/features/8/conv_0/0/convolution_21] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/8/conv_0/1/_native_batch_norm_legit_no_training_21]",
  "LayerType": "CaskGemmConvolution",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 184) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,64,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 186) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 384,
  "Groups": 1,
  "Weights": {"Type": "Half", "Count": 24576},
  "Bias": {"Type": "Half", "Count": 384},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize64x64x64_stage4_warpsize2x2x1_tensor16x8x16",
  "TacticValue": "0x00000000000205ec",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/8/conv_0/1/_native_batch_norm_legit_no_training_21]_output from DataType.HALF to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/8/conv_0/2/_to_copy_28]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 186) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 187) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "PWN(/features/8/conv_0/2/clamp_14_min_rhs + /features/8/conv_0/2/clamp_14_min_broadcast_to_same_shape_rhs_broadcast, PWN(PWN(/features/8/conv_0/2/clamp_14_max_rhs + /features/8/conv_0/2/clamp_14_max_broadcast_to_same_shape_rhs_broadcast, PWN([SLICE]-[aten_ops.clamp.default]-[/features/8/conv_0/2/clamp_14_max_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/8/conv_0/2/clamp_14_max])), PWN([SLICE]-[aten_ops.clamp.default]-[/features/8/conv_0/2/clamp_14_min_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/8/conv_0/2/clamp_14_min])))",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 187) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/8/conv_0/2/clamp_14_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 1,
  "InputArgs": ["arg0"],
  "NbOutputVars": 1,
  "OutputVars": ["var1"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 2,
  "Literals": ["6.000000e+00f", "0.000000e+00f"],
  "NbOperations": 2,
  "Operations": ["auto const var0 = pwgen::iMax(arg0, literal1);", "auto const var1 = pwgen::iMin(var0, literal0);"],
  "TacticValue": "0x000000000000001d",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/8/conv_0/2/clamp_14_min]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/8/conv_0/2/_to_copy_29]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/8/conv_0/2/clamp_14_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 196) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/features/8/conv_1/0/convolution_22] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/8/conv_1/1/_native_batch_norm_legit_no_training_22]",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 196) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 198) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 384,
  "Groups": 384,
  "Weights": {"Type": "Half", "Count": 3456},
  "Bias": {"Type": "Half", "Count": 384},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm50_xmma_convolution_depthwiseHMMA_FP16NHWCx8_TR3_TS3_STRIDEH1_STRIDEW1",
  "TacticValue": "0xf9f6e2e1b0fd88e6",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/8/conv_1/1/_native_batch_norm_legit_no_training_22]_output from DataType.HALF to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/8/conv_1/2/_to_copy_30]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 198) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 199) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "PWN(/features/8/conv_1/2/clamp_15_min_rhs + /features/8/conv_1/2/clamp_15_min_broadcast_to_same_shape_rhs_broadcast, PWN(PWN(/features/8/conv_1/2/clamp_15_max_rhs + /features/8/conv_1/2/clamp_15_max_broadcast_to_same_shape_rhs_broadcast, PWN([SLICE]-[aten_ops.clamp.default]-[/features/8/conv_1/2/clamp_15_max_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/8/conv_1/2/clamp_15_max])), PWN([SLICE]-[aten_ops.clamp.default]-[/features/8/conv_1/2/clamp_15_min_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/8/conv_1/2/clamp_15_min])))",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 199) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/8/conv_1/2/clamp_15_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 1,
  "InputArgs": ["arg0"],
  "NbOutputVars": 1,
  "OutputVars": ["var1"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 2,
  "Literals": ["6.000000e+00f", "0.000000e+00f"],
  "NbOperations": 2,
  "Operations": ["auto const var0 = pwgen::iMax(arg0, literal1);", "auto const var1 = pwgen::iMin(var0, literal0);"],
  "TacticValue": "0x000000000000001d",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/8/conv_1/2/clamp_15_min]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/8/conv_1/2/_to_copy_31]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/8/conv_1/2/clamp_15_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 208) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/features/8/conv/2/convolution_23] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/8/conv/3/_native_batch_norm_legit_no_training_23] + [ELEMENTWISE]-[aten_ops.add.Tensor]-[/features/8/add_3]",
  "LayerType": "CaskGemmConvolution",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 208) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  },
  {
    "Name": "(Unnamed Layer* 184) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,64,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.add.Tensor]-[/features/8/add_3]_output_add.Tensor",
    "Location": "Device",
    "Dimensions": [1,64,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Half", "Count": 24576},
  "Bias": {"Type": "Half", "Count": 64},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 1,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize32x32x64_stage6_warpsize2x2x1_tensor16x8x16",
  "TacticValue": "0x00000000000208d9",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/features/9/conv_0/0/convolution_24] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/9/conv_0/1/_native_batch_norm_legit_no_training_24]",
  "LayerType": "CaskGemmConvolution",
  "Inputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.add.Tensor]-[/features/8/add_3]_output_add.Tensor",
    "Location": "Device",
    "Dimensions": [1,64,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 213) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 384,
  "Groups": 1,
  "Weights": {"Type": "Half", "Count": 24576},
  "Bias": {"Type": "Half", "Count": 384},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize64x64x64_stage4_warpsize2x2x1_tensor16x8x16",
  "TacticValue": "0x00000000000205ec",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/9/conv_0/1/_native_batch_norm_legit_no_training_24]_output from DataType.HALF to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/9/conv_0/2/_to_copy_32]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 213) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 214) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "PWN(/features/9/conv_0/2/clamp_16_min_rhs + /features/9/conv_0/2/clamp_16_min_broadcast_to_same_shape_rhs_broadcast, PWN(PWN(/features/9/conv_0/2/clamp_16_max_rhs + /features/9/conv_0/2/clamp_16_max_broadcast_to_same_shape_rhs_broadcast, PWN([SLICE]-[aten_ops.clamp.default]-[/features/9/conv_0/2/clamp_16_max_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/9/conv_0/2/clamp_16_max])), PWN([SLICE]-[aten_ops.clamp.default]-[/features/9/conv_0/2/clamp_16_min_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/9/conv_0/2/clamp_16_min])))",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 214) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/9/conv_0/2/clamp_16_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 1,
  "InputArgs": ["arg0"],
  "NbOutputVars": 1,
  "OutputVars": ["var1"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 2,
  "Literals": ["6.000000e+00f", "0.000000e+00f"],
  "NbOperations": 2,
  "Operations": ["auto const var0 = pwgen::iMax(arg0, literal1);", "auto const var1 = pwgen::iMin(var0, literal0);"],
  "TacticValue": "0x000000000000001d",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/9/conv_0/2/clamp_16_min]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/9/conv_0/2/_to_copy_33]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/9/conv_0/2/clamp_16_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 223) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/features/9/conv_1/0/convolution_25] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/9/conv_1/1/_native_batch_norm_legit_no_training_25]",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 223) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 225) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 384,
  "Groups": 384,
  "Weights": {"Type": "Half", "Count": 3456},
  "Bias": {"Type": "Half", "Count": 384},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm50_xmma_convolution_depthwiseHMMA_FP16NHWCx8_TR3_TS3_STRIDEH1_STRIDEW1",
  "TacticValue": "0xf9f6e2e1b0fd88e6",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/9/conv_1/1/_native_batch_norm_legit_no_training_25]_output from DataType.HALF to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/9/conv_1/2/_to_copy_34]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 225) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 226) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "PWN(/features/9/conv_1/2/clamp_17_min_rhs + /features/9/conv_1/2/clamp_17_min_broadcast_to_same_shape_rhs_broadcast, PWN(PWN(/features/9/conv_1/2/clamp_17_max_rhs + /features/9/conv_1/2/clamp_17_max_broadcast_to_same_shape_rhs_broadcast, PWN([SLICE]-[aten_ops.clamp.default]-[/features/9/conv_1/2/clamp_17_max_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/9/conv_1/2/clamp_17_max])), PWN([SLICE]-[aten_ops.clamp.default]-[/features/9/conv_1/2/clamp_17_min_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/9/conv_1/2/clamp_17_min])))",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 226) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/9/conv_1/2/clamp_17_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 1,
  "InputArgs": ["arg0"],
  "NbOutputVars": 1,
  "OutputVars": ["var1"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 2,
  "Literals": ["6.000000e+00f", "0.000000e+00f"],
  "NbOperations": 2,
  "Operations": ["auto const var0 = pwgen::iMax(arg0, literal1);", "auto const var1 = pwgen::iMin(var0, literal0);"],
  "TacticValue": "0x000000000000001d",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/9/conv_1/2/clamp_17_min]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/9/conv_1/2/_to_copy_35]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/9/conv_1/2/clamp_17_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 235) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/features/9/conv/2/convolution_26] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/9/conv/3/_native_batch_norm_legit_no_training_26] + [ELEMENTWISE]-[aten_ops.add.Tensor]-[/features/9/add_4]",
  "LayerType": "CaskGemmConvolution",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 235) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  },
  {
    "Name": "[ELEMENTWISE]-[aten_ops.add.Tensor]-[/features/8/add_3]_output_add.Tensor",
    "Location": "Device",
    "Dimensions": [1,64,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.add.Tensor]-[/features/9/add_4]_output_add.Tensor",
    "Location": "Device",
    "Dimensions": [1,64,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Half", "Count": 24576},
  "Bias": {"Type": "Half", "Count": 64},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 1,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize32x32x64_stage6_warpsize2x2x1_tensor16x8x16",
  "TacticValue": "0x00000000000208d9",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/features/10/conv_0/0/convolution_27] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/10/conv_0/1/_native_batch_norm_legit_no_training_27]",
  "LayerType": "CaskGemmConvolution",
  "Inputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.add.Tensor]-[/features/9/add_4]_output_add.Tensor",
    "Location": "Device",
    "Dimensions": [1,64,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 240) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 384,
  "Groups": 1,
  "Weights": {"Type": "Half", "Count": 24576},
  "Bias": {"Type": "Half", "Count": 384},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize64x64x64_stage4_warpsize2x2x1_tensor16x8x16",
  "TacticValue": "0x00000000000205ec",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/10/conv_0/1/_native_batch_norm_legit_no_training_27]_output from DataType.HALF to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/10/conv_0/2/_to_copy_36]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 240) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 241) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "PWN(/features/10/conv_0/2/clamp_18_min_rhs + /features/10/conv_0/2/clamp_18_min_broadcast_to_same_shape_rhs_broadcast, PWN(PWN(/features/10/conv_0/2/clamp_18_max_rhs + /features/10/conv_0/2/clamp_18_max_broadcast_to_same_shape_rhs_broadcast, PWN([SLICE]-[aten_ops.clamp.default]-[/features/10/conv_0/2/clamp_18_max_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/10/conv_0/2/clamp_18_max])), PWN([SLICE]-[aten_ops.clamp.default]-[/features/10/conv_0/2/clamp_18_min_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/10/conv_0/2/clamp_18_min])))",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 241) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/10/conv_0/2/clamp_18_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 1,
  "InputArgs": ["arg0"],
  "NbOutputVars": 1,
  "OutputVars": ["var1"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 2,
  "Literals": ["6.000000e+00f", "0.000000e+00f"],
  "NbOperations": 2,
  "Operations": ["auto const var0 = pwgen::iMax(arg0, literal1);", "auto const var1 = pwgen::iMin(var0, literal0);"],
  "TacticValue": "0x000000000000001d",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/10/conv_0/2/clamp_18_min]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/10/conv_0/2/_to_copy_37]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/10/conv_0/2/clamp_18_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 250) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/features/10/conv_1/0/convolution_28] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/10/conv_1/1/_native_batch_norm_legit_no_training_28]",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 250) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 252) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 384,
  "Groups": 384,
  "Weights": {"Type": "Half", "Count": 3456},
  "Bias": {"Type": "Half", "Count": 384},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm50_xmma_convolution_depthwiseHMMA_FP16NHWCx8_TR3_TS3_STRIDEH1_STRIDEW1",
  "TacticValue": "0xf9f6e2e1b0fd88e6",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/10/conv_1/1/_native_batch_norm_legit_no_training_28]_output from DataType.HALF to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/10/conv_1/2/_to_copy_38]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 252) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 253) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "PWN(/features/10/conv_1/2/clamp_19_min_rhs + /features/10/conv_1/2/clamp_19_min_broadcast_to_same_shape_rhs_broadcast, PWN(PWN(/features/10/conv_1/2/clamp_19_max_rhs + /features/10/conv_1/2/clamp_19_max_broadcast_to_same_shape_rhs_broadcast, PWN([SLICE]-[aten_ops.clamp.default]-[/features/10/conv_1/2/clamp_19_max_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/10/conv_1/2/clamp_19_max])), PWN([SLICE]-[aten_ops.clamp.default]-[/features/10/conv_1/2/clamp_19_min_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/10/conv_1/2/clamp_19_min])))",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 253) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/10/conv_1/2/clamp_19_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 1,
  "InputArgs": ["arg0"],
  "NbOutputVars": 1,
  "OutputVars": ["var1"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 2,
  "Literals": ["6.000000e+00f", "0.000000e+00f"],
  "NbOperations": 2,
  "Operations": ["auto const var0 = pwgen::iMax(arg0, literal1);", "auto const var1 = pwgen::iMin(var0, literal0);"],
  "TacticValue": "0x000000000000001d",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/10/conv_1/2/clamp_19_min]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/10/conv_1/2/_to_copy_39]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/10/conv_1/2/clamp_19_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 262) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/features/10/conv/2/convolution_29] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/10/conv/3/_native_batch_norm_legit_no_training_29] + [ELEMENTWISE]-[aten_ops.add.Tensor]-[/features/10/add_5]",
  "LayerType": "CaskGemmConvolution",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 262) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  },
  {
    "Name": "[ELEMENTWISE]-[aten_ops.add.Tensor]-[/features/9/add_4]_output_add.Tensor",
    "Location": "Device",
    "Dimensions": [1,64,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.add.Tensor]-[/features/10/add_5]_output_add.Tensor",
    "Location": "Device",
    "Dimensions": [1,64,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Half", "Count": 24576},
  "Bias": {"Type": "Half", "Count": 64},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 1,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize32x32x64_stage6_warpsize2x2x1_tensor16x8x16",
  "TacticValue": "0x00000000000208d9",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/features/11/conv_0/0/convolution_30] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/11/conv_0/1/_native_batch_norm_legit_no_training_30]",
  "LayerType": "CaskGemmConvolution",
  "Inputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.add.Tensor]-[/features/10/add_5]_output_add.Tensor",
    "Location": "Device",
    "Dimensions": [1,64,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 267) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 384,
  "Groups": 1,
  "Weights": {"Type": "Half", "Count": 24576},
  "Bias": {"Type": "Half", "Count": 384},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize64x64x64_stage4_warpsize2x2x1_tensor16x8x16",
  "TacticValue": "0x00000000000205ec",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/11/conv_0/1/_native_batch_norm_legit_no_training_30]_output from DataType.HALF to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/11/conv_0/2/_to_copy_40]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 267) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 268) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "PWN(/features/11/conv_0/2/clamp_20_min_rhs + /features/11/conv_0/2/clamp_20_min_broadcast_to_same_shape_rhs_broadcast, PWN(PWN(/features/11/conv_0/2/clamp_20_max_rhs + /features/11/conv_0/2/clamp_20_max_broadcast_to_same_shape_rhs_broadcast, PWN([SLICE]-[aten_ops.clamp.default]-[/features/11/conv_0/2/clamp_20_max_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/11/conv_0/2/clamp_20_max])), PWN([SLICE]-[aten_ops.clamp.default]-[/features/11/conv_0/2/clamp_20_min_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/11/conv_0/2/clamp_20_min])))",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 268) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/11/conv_0/2/clamp_20_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 1,
  "InputArgs": ["arg0"],
  "NbOutputVars": 1,
  "OutputVars": ["var1"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 2,
  "Literals": ["6.000000e+00f", "0.000000e+00f"],
  "NbOperations": 2,
  "Operations": ["auto const var0 = pwgen::iMax(arg0, literal1);", "auto const var1 = pwgen::iMin(var0, literal0);"],
  "TacticValue": "0x000000000000001d",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/11/conv_0/2/clamp_20_min]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/11/conv_0/2/_to_copy_41]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/11/conv_0/2/clamp_20_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 277) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/features/11/conv_1/0/convolution_31] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/11/conv_1/1/_native_batch_norm_legit_no_training_31]",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 277) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 279) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 384,
  "Groups": 384,
  "Weights": {"Type": "Half", "Count": 3456},
  "Bias": {"Type": "Half", "Count": 384},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm50_xmma_convolution_depthwiseHMMA_FP16NHWCx8_TR3_TS3_STRIDEH1_STRIDEW1",
  "TacticValue": "0xf9f6e2e1b0fd88e6",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/11/conv_1/1/_native_batch_norm_legit_no_training_31]_output from DataType.HALF to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/11/conv_1/2/_to_copy_42]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 279) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 280) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "PWN(/features/11/conv_1/2/clamp_21_min_rhs + /features/11/conv_1/2/clamp_21_min_broadcast_to_same_shape_rhs_broadcast, PWN(PWN(/features/11/conv_1/2/clamp_21_max_rhs + /features/11/conv_1/2/clamp_21_max_broadcast_to_same_shape_rhs_broadcast, PWN([SLICE]-[aten_ops.clamp.default]-[/features/11/conv_1/2/clamp_21_max_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/11/conv_1/2/clamp_21_max])), PWN([SLICE]-[aten_ops.clamp.default]-[/features/11/conv_1/2/clamp_21_min_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/11/conv_1/2/clamp_21_min])))",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 280) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/11/conv_1/2/clamp_21_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 1,
  "InputArgs": ["arg0"],
  "NbOutputVars": 1,
  "OutputVars": ["var1"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 2,
  "Literals": ["6.000000e+00f", "0.000000e+00f"],
  "NbOperations": 2,
  "Operations": ["auto const var0 = pwgen::iMax(arg0, literal1);", "auto const var1 = pwgen::iMin(var0, literal0);"],
  "TacticValue": "0x000000000000001d",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/11/conv_1/2/clamp_21_min]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/11/conv_1/2/_to_copy_43]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/11/conv_1/2/clamp_21_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 289) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/features/11/conv/2/convolution_32] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/11/conv/3/_native_batch_norm_legit_no_training_32]",
  "LayerType": "CaskGemmConvolution",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 289) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,384,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 291) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,96,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 96,
  "Groups": 1,
  "Weights": {"Type": "Half", "Count": 36864},
  "Bias": {"Type": "Half", "Count": 96},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize32x32x64_stage6_warpsize2x2x1_tensor16x8x16",
  "TacticValue": "0x00000000000204c1",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/features/12/conv_0/0/convolution_33] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/12/conv_0/1/_native_batch_norm_legit_no_training_33]",
  "LayerType": "CaskGemmConvolution",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 291) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,96,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 293) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,576,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 576,
  "Groups": 1,
  "Weights": {"Type": "Half", "Count": 55296},
  "Bias": {"Type": "Half", "Count": 576},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize64x128x32_stage5_warpsize2x2x1_tensor16x8x16",
  "TacticValue": "0x0000000000020808",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/12/conv_0/1/_native_batch_norm_legit_no_training_33]_output from DataType.HALF to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/12/conv_0/2/_to_copy_44]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 293) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,576,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 294) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,576,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "PWN(/features/12/conv_0/2/clamp_22_min_rhs + /features/12/conv_0/2/clamp_22_min_broadcast_to_same_shape_rhs_broadcast, PWN(PWN(/features/12/conv_0/2/clamp_22_max_rhs + /features/12/conv_0/2/clamp_22_max_broadcast_to_same_shape_rhs_broadcast, PWN([SLICE]-[aten_ops.clamp.default]-[/features/12/conv_0/2/clamp_22_max_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/12/conv_0/2/clamp_22_max])), PWN([SLICE]-[aten_ops.clamp.default]-[/features/12/conv_0/2/clamp_22_min_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/12/conv_0/2/clamp_22_min])))",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 294) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,576,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/12/conv_0/2/clamp_22_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,576,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 1,
  "InputArgs": ["arg0"],
  "NbOutputVars": 1,
  "OutputVars": ["var1"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 2,
  "Literals": ["6.000000e+00f", "0.000000e+00f"],
  "NbOperations": 2,
  "Operations": ["auto const var0 = pwgen::iMax(arg0, literal1);", "auto const var1 = pwgen::iMin(var0, literal0);"],
  "TacticValue": "0x000000000000001c",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/12/conv_0/2/clamp_22_min]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/12/conv_0/2/_to_copy_45]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/12/conv_0/2/clamp_22_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,576,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 303) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,576,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/features/12/conv_1/0/convolution_34] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/12/conv_1/1/_native_batch_norm_legit_no_training_34]",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 303) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,576,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 305) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,576,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 576,
  "Groups": 576,
  "Weights": {"Type": "Half", "Count": 5184},
  "Bias": {"Type": "Half", "Count": 576},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm50_xmma_convolution_depthwiseHMMA_FP16NHWCx8_TR3_TS3_STRIDEH1_STRIDEW1",
  "TacticValue": "0xf9f6e2e1b0fd88e6",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/12/conv_1/1/_native_batch_norm_legit_no_training_34]_output from DataType.HALF to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/12/conv_1/2/_to_copy_46]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 305) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,576,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 306) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,576,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "PWN(/features/12/conv_1/2/clamp_23_min_rhs + /features/12/conv_1/2/clamp_23_min_broadcast_to_same_shape_rhs_broadcast, PWN(PWN(/features/12/conv_1/2/clamp_23_max_rhs + /features/12/conv_1/2/clamp_23_max_broadcast_to_same_shape_rhs_broadcast, PWN([SLICE]-[aten_ops.clamp.default]-[/features/12/conv_1/2/clamp_23_max_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/12/conv_1/2/clamp_23_max])), PWN([SLICE]-[aten_ops.clamp.default]-[/features/12/conv_1/2/clamp_23_min_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/12/conv_1/2/clamp_23_min])))",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 306) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,576,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/12/conv_1/2/clamp_23_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,576,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 1,
  "InputArgs": ["arg0"],
  "NbOutputVars": 1,
  "OutputVars": ["var1"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 2,
  "Literals": ["6.000000e+00f", "0.000000e+00f"],
  "NbOperations": 2,
  "Operations": ["auto const var0 = pwgen::iMax(arg0, literal1);", "auto const var1 = pwgen::iMin(var0, literal0);"],
  "TacticValue": "0x000000000000001c",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/12/conv_1/2/clamp_23_min]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/12/conv_1/2/_to_copy_47]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/12/conv_1/2/clamp_23_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,576,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 315) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,576,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/features/12/conv/2/convolution_35] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/12/conv/3/_native_batch_norm_legit_no_training_35] + [ELEMENTWISE]-[aten_ops.add.Tensor]-[/features/12/add_6]",
  "LayerType": "CaskGemmConvolution",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 315) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,576,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  },
  {
    "Name": "(Unnamed Layer* 291) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,96,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.add.Tensor]-[/features/12/add_6]_output_add.Tensor",
    "Location": "Device",
    "Dimensions": [1,96,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 96,
  "Groups": 1,
  "Weights": {"Type": "Half", "Count": 55296},
  "Bias": {"Type": "Half", "Count": 96},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 1,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize32x32x64_stage6_warpsize2x2x1_tensor16x8x16",
  "TacticValue": "0x00000000000208d9",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/features/13/conv_0/0/convolution_36] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/13/conv_0/1/_native_batch_norm_legit_no_training_36]",
  "LayerType": "CaskGemmConvolution",
  "Inputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.add.Tensor]-[/features/12/add_6]_output_add.Tensor",
    "Location": "Device",
    "Dimensions": [1,96,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 320) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,576,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 576,
  "Groups": 1,
  "Weights": {"Type": "Half", "Count": 55296},
  "Bias": {"Type": "Half", "Count": 576},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize64x128x32_stage5_warpsize2x2x1_tensor16x8x16",
  "TacticValue": "0x0000000000020808",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/13/conv_0/1/_native_batch_norm_legit_no_training_36]_output from DataType.HALF to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/13/conv_0/2/_to_copy_48]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 320) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,576,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 321) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,576,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "PWN(/features/13/conv_0/2/clamp_24_min_rhs + /features/13/conv_0/2/clamp_24_min_broadcast_to_same_shape_rhs_broadcast, PWN(PWN(/features/13/conv_0/2/clamp_24_max_rhs + /features/13/conv_0/2/clamp_24_max_broadcast_to_same_shape_rhs_broadcast, PWN([SLICE]-[aten_ops.clamp.default]-[/features/13/conv_0/2/clamp_24_max_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/13/conv_0/2/clamp_24_max])), PWN([SLICE]-[aten_ops.clamp.default]-[/features/13/conv_0/2/clamp_24_min_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/13/conv_0/2/clamp_24_min])))",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 321) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,576,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/13/conv_0/2/clamp_24_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,576,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 1,
  "InputArgs": ["arg0"],
  "NbOutputVars": 1,
  "OutputVars": ["var1"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 2,
  "Literals": ["6.000000e+00f", "0.000000e+00f"],
  "NbOperations": 2,
  "Operations": ["auto const var0 = pwgen::iMax(arg0, literal1);", "auto const var1 = pwgen::iMin(var0, literal0);"],
  "TacticValue": "0x000000000000001c",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/13/conv_0/2/clamp_24_min]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/13/conv_0/2/_to_copy_49]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/13/conv_0/2/clamp_24_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,576,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 330) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,576,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/features/13/conv_1/0/convolution_37] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/13/conv_1/1/_native_batch_norm_legit_no_training_37]",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 330) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,576,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 332) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,576,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 576,
  "Groups": 576,
  "Weights": {"Type": "Half", "Count": 5184},
  "Bias": {"Type": "Half", "Count": 576},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm50_xmma_convolution_depthwiseHMMA_FP16NHWCx8_TR3_TS3_STRIDEH1_STRIDEW1",
  "TacticValue": "0xf9f6e2e1b0fd88e6",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/13/conv_1/1/_native_batch_norm_legit_no_training_37]_output from DataType.HALF to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/13/conv_1/2/_to_copy_50]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 332) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,576,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 333) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,576,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "PWN(/features/13/conv_1/2/clamp_25_min_rhs + /features/13/conv_1/2/clamp_25_min_broadcast_to_same_shape_rhs_broadcast, PWN(PWN(/features/13/conv_1/2/clamp_25_max_rhs + /features/13/conv_1/2/clamp_25_max_broadcast_to_same_shape_rhs_broadcast, PWN([SLICE]-[aten_ops.clamp.default]-[/features/13/conv_1/2/clamp_25_max_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/13/conv_1/2/clamp_25_max])), PWN([SLICE]-[aten_ops.clamp.default]-[/features/13/conv_1/2/clamp_25_min_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/13/conv_1/2/clamp_25_min])))",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 333) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,576,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/13/conv_1/2/clamp_25_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,576,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 1,
  "InputArgs": ["arg0"],
  "NbOutputVars": 1,
  "OutputVars": ["var1"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 2,
  "Literals": ["6.000000e+00f", "0.000000e+00f"],
  "NbOperations": 2,
  "Operations": ["auto const var0 = pwgen::iMax(arg0, literal1);", "auto const var1 = pwgen::iMin(var0, literal0);"],
  "TacticValue": "0x000000000000001c",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/13/conv_1/2/clamp_25_min]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/13/conv_1/2/_to_copy_51]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/13/conv_1/2/clamp_25_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,576,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 342) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,576,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/features/13/conv/2/convolution_38] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/13/conv/3/_native_batch_norm_legit_no_training_38] + [ELEMENTWISE]-[aten_ops.add.Tensor]-[/features/13/add_7]",
  "LayerType": "CaskGemmConvolution",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 342) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,576,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  },
  {
    "Name": "[ELEMENTWISE]-[aten_ops.add.Tensor]-[/features/12/add_6]_output_add.Tensor",
    "Location": "Device",
    "Dimensions": [1,96,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.add.Tensor]-[/features/13/add_7]_output_add.Tensor",
    "Location": "Device",
    "Dimensions": [1,96,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 96,
  "Groups": 1,
  "Weights": {"Type": "Half", "Count": 55296},
  "Bias": {"Type": "Half", "Count": 96},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 1,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize32x32x64_stage6_warpsize2x2x1_tensor16x8x16",
  "TacticValue": "0x00000000000208d9",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/features/14/conv_0/0/convolution_39] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/14/conv_0/1/_native_batch_norm_legit_no_training_39]",
  "LayerType": "CaskGemmConvolution",
  "Inputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.add.Tensor]-[/features/13/add_7]_output_add.Tensor",
    "Location": "Device",
    "Dimensions": [1,96,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 347) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,576,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 576,
  "Groups": 1,
  "Weights": {"Type": "Half", "Count": 55296},
  "Bias": {"Type": "Half", "Count": 576},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize64x128x32_stage5_warpsize2x2x1_tensor16x8x16",
  "TacticValue": "0x0000000000020808",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/14/conv_0/1/_native_batch_norm_legit_no_training_39]_output from DataType.HALF to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/14/conv_0/2/_to_copy_52]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 347) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,576,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 348) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,576,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "PWN(/features/14/conv_0/2/clamp_26_min_rhs + /features/14/conv_0/2/clamp_26_min_broadcast_to_same_shape_rhs_broadcast, PWN(PWN(/features/14/conv_0/2/clamp_26_max_rhs + /features/14/conv_0/2/clamp_26_max_broadcast_to_same_shape_rhs_broadcast, PWN([SLICE]-[aten_ops.clamp.default]-[/features/14/conv_0/2/clamp_26_max_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/14/conv_0/2/clamp_26_max])), PWN([SLICE]-[aten_ops.clamp.default]-[/features/14/conv_0/2/clamp_26_min_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/14/conv_0/2/clamp_26_min])))",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 348) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,576,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/14/conv_0/2/clamp_26_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,576,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 1,
  "InputArgs": ["arg0"],
  "NbOutputVars": 1,
  "OutputVars": ["var1"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 2,
  "Literals": ["6.000000e+00f", "0.000000e+00f"],
  "NbOperations": 2,
  "Operations": ["auto const var0 = pwgen::iMax(arg0, literal1);", "auto const var1 = pwgen::iMin(var0, literal0);"],
  "TacticValue": "0x000000000000001c",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/14/conv_0/2/clamp_26_min]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/14/conv_0/2/_to_copy_53]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/14/conv_0/2/clamp_26_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,576,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 357) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,576,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/features/14/conv_1/0/convolution_40] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/14/conv_1/1/_native_batch_norm_legit_no_training_40]",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 357) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,576,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 359) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,576,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [2,2],
  "Dilation": [1,1],
  "OutMaps": 576,
  "Groups": 576,
  "Weights": {"Type": "Half", "Count": 5184},
  "Bias": {"Type": "Half", "Count": 576},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm50_xmma_convolution_depthwiseHMMA_FP16NHWCx8_TR3_TS3_STRIDEH2_STRIDEW2",
  "TacticValue": "0x4a741be05296db88",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/14/conv_1/1/_native_batch_norm_legit_no_training_40]_output from DataType.HALF to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/14/conv_1/2/_to_copy_54]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 359) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,576,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 360) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,576,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "PWN(/features/14/conv_1/2/clamp_27_min_rhs + /features/14/conv_1/2/clamp_27_min_broadcast_to_same_shape_rhs_broadcast, PWN(PWN(/features/14/conv_1/2/clamp_27_max_rhs + /features/14/conv_1/2/clamp_27_max_broadcast_to_same_shape_rhs_broadcast, PWN([SLICE]-[aten_ops.clamp.default]-[/features/14/conv_1/2/clamp_27_max_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/14/conv_1/2/clamp_27_max])), PWN([SLICE]-[aten_ops.clamp.default]-[/features/14/conv_1/2/clamp_27_min_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/14/conv_1/2/clamp_27_min])))",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 360) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,576,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/14/conv_1/2/clamp_27_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,576,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 1,
  "InputArgs": ["arg0"],
  "NbOutputVars": 1,
  "OutputVars": ["var1"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 2,
  "Literals": ["6.000000e+00f", "0.000000e+00f"],
  "NbOperations": 2,
  "Operations": ["auto const var0 = pwgen::iMax(arg0, literal1);", "auto const var1 = pwgen::iMin(var0, literal0);"],
  "TacticValue": "0x000000000000001d",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/14/conv_1/2/clamp_27_min]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/14/conv_1/2/_to_copy_55]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/14/conv_1/2/clamp_27_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,576,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 369) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,576,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/features/14/conv/2/convolution_41] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/14/conv/3/_native_batch_norm_legit_no_training_41]",
  "LayerType": "CaskGemmConvolution",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 369) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,576,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 371) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,160,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 160,
  "Groups": 1,
  "Weights": {"Type": "Half", "Count": 92160},
  "Bias": {"Type": "Half", "Count": 160},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize32x32x64_stage6_warpsize2x2x1_tensor16x8x16",
  "TacticValue": "0x00000000000208d9",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/features/15/conv_0/0/convolution_42] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/15/conv_0/1/_native_batch_norm_legit_no_training_42]",
  "LayerType": "CaskGemmConvolution",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 371) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,160,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 373) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,960,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 960,
  "Groups": 1,
  "Weights": {"Type": "Half", "Count": 153600},
  "Bias": {"Type": "Half", "Count": 960},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize64x32x64_stage5_warpsize2x2x1_tensor16x8x16",
  "TacticValue": "0x00000000000208c3",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/15/conv_0/1/_native_batch_norm_legit_no_training_42]_output from DataType.HALF to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/15/conv_0/2/_to_copy_56]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 373) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,960,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 374) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,960,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "PWN(/features/15/conv_0/2/clamp_28_min_rhs + /features/15/conv_0/2/clamp_28_min_broadcast_to_same_shape_rhs_broadcast, PWN(PWN(/features/15/conv_0/2/clamp_28_max_rhs + /features/15/conv_0/2/clamp_28_max_broadcast_to_same_shape_rhs_broadcast, PWN([SLICE]-[aten_ops.clamp.default]-[/features/15/conv_0/2/clamp_28_max_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/15/conv_0/2/clamp_28_max])), PWN([SLICE]-[aten_ops.clamp.default]-[/features/15/conv_0/2/clamp_28_min_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/15/conv_0/2/clamp_28_min])))",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 374) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,960,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "Outputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/15/conv_0/2/clamp_28_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,960,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 1,
  "InputArgs": ["arg0"],
  "NbOutputVars": 1,
  "OutputVars": ["var1"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 2,
  "Literals": ["6.000000e+00f", "0.000000e+00f"],
  "NbOperations": 2,
  "Operations": ["auto const var0 = pwgen::iMax(arg0, literal1);", "auto const var1 = pwgen::iMin(var0, literal0);"],
  "TacticValue": "0x000000000000001d",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/15/conv_0/2/clamp_28_min]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/15/conv_0/2/_to_copy_57]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/15/conv_0/2/clamp_28_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,960,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 383) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,960,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/features/15/conv_1/0/convolution_43] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/15/conv_1/1/_native_batch_norm_legit_no_training_43]",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 383) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,960,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 385) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,960,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 960,
  "Groups": 960,
  "Weights": {"Type": "Half", "Count": 8640},
  "Bias": {"Type": "Half", "Count": 960},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm50_xmma_convolution_depthwiseHMMA_FP16NHWCx8_TR3_TS3_STRIDEH1_STRIDEW1",
  "TacticValue": "0xf9f6e2e1b0fd88e6",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/15/conv_1/1/_native_batch_norm_legit_no_training_43]_output from DataType.HALF to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/15/conv_1/2/_to_copy_58]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 385) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,960,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 386) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,960,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "PWN(/features/15/conv_1/2/clamp_29_min_rhs + /features/15/conv_1/2/clamp_29_min_broadcast_to_same_shape_rhs_broadcast, PWN(PWN(/features/15/conv_1/2/clamp_29_max_rhs + /features/15/conv_1/2/clamp_29_max_broadcast_to_same_shape_rhs_broadcast, PWN([SLICE]-[aten_ops.clamp.default]-[/features/15/conv_1/2/clamp_29_max_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/15/conv_1/2/clamp_29_max])), PWN([SLICE]-[aten_ops.clamp.default]-[/features/15/conv_1/2/clamp_29_min_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/15/conv_1/2/clamp_29_min])))",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 386) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,960,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "Outputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/15/conv_1/2/clamp_29_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,960,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 1,
  "InputArgs": ["arg0"],
  "NbOutputVars": 1,
  "OutputVars": ["var1"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 2,
  "Literals": ["6.000000e+00f", "0.000000e+00f"],
  "NbOperations": 2,
  "Operations": ["auto const var0 = pwgen::iMax(arg0, literal1);", "auto const var1 = pwgen::iMin(var0, literal0);"],
  "TacticValue": "0x000000000000001d",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/15/conv_1/2/clamp_29_min]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/15/conv_1/2/_to_copy_59]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/15/conv_1/2/clamp_29_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,960,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 395) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,960,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/features/15/conv/2/convolution_44] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/15/conv/3/_native_batch_norm_legit_no_training_44] + [ELEMENTWISE]-[aten_ops.add.Tensor]-[/features/15/add_8]",
  "LayerType": "CaskGemmConvolution",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 395) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,960,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  },
  {
    "Name": "(Unnamed Layer* 371) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,160,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.add.Tensor]-[/features/15/add_8]_output_add.Tensor",
    "Location": "Device",
    "Dimensions": [1,160,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 160,
  "Groups": 1,
  "Weights": {"Type": "Half", "Count": 153600},
  "Bias": {"Type": "Half", "Count": 160},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 1,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize32x32x64_stage6_warpsize2x2x1_tensor16x8x16",
  "TacticValue": "0x00000000000208d9",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/features/16/conv_0/0/convolution_45] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/16/conv_0/1/_native_batch_norm_legit_no_training_45]",
  "LayerType": "CaskGemmConvolution",
  "Inputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.add.Tensor]-[/features/15/add_8]_output_add.Tensor",
    "Location": "Device",
    "Dimensions": [1,160,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 400) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,960,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 960,
  "Groups": 1,
  "Weights": {"Type": "Half", "Count": 153600},
  "Bias": {"Type": "Half", "Count": 960},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize64x32x64_stage5_warpsize2x2x1_tensor16x8x16",
  "TacticValue": "0x00000000000208c3",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/16/conv_0/1/_native_batch_norm_legit_no_training_45]_output from DataType.HALF to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/16/conv_0/2/_to_copy_60]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 400) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,960,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 401) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,960,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "PWN(/features/16/conv_0/2/clamp_30_min_rhs + /features/16/conv_0/2/clamp_30_min_broadcast_to_same_shape_rhs_broadcast, PWN(PWN(/features/16/conv_0/2/clamp_30_max_rhs + /features/16/conv_0/2/clamp_30_max_broadcast_to_same_shape_rhs_broadcast, PWN([SLICE]-[aten_ops.clamp.default]-[/features/16/conv_0/2/clamp_30_max_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/16/conv_0/2/clamp_30_max])), PWN([SLICE]-[aten_ops.clamp.default]-[/features/16/conv_0/2/clamp_30_min_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/16/conv_0/2/clamp_30_min])))",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 401) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,960,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "Outputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/16/conv_0/2/clamp_30_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,960,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 1,
  "InputArgs": ["arg0"],
  "NbOutputVars": 1,
  "OutputVars": ["var1"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 2,
  "Literals": ["6.000000e+00f", "0.000000e+00f"],
  "NbOperations": 2,
  "Operations": ["auto const var0 = pwgen::iMax(arg0, literal1);", "auto const var1 = pwgen::iMin(var0, literal0);"],
  "TacticValue": "0x000000000000001d",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/16/conv_0/2/clamp_30_min]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/16/conv_0/2/_to_copy_61]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/16/conv_0/2/clamp_30_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,960,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 410) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,960,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/features/16/conv_1/0/convolution_46] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/16/conv_1/1/_native_batch_norm_legit_no_training_46]",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 410) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,960,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 412) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,960,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 960,
  "Groups": 960,
  "Weights": {"Type": "Half", "Count": 8640},
  "Bias": {"Type": "Half", "Count": 960},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm50_xmma_convolution_depthwiseHMMA_FP16NHWCx8_TR3_TS3_STRIDEH1_STRIDEW1",
  "TacticValue": "0xf9f6e2e1b0fd88e6",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/16/conv_1/1/_native_batch_norm_legit_no_training_46]_output from DataType.HALF to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/16/conv_1/2/_to_copy_62]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 412) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,960,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 413) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,960,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "PWN(/features/16/conv_1/2/clamp_31_min_rhs + /features/16/conv_1/2/clamp_31_min_broadcast_to_same_shape_rhs_broadcast, PWN(PWN(/features/16/conv_1/2/clamp_31_max_rhs + /features/16/conv_1/2/clamp_31_max_broadcast_to_same_shape_rhs_broadcast, PWN([SLICE]-[aten_ops.clamp.default]-[/features/16/conv_1/2/clamp_31_max_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/16/conv_1/2/clamp_31_max])), PWN([SLICE]-[aten_ops.clamp.default]-[/features/16/conv_1/2/clamp_31_min_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/16/conv_1/2/clamp_31_min])))",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 413) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,960,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "Outputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/16/conv_1/2/clamp_31_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,960,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 1,
  "InputArgs": ["arg0"],
  "NbOutputVars": 1,
  "OutputVars": ["var1"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 2,
  "Literals": ["6.000000e+00f", "0.000000e+00f"],
  "NbOperations": 2,
  "Operations": ["auto const var0 = pwgen::iMax(arg0, literal1);", "auto const var1 = pwgen::iMin(var0, literal0);"],
  "TacticValue": "0x000000000000001d",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/16/conv_1/2/clamp_31_min]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/16/conv_1/2/_to_copy_63]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/16/conv_1/2/clamp_31_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,960,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 422) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,960,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/features/16/conv/2/convolution_47] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/16/conv/3/_native_batch_norm_legit_no_training_47] + [ELEMENTWISE]-[aten_ops.add.Tensor]-[/features/16/add_9]",
  "LayerType": "CaskGemmConvolution",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 422) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,960,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  },
  {
    "Name": "[ELEMENTWISE]-[aten_ops.add.Tensor]-[/features/15/add_8]_output_add.Tensor",
    "Location": "Device",
    "Dimensions": [1,160,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.add.Tensor]-[/features/16/add_9]_output_add.Tensor",
    "Location": "Device",
    "Dimensions": [1,160,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 160,
  "Groups": 1,
  "Weights": {"Type": "Half", "Count": 153600},
  "Bias": {"Type": "Half", "Count": 160},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 1,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize32x32x64_stage6_warpsize2x2x1_tensor16x8x16",
  "TacticValue": "0x00000000000208d9",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/features/17/conv_0/0/convolution_48] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/17/conv_0/1/_native_batch_norm_legit_no_training_48]",
  "LayerType": "CaskGemmConvolution",
  "Inputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.add.Tensor]-[/features/16/add_9]_output_add.Tensor",
    "Location": "Device",
    "Dimensions": [1,160,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 427) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,960,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 960,
  "Groups": 1,
  "Weights": {"Type": "Half", "Count": 153600},
  "Bias": {"Type": "Half", "Count": 960},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize64x32x64_stage5_warpsize2x2x1_tensor16x8x16",
  "TacticValue": "0x00000000000208c3",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/17/conv_0/1/_native_batch_norm_legit_no_training_48]_output from DataType.HALF to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/17/conv_0/2/_to_copy_64]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 427) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,960,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 428) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,960,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "PWN(/features/17/conv_0/2/clamp_32_min_rhs + /features/17/conv_0/2/clamp_32_min_broadcast_to_same_shape_rhs_broadcast, PWN(PWN(/features/17/conv_0/2/clamp_32_max_rhs + /features/17/conv_0/2/clamp_32_max_broadcast_to_same_shape_rhs_broadcast, PWN([SLICE]-[aten_ops.clamp.default]-[/features/17/conv_0/2/clamp_32_max_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/17/conv_0/2/clamp_32_max])), PWN([SLICE]-[aten_ops.clamp.default]-[/features/17/conv_0/2/clamp_32_min_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/17/conv_0/2/clamp_32_min])))",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 428) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,960,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "Outputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/17/conv_0/2/clamp_32_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,960,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 1,
  "InputArgs": ["arg0"],
  "NbOutputVars": 1,
  "OutputVars": ["var1"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 2,
  "Literals": ["6.000000e+00f", "0.000000e+00f"],
  "NbOperations": 2,
  "Operations": ["auto const var0 = pwgen::iMax(arg0, literal1);", "auto const var1 = pwgen::iMin(var0, literal0);"],
  "TacticValue": "0x000000000000001d",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/17/conv_0/2/clamp_32_min]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/17/conv_0/2/_to_copy_65]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/17/conv_0/2/clamp_32_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,960,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 437) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,960,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/features/17/conv_1/0/convolution_49] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/17/conv_1/1/_native_batch_norm_legit_no_training_49]",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 437) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,960,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 439) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,960,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 960,
  "Groups": 960,
  "Weights": {"Type": "Half", "Count": 8640},
  "Bias": {"Type": "Half", "Count": 960},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm50_xmma_convolution_depthwiseHMMA_FP16NHWCx8_TR3_TS3_STRIDEH1_STRIDEW1",
  "TacticValue": "0xf9f6e2e1b0fd88e6",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/17/conv_1/1/_native_batch_norm_legit_no_training_49]_output from DataType.HALF to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/17/conv_1/2/_to_copy_66]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 439) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,960,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 440) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,960,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "PWN(/features/17/conv_1/2/clamp_33_min_rhs + /features/17/conv_1/2/clamp_33_min_broadcast_to_same_shape_rhs_broadcast, PWN(PWN(/features/17/conv_1/2/clamp_33_max_rhs + /features/17/conv_1/2/clamp_33_max_broadcast_to_same_shape_rhs_broadcast, PWN([SLICE]-[aten_ops.clamp.default]-[/features/17/conv_1/2/clamp_33_max_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/17/conv_1/2/clamp_33_max])), PWN([SLICE]-[aten_ops.clamp.default]-[/features/17/conv_1/2/clamp_33_min_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/17/conv_1/2/clamp_33_min])))",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 440) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,960,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "Outputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/17/conv_1/2/clamp_33_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,960,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 1,
  "InputArgs": ["arg0"],
  "NbOutputVars": 1,
  "OutputVars": ["var1"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 2,
  "Literals": ["6.000000e+00f", "0.000000e+00f"],
  "NbOperations": 2,
  "Operations": ["auto const var0 = pwgen::iMax(arg0, literal1);", "auto const var1 = pwgen::iMin(var0, literal0);"],
  "TacticValue": "0x000000000000001d",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/17/conv_1/2/clamp_33_min]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/17/conv_1/2/_to_copy_67]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features/17/conv_1/2/clamp_33_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,960,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 449) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,960,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/features/17/conv/2/convolution_50] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/17/conv/3/_native_batch_norm_legit_no_training_50]",
  "LayerType": "CaskGemmConvolution",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 449) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,960,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 451) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,320,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 320,
  "Groups": 1,
  "Weights": {"Type": "Half", "Count": 307200},
  "Bias": {"Type": "Half", "Count": 320},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_gemm_f16f16_f16f16_f16_tn_n_tilesize32x32x64_stage6_warpsize2x2x1_tensor16x8x16",
  "TacticValue": "0x00000000000208d9",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/features_18/0/convolution_51] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features_18/1/_native_batch_norm_legit_no_training_51]",
  "LayerType": "CaskGemmConvolution",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 451) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,320,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 453) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,1280,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 1280,
  "Groups": 1,
  "Weights": {"Type": "Half", "Count": 409600},
  "Bias": {"Type": "Half", "Count": 1280},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_gemm_f16f16_f16f16_f16_nn_n_tilesize64x64x64_stage4_warpsize2x2x1_tensor16x8x16",
  "TacticValue": "0x000000000002040f",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features_18/1/_native_batch_norm_legit_no_training_51]_output from DataType.HALF to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features_18/2/_to_copy_68]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 453) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,1280,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 454) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,1280,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "PWN(/features_18/2/clamp_34_min_rhs + /features_18/2/clamp_34_min_broadcast_to_same_shape_rhs_broadcast, PWN(PWN(/features_18/2/clamp_34_max_rhs + /features_18/2/clamp_34_max_broadcast_to_same_shape_rhs_broadcast, PWN([SLICE]-[aten_ops.clamp.default]-[/features_18/2/clamp_34_max_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features_18/2/clamp_34_max])), PWN([SLICE]-[aten_ops.clamp.default]-[/features_18/2/clamp_34_min_broadcast_to_same_shape_expand_rhs_val] + [ELEMENTWISE]-[aten_ops.clamp.default]-[/features_18/2/clamp_34_min])))",
  "LayerType": "PointWiseV2",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 454) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,1280,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "Outputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features_18/2/clamp_34_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,1280,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "ParameterType": "PointWise",
  "ParameterSubType": "PointWiseExpression",
  "NbInputArgs": 1,
  "InputArgs": ["arg0"],
  "NbOutputVars": 1,
  "OutputVars": ["var1"],
  "NbParams": 0,
  "Params": [],
  "NbLiterals": 2,
  "Literals": ["6.000000e+00f", "0.000000e+00f"],
  "NbOperations": 2,
  "Operations": ["auto const var0 = pwgen::iMax(arg0, literal1);", "auto const var1 = pwgen::iMin(var0, literal0);"],
  "TacticValue": "0x000000000000001e",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [ELEMENTWISE]-[aten_ops.clamp.default]-[/features_18/2/clamp_34_min]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features_18/2/_to_copy_69]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.clamp.default]-[/features_18/2/clamp_34_min]_output_clamp.default",
    "Location": "Device",
    "Dimensions": [1,1280,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 16 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 463) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,1280,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[REDUCE]-[aten_ops.mean.dim]-[__/mean]",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 463) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,1280,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 464) [Reduce]_output",
    "Location": "Device",
    "Dimensions": [1,1280,1,1],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "AVERAGE",
  "WindowSize": [7,7],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm50_xmma_pooling_fw_4d_FP16FP32NHWC_Average_FastDiv_CAlign4",
  "TacticValue": "0x56d7b61f084f251e",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to [SHUFFLE]-[aten_ops.reshape.default]-[__/reshape_default]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 464) [Reduce]_output",
    "Location": "Device",
    "Dimensions": [1,1280,1,1],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to [SHUFFLE]-[aten_ops.reshape.default]-[__/reshape_default]",
    "Location": "Device",
    "Dimensions": [1,1280,1,1],
    "Format/Datatype": "Row major linear FP16 format"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[SHUFFLE]-[aten_ops.reshape.default]-[__/reshape_default]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to [SHUFFLE]-[aten_ops.reshape.default]-[__/reshape_default]",
    "Location": "Device",
    "Dimensions": [1,1280,1,1],
    "Format/Datatype": "Row major linear FP16 format"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 465) [Shuffle]_output",
    "Location": "Device",
    "Dimensions": [1,1280],
    "Format/Datatype": "Row major linear FP16 format"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Forced Cast ITensor [SHUFFLE]-[aten_ops.reshape.default]-[__/reshape_default]_output from DataType.HALF to DataType.HALF - [aten_ops.torch.ops.aten.clone.default]-[/classifier/0/clone]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 465) [Shuffle]_output",
    "Location": "Device",
    "Dimensions": [1,1280],
    "Format/Datatype": "Row major linear FP16 format"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 466) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,1280],
    "Format/Datatype": "Row major linear FP16 format"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "reshape_before_[MATRIX_MULTIPLY]-[aten_ops.addmm.default]-[/classifier/1/addmm_mm]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 466) [Identity]_output",
    "Location": "Device",
    "Dimensions": [1,1280],
    "Format/Datatype": "Row major linear FP16 format"
  }],
  "Outputs": [
  {
    "Name": "reshape_before_[MATRIX_MULTIPLY]-[aten_ops.addmm.default]-[/classifier/1/addmm_mm]",
    "Location": "Device",
    "Dimensions": [1,1280,1,1],
    "Format/Datatype": "Row major linear FP16 format"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to [MATRIX_MULTIPLY]-[aten_ops.addmm.default]-[/classifier/1/addmm_mm] + /classifier/1/addmm_constant_0 + /classifier/1/addmm_add_broadcast_to_same_shape_lhs_broadcast + unsqueeze_node_after_/classifier/1/addmm_constant_0 + /classifier/1/addmm_add_broadcast_to_same_shape_lhs_broadcast_/classifier/1/addmm_add_broadcast_to_same_shape_lhs_broadcast_output + [ELEMENTWISE]-[aten_ops.addmm.default]-[/classifier/1/addmm_add]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "reshape_before_[MATRIX_MULTIPLY]-[aten_ops.addmm.default]-[/classifier/1/addmm_mm]",
    "Location": "Device",
    "Dimensions": [1,1280,1,1],
    "Format/Datatype": "Row major linear FP16 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to [MATRIX_MULTIPLY]-[aten_ops.addmm.default]-[/classifier/1/addmm_mm] + /classifier/1/addmm_constant_0 + /classifier/1/addmm_add_broadcast_to_same_shape_lhs_broadcast + unsqueeze_node_after_/classifier/1/addmm_constant_0 + /classifier/1/addmm_add_broadcast_to_same_shape_lhs_broadcast_/classifier/1/addmm_add_broadcast_to_same_shape_lhs_broadcast_output + [ELEMENTWISE]-[aten_ops.addmm.default]-[/classifier/1/addmm_add]",
    "Location": "Device",
    "Dimensions": [1,1280,1,1],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[MATRIX_MULTIPLY]-[aten_ops.addmm.default]-[/classifier/1/addmm_mm] + /classifier/1/addmm_constant_0 + /classifier/1/addmm_add_broadcast_to_same_shape_lhs_broadcast + unsqueeze_node_after_/classifier/1/addmm_constant_0 + /classifier/1/addmm_add_broadcast_to_same_shape_lhs_broadcast_/classifier/1/addmm_add_broadcast_to_same_shape_lhs_broadcast_output + [ELEMENTWISE]-[aten_ops.addmm.default]-[/classifier/1/addmm_add]",
  "LayerType": "CaskGemmConvolution",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to [MATRIX_MULTIPLY]-[aten_ops.addmm.default]-[/classifier/1/addmm_mm] + /classifier/1/addmm_constant_0 + /classifier/1/addmm_add_broadcast_to_same_shape_lhs_broadcast + unsqueeze_node_after_/classifier/1/addmm_constant_0 + /classifier/1/addmm_add_broadcast_to_same_shape_lhs_broadcast_/classifier/1/addmm_add_broadcast_to_same_shape_lhs_broadcast_output + [ELEMENTWISE]-[aten_ops.addmm.default]-[/classifier/1/addmm_add]",
    "Location": "Device",
    "Dimensions": [1,1280,1,1],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.addmm.default]-[/classifier/1/addmm_add]_out_tensor",
    "Location": "Device",
    "Dimensions": [1,1000,1,1],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 1000,
  "Groups": 1,
  "Weights": {"Type": "Half", "Count": 1280000},
  "Bias": {"Type": "Half", "Count": 1000},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm70_xmma_gemm_as_conv1x1_f16f16_f16_f16_tn_n_simt_small_batch_bias_relu",
  "TacticValue": "0x0000000000020796",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to copied_squeeze_after_[ELEMENTWISE]-[aten_ops.addmm.default]-[/classifier/1/addmm_add]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.addmm.default]-[/classifier/1/addmm_add]_out_tensor",
    "Location": "Device",
    "Dimensions": [1,1000,1,1],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to copied_squeeze_after_[ELEMENTWISE]-[aten_ops.addmm.default]-[/classifier/1/addmm_add]",
    "Location": "Device",
    "Dimensions": [1,1000,1,1],
    "Format/Datatype": "Row major linear FP16 format"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "copied_squeeze_after_[ELEMENTWISE]-[aten_ops.addmm.default]-[/classifier/1/addmm_add]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to copied_squeeze_after_[ELEMENTWISE]-[aten_ops.addmm.default]-[/classifier/1/addmm_add]",
    "Location": "Device",
    "Dimensions": [1,1000,1,1],
    "Format/Datatype": "Row major linear FP16 format"
  }],
  "Outputs": [
  {
    "Name": "output0",
    "Location": "Device",
    "Dimensions": [1,1000],
    "Format/Datatype": "Row major linear FP16 format"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
}],
"Bindings": ["x"
,"output0"
]}
