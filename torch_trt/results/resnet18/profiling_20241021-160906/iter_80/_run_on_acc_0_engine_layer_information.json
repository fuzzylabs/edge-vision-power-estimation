{"Layers": [{
  "Name": "Reformatting CopyNode for Input Tensor 0 to [CONVOLUTION]-[aten_ops.convolution.default]-[/conv1/convolution] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/bn1/_native_batch_norm_legit_no_training] + [RELU]-[aten_ops.relu.default]-[/relu/relu]",
  "LayerType": "Reformat",
  "Inputs": [
  {
    "Name": "x",
    "Location": "Device",
    "Dimensions": [1,3,224,224],
    "Format/Datatype": "Row major linear FP16 format"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to [CONVOLUTION]-[aten_ops.convolution.default]-[/conv1/convolution] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/bn1/_native_batch_norm_legit_no_training] + [RELU]-[aten_ops.relu.default]-[/relu/relu]",
    "Location": "Device",
    "Dimensions": [1,3,224,224],
    "Format/Datatype": "Channel major FP16 format where channel % 4 == 0"
  }],
  "ParameterType": "Reformat",
  "Origin": "REFORMAT",
  "TacticValue": "0x00000000000003e8",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/conv1/convolution] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/bn1/_native_batch_norm_legit_no_training] + [RELU]-[aten_ops.relu.default]-[/relu/relu]",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to [CONVOLUTION]-[aten_ops.convolution.default]-[/conv1/convolution] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/bn1/_native_batch_norm_legit_no_training] + [RELU]-[aten_ops.relu.default]-[/relu/relu]",
    "Location": "Device",
    "Dimensions": [1,3,224,224],
    "Format/Datatype": "Channel major FP16 format where channel % 4 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 2) [Activation]_output",
    "Location": "Device",
    "Dimensions": [1,64,112,112],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [7,7],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [3,3],
  "PostPadding": [3,3],
  "Stride": [2,2],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Half", "Count": 9408},
  "Bias": {"Type": "Half", "Count": 64},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_indexed_wo_smem_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x32x64_stage1_warpsize4x1x1_g1_tensor16x8x16_aligna8_alignc8",
  "TacticValue": "0x280b0ad3c23d8442",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[MAX]-[aten_ops.max_pool2d.default]-[/maxpool/max_pool2d_default]",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 2) [Activation]_output",
    "Location": "Device",
    "Dimensions": [1,64,112,112],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 3) [Pooling]_output",
    "Location": "Device",
    "Dimensions": [1,64,56,56],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "MAX",
  "WindowSize": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [2,2],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm50_xmma_pooling_coalescedC_NHWC_kMAX_3_False",
  "TacticValue": "0xdb415cba6b0e9137",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/layer1/0/conv1/convolution_1] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/layer1/0/bn1/_native_batch_norm_legit_no_training_1] + [RELU]-[aten_ops.relu.default]-[/layer1/0/relu/relu_1]",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 3) [Pooling]_output",
    "Location": "Device",
    "Dimensions": [1,64,56,56],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 6) [Activation]_output",
    "Location": "Device",
    "Dimensions": [1,64,56,56],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Half", "Count": 36864},
  "Bias": {"Type": "Half", "Count": 64},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3_aACCESS",
  "TacticValue": "0x263a38afd75e3a43",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/layer1/0/conv2/convolution_2] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/layer1/0/bn2/_native_batch_norm_legit_no_training_2] + [ELEMENTWISE]-[aten_ops.add.Tensor]-[/layer1/0/add] + [RELU]-[aten_ops.relu.default]-[/layer1/0/relu/relu_2]",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 6) [Activation]_output",
    "Location": "Device",
    "Dimensions": [1,64,56,56],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  },
  {
    "Name": "(Unnamed Layer* 3) [Pooling]_output",
    "Location": "Device",
    "Dimensions": [1,64,56,56],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 10) [Activation]_output",
    "Location": "Device",
    "Dimensions": [1,64,56,56],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Half", "Count": 36864},
  "Bias": {"Type": "Half", "Count": 64},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 1,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3_aACCESS",
  "TacticValue": "0x263a38afd75e3a43",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/layer1/1/conv1/convolution_3] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/layer1/1/bn1/_native_batch_norm_legit_no_training_3] + [RELU]-[aten_ops.relu.default]-[/layer1/1/relu/relu_3]",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 10) [Activation]_output",
    "Location": "Device",
    "Dimensions": [1,64,56,56],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 13) [Activation]_output",
    "Location": "Device",
    "Dimensions": [1,64,56,56],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Half", "Count": 36864},
  "Bias": {"Type": "Half", "Count": 64},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3_aACCESS",
  "TacticValue": "0x263a38afd75e3a43",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/layer1/1/conv2/convolution_4] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/layer1/1/bn2/_native_batch_norm_legit_no_training_4] + [ELEMENTWISE]-[aten_ops.add.Tensor]-[/layer1/1/add_1] + [RELU]-[aten_ops.relu.default]-[/layer1/1/relu/relu_4]",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 13) [Activation]_output",
    "Location": "Device",
    "Dimensions": [1,64,56,56],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  },
  {
    "Name": "(Unnamed Layer* 10) [Activation]_output",
    "Location": "Device",
    "Dimensions": [1,64,56,56],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 17) [Activation]_output",
    "Location": "Device",
    "Dimensions": [1,64,56,56],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 64,
  "Groups": 1,
  "Weights": {"Type": "Half", "Count": 36864},
  "Bias": {"Type": "Half", "Count": 64},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 1,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3_aACCESS",
  "TacticValue": "0x263a38afd75e3a43",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/layer2/0/conv1/convolution_5] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/layer2/0/bn1/_native_batch_norm_legit_no_training_5] + [RELU]-[aten_ops.relu.default]-[/layer2/0/relu/relu_5]",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 17) [Activation]_output",
    "Location": "Device",
    "Dimensions": [1,64,56,56],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 20) [Activation]_output",
    "Location": "Device",
    "Dimensions": [1,128,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [2,2],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Half", "Count": 73728},
  "Bias": {"Type": "Half", "Count": 128},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x1x2_g1_tensor16x8x16_aACCESS",
  "TacticValue": "0x841c601dec2a75bc",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/layer2/0/downsample/0/convolution_7] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/layer2/0/downsample/1/_native_batch_norm_legit_no_training_7]",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 17) [Activation]_output",
    "Location": "Device",
    "Dimensions": [1,64,56,56],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 24) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,128,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [2,2],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Half", "Count": 8192},
  "Bias": {"Type": "Half", "Count": 128},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16",
  "TacticValue": "0x4a81ea1e51436a30",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/layer2/0/conv2/convolution_6] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/layer2/0/bn2/_native_batch_norm_legit_no_training_6] + [ELEMENTWISE]-[aten_ops.add.Tensor]-[/layer2/0/add_2] + [RELU]-[aten_ops.relu.default]-[/layer2/0/relu/relu_6]",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 20) [Activation]_output",
    "Location": "Device",
    "Dimensions": [1,128,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  },
  {
    "Name": "(Unnamed Layer* 24) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,128,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 26) [Activation]_output",
    "Location": "Device",
    "Dimensions": [1,128,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Half", "Count": 147456},
  "Bias": {"Type": "Half", "Count": 128},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 1,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x1x2_g1_tensor16x8x16_aACCESS",
  "TacticValue": "0x841c601dec2a75bc",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/layer2/1/conv1/convolution_8] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/layer2/1/bn1/_native_batch_norm_legit_no_training_8] + [RELU]-[aten_ops.relu.default]-[/layer2/1/relu/relu_7]",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 26) [Activation]_output",
    "Location": "Device",
    "Dimensions": [1,128,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 29) [Activation]_output",
    "Location": "Device",
    "Dimensions": [1,128,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Half", "Count": 147456},
  "Bias": {"Type": "Half", "Count": 128},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x1x2_g1_tensor16x8x16_aACCESS",
  "TacticValue": "0x841c601dec2a75bc",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/layer2/1/conv2/convolution_9] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/layer2/1/bn2/_native_batch_norm_legit_no_training_9] + [ELEMENTWISE]-[aten_ops.add.Tensor]-[/layer2/1/add_3] + [RELU]-[aten_ops.relu.default]-[/layer2/1/relu/relu_8]",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 29) [Activation]_output",
    "Location": "Device",
    "Dimensions": [1,128,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  },
  {
    "Name": "(Unnamed Layer* 26) [Activation]_output",
    "Location": "Device",
    "Dimensions": [1,128,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 33) [Activation]_output",
    "Location": "Device",
    "Dimensions": [1,128,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 128,
  "Groups": 1,
  "Weights": {"Type": "Half", "Count": 147456},
  "Bias": {"Type": "Half", "Count": 128},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 1,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x1x2_g1_tensor16x8x16_aACCESS",
  "TacticValue": "0x841c601dec2a75bc",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/layer3/0/conv1/convolution_10] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/layer3/0/bn1/_native_batch_norm_legit_no_training_10] + [RELU]-[aten_ops.relu.default]-[/layer3/0/relu/relu_9]",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 33) [Activation]_output",
    "Location": "Device",
    "Dimensions": [1,128,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 36) [Activation]_output",
    "Location": "Device",
    "Dimensions": [1,256,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [2,2],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Half", "Count": 294912},
  "Bias": {"Type": "Half", "Count": 256},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16",
  "TacticValue": "0xf35e0311fa1cc516",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/layer3/0/downsample/0/convolution_12] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/layer3/0/downsample/1/_native_batch_norm_legit_no_training_12]",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 33) [Activation]_output",
    "Location": "Device",
    "Dimensions": [1,128,28,28],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 40) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,256,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [2,2],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Half", "Count": 32768},
  "Bias": {"Type": "Half", "Count": 256},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16",
  "TacticValue": "0x4a81ea1e51436a30",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/layer3/0/conv2/convolution_11] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/layer3/0/bn2/_native_batch_norm_legit_no_training_11] + [ELEMENTWISE]-[aten_ops.add.Tensor]-[/layer3/0/add_4] + [RELU]-[aten_ops.relu.default]-[/layer3/0/relu/relu_10]",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 36) [Activation]_output",
    "Location": "Device",
    "Dimensions": [1,256,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  },
  {
    "Name": "(Unnamed Layer* 40) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,256,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 42) [Activation]_output",
    "Location": "Device",
    "Dimensions": [1,256,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Half", "Count": 589824},
  "Bias": {"Type": "Half", "Count": 256},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 1,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x1x2_g1_tensor16x8x16_aACCESS",
  "TacticValue": "0x841c601dec2a75bc",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/layer3/1/conv1/convolution_13] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/layer3/1/bn1/_native_batch_norm_legit_no_training_13] + [RELU]-[aten_ops.relu.default]-[/layer3/1/relu/relu_11]",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 42) [Activation]_output",
    "Location": "Device",
    "Dimensions": [1,256,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 45) [Activation]_output",
    "Location": "Device",
    "Dimensions": [1,256,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Half", "Count": 589824},
  "Bias": {"Type": "Half", "Count": 256},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x1x2_g1_tensor16x8x16_aACCESS",
  "TacticValue": "0x841c601dec2a75bc",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/layer3/1/conv2/convolution_14] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/layer3/1/bn2/_native_batch_norm_legit_no_training_14] + [ELEMENTWISE]-[aten_ops.add.Tensor]-[/layer3/1/add_5] + [RELU]-[aten_ops.relu.default]-[/layer3/1/relu/relu_12]",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 45) [Activation]_output",
    "Location": "Device",
    "Dimensions": [1,256,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  },
  {
    "Name": "(Unnamed Layer* 42) [Activation]_output",
    "Location": "Device",
    "Dimensions": [1,256,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 49) [Activation]_output",
    "Location": "Device",
    "Dimensions": [1,256,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 256,
  "Groups": 1,
  "Weights": {"Type": "Half", "Count": 589824},
  "Bias": {"Type": "Half", "Count": 256},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 1,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x1x2_g1_tensor16x8x16_aACCESS",
  "TacticValue": "0x841c601dec2a75bc",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/layer4/0/conv1/convolution_15] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/layer4/0/bn1/_native_batch_norm_legit_no_training_15] + [RELU]-[aten_ops.relu.default]-[/layer4/0/relu/relu_13]",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 49) [Activation]_output",
    "Location": "Device",
    "Dimensions": [1,256,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 52) [Activation]_output",
    "Location": "Device",
    "Dimensions": [1,512,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [2,2],
  "Dilation": [1,1],
  "OutMaps": 512,
  "Groups": 1,
  "Weights": {"Type": "Half", "Count": 1179648},
  "Bias": {"Type": "Half", "Count": 512},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3",
  "TacticValue": "0xa033e20ae9f412b2",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/layer4/0/downsample/0/convolution_17] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/layer4/0/downsample/1/_native_batch_norm_legit_no_training_17]",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 49) [Activation]_output",
    "Location": "Device",
    "Dimensions": [1,256,14,14],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 56) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,512,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [2,2],
  "Dilation": [1,1],
  "OutMaps": 512,
  "Groups": 1,
  "Weights": {"Type": "Half", "Count": 131072},
  "Bias": {"Type": "Half", "Count": 512},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r1s1",
  "TacticValue": "0x2aa016c86360697f",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/layer4/0/conv2/convolution_16] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/layer4/0/bn2/_native_batch_norm_legit_no_training_16] + [ELEMENTWISE]-[aten_ops.add.Tensor]-[/layer4/0/add_6] + [RELU]-[aten_ops.relu.default]-[/layer4/0/relu/relu_14]",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 52) [Activation]_output",
    "Location": "Device",
    "Dimensions": [1,512,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  },
  {
    "Name": "(Unnamed Layer* 56) [Scale]_output",
    "Location": "Device",
    "Dimensions": [1,512,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 58) [Activation]_output",
    "Location": "Device",
    "Dimensions": [1,512,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 512,
  "Groups": 1,
  "Weights": {"Type": "Half", "Count": 2359296},
  "Bias": {"Type": "Half", "Count": 512},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 1,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3",
  "TacticValue": "0xa033e20ae9f412b2",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/layer4/1/conv1/convolution_18] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/layer4/1/bn1/_native_batch_norm_legit_no_training_18] + [RELU]-[aten_ops.relu.default]-[/layer4/1/relu/relu_15]",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 58) [Activation]_output",
    "Location": "Device",
    "Dimensions": [1,512,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 61) [Activation]_output",
    "Location": "Device",
    "Dimensions": [1,512,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 512,
  "Groups": 1,
  "Weights": {"Type": "Half", "Count": 2359296},
  "Bias": {"Type": "Half", "Count": 512},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3",
  "TacticValue": "0xa033e20ae9f412b2",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/layer4/1/conv2/convolution_19] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/layer4/1/bn2/_native_batch_norm_legit_no_training_19] + [ELEMENTWISE]-[aten_ops.add.Tensor]-[/layer4/1/add_7] + [RELU]-[aten_ops.relu.default]-[/layer4/1/relu/relu_16]",
  "LayerType": "CaskConvolution",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 61) [Activation]_output",
    "Location": "Device",
    "Dimensions": [1,512,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  },
  {
    "Name": "(Unnamed Layer* 58) [Activation]_output",
    "Location": "Device",
    "Dimensions": [1,512,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 65) [Activation]_output",
    "Location": "Device",
    "Dimensions": [1,512,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [3,3],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [1,1],
  "PostPadding": [1,1],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 512,
  "Groups": 1,
  "Weights": {"Type": "Half", "Count": 2359296},
  "Bias": {"Type": "Half", "Count": 512},
  "HasBias": 1,
  "HasReLU": 1,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 1,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "RELU",
  "TacticName": "sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x32x64_stage5_warpsize2x2x1_g1_tensor16x8x16_t1r3s3",
  "TacticValue": "0xa033e20ae9f412b2",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[REDUCE]-[aten_ops.mean.dim]-[/avgpool/mean]",
  "LayerType": "CaskPooling",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 65) [Activation]_output",
    "Location": "Device",
    "Dimensions": [1,512,7,7],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "(Unnamed Layer* 66) [Reduce]_output",
    "Location": "Device",
    "Dimensions": [1,512,1,1],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Pooling",
  "PoolingType": "AVERAGE",
  "WindowSize": [7,7],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "BlendFactor": 0,
  "AverageCountExcludesPadding": 1,
  "TacticName": "sm50_xmma_pooling_fw_4d_FP16FP32NHWC_Average_FastDiv_CAlign4",
  "TacticValue": "0x56d7b61f084f251e",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "[MATRIX_MULTIPLY]-[aten_ops.addmm.default]-[/fc/addmm_mm] + /fc/addmm_constant_0 + /fc/addmm_add_broadcast_to_same_shape_lhs_broadcast + unsqueeze_node_after_/fc/addmm_constant_0 + /fc/addmm_add_broadcast_to_same_shape_lhs_broadcast_/fc/addmm_add_broadcast_to_same_shape_lhs_broadcast_output + [ELEMENTWISE]-[aten_ops.addmm.default]-[/fc/addmm_add]",
  "LayerType": "CaskGemmConvolution",
  "Inputs": [
  {
    "Name": "(Unnamed Layer* 66) [Reduce]_output",
    "Location": "Device",
    "Dimensions": [1,512,1,1],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.addmm.default]-[/fc/addmm_add]_out_tensor",
    "Location": "Device",
    "Dimensions": [1,1000,1,1],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "ParameterType": "Convolution",
  "Kernel": [1,1],
  "PaddingMode": "kEXPLICIT_ROUND_DOWN",
  "PrePadding": [0,0],
  "PostPadding": [0,0],
  "Stride": [1,1],
  "Dilation": [1,1],
  "OutMaps": 1000,
  "Groups": 1,
  "Weights": {"Type": "Half", "Count": 512000},
  "Bias": {"Type": "Half", "Count": 1000},
  "HasBias": 1,
  "HasReLU": 0,
  "HasSparseWeights": 0,
  "HasDynamicFilter": 0,
  "HasDynamicBias": 0,
  "HasResidual": 0,
  "ConvXAsActInputIdx": -1,
  "BiasAsActInputIdx": -1,
  "ResAsActInputIdx": -1,
  "Activation": "NONE",
  "TacticName": "sm70_xmma_gemm_as_conv1x1_f16f16_f16_f16_tn_n_simt_small_batch_bias_relu",
  "TacticValue": "0x0000000000020796",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "Reformatting CopyNode for Input Tensor 0 to copied_squeeze_after_[ELEMENTWISE]-[aten_ops.addmm.default]-[/fc/addmm_add]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "[ELEMENTWISE]-[aten_ops.addmm.default]-[/fc/addmm_add]_out_tensor",
    "Location": "Device",
    "Dimensions": [1,1000,1,1],
    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
  }],
  "Outputs": [
  {
    "Name": "Reformatted Input Tensor 0 to copied_squeeze_after_[ELEMENTWISE]-[aten_ops.addmm.default]-[/fc/addmm_add]",
    "Location": "Device",
    "Dimensions": [1,1000,1,1],
    "Format/Datatype": "Row major linear FP16 format"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
},{
  "Name": "copied_squeeze_after_[ELEMENTWISE]-[aten_ops.addmm.default]-[/fc/addmm_add]",
  "LayerType": "NoOp",
  "Inputs": [
  {
    "Name": "Reformatted Input Tensor 0 to copied_squeeze_after_[ELEMENTWISE]-[aten_ops.addmm.default]-[/fc/addmm_add]",
    "Location": "Device",
    "Dimensions": [1,1000,1,1],
    "Format/Datatype": "Row major linear FP16 format"
  }],
  "Outputs": [
  {
    "Name": "output0",
    "Location": "Device",
    "Dimensions": [1,1000],
    "Format/Datatype": "Row major linear FP16 format"
  }],
  "TacticValue": "0x0000000000000000",
  "StreamId": 0,
  "Metadata": ""
}],
"Bindings": ["x"
,"output0"
]}
