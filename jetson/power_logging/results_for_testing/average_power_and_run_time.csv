layer name,layer_type,average_power,average_run_time
Reformatting CopyNode for Input Tensor 0 to [CONVOLUTION]-[aten_ops.convolution.default]-[/features_0/0/convolution] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features_0/1/_native_batch_norm_legit_no_training],Reformat,5973112.247278167,0.13567360043525695
[CONVOLUTION]-[aten_ops.convolution.default]-[/features_0/0/convolution] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features_0/1/_native_batch_norm_legit_no_training],CaskConvolution,6059183.288163265,0.04306560009717941
Forced Cast ITensor (Unnamed Layer* 1) [Scale]_output from DataType.FLOAT to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features_0/2/_to_copy],NoOp,0.0,0.0
"PWN(/features_0/2/clamp_min_rhs + /features_0/2/clamp_min_rhs_broadcast, PWN(PWN(/features_0/2/clamp_max_rhs + /features_0/2/clamp_max_rhs_broadcast, [ELEMENTWISE]-[aten_ops.clamp.default]-[/features_0/2/clamp_max]), [ELEMENTWISE]-[aten_ops.clamp.default]-[/features_0/2/clamp_min]))",PointWiseV2,6065689.6,0.024083199724555016
Forced Cast ITensor (Unnamed Layer* 8) [ElementWise]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features_0/2/_to_copy_1],NoOp,0.0,0.0
[CONVOLUTION]-[aten_ops.convolution.default]-[/features/1/conv_0/0/convolution_1] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/1/conv_0/1/_native_batch_norm_legit_no_training_1],CaskConvolution,6044689.870531401,0.059731199592351916
Forced Cast ITensor (Unnamed Layer* 11) [Scale]_output from DataType.FLOAT to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/1/conv_0/2/_to_copy_2],NoOp,0.0,0.0
"PWN(/features/1/conv_0/2/clamp_1_min_rhs + /features/1/conv_0/2/clamp_1_min_rhs_broadcast, PWN(PWN(/features/1/conv_0/2/clamp_1_max_rhs + /features/1/conv_0/2/clamp_1_max_rhs_broadcast, [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/1/conv_0/2/clamp_1_max]), [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/1/conv_0/2/clamp_1_min]))",PointWiseV2,6065506.3006535955,0.022681599855422972
Forced Cast ITensor (Unnamed Layer* 18) [ElementWise]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/1/conv_0/2/_to_copy_3],NoOp,0.0,0.0
[CONVOLUTION]-[aten_ops.convolution.default]-[/features/1/conv/1/convolution_2] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/1/conv/2/_native_batch_norm_legit_no_training_2],CaskConvolution,6065124.955321638,0.024243200197815895
[CONVOLUTION]-[aten_ops.convolution.default]-[/features/2/conv_0/0/convolution_3] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/2/conv_0/1/_native_batch_norm_legit_no_training_3],CaskConvolution,6041265.8224761905,0.06330879926681518
Forced Cast ITensor (Unnamed Layer* 23) [Scale]_output from DataType.FLOAT to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/2/conv_0/2/_to_copy_4],NoOp,0.0,0.0
"PWN(/features/2/conv_0/2/clamp_2_min_rhs + /features/2/conv_0/2/clamp_2_min_rhs_broadcast, PWN(PWN(/features/2/conv_0/2/clamp_2_max_rhs + /features/2/conv_0/2/clamp_2_max_rhs_broadcast, [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/2/conv_0/2/clamp_2_max]), [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/2/conv_0/2/clamp_2_min]))",PointWiseV2,6015895.771428572,0.08997759819030762
Forced Cast ITensor (Unnamed Layer* 30) [ElementWise]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/2/conv_0/2/_to_copy_5],NoOp,0.0,0.0
[CONVOLUTION]-[aten_ops.convolution.default]-[/features/2/conv_1/0/convolution_4] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/2/conv_1/1/_native_batch_norm_legit_no_training_4],CaskConvolution,6034993.719230036,0.07017599940299987
Forced Cast ITensor (Unnamed Layer* 33) [Scale]_output from DataType.FLOAT to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/2/conv_1/2/_to_copy_6],NoOp,0.0,0.0
"PWN(/features/2/conv_1/2/clamp_3_min_rhs + /features/2/conv_1/2/clamp_3_min_rhs_broadcast, PWN(PWN(/features/2/conv_1/2/clamp_3_max_rhs + /features/2/conv_1/2/clamp_3_max_rhs_broadcast, [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/2/conv_1/2/clamp_3_max]), [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/2/conv_1/2/clamp_3_min]))",PointWiseV2,6066092.2039215695,0.021811199933290483
Forced Cast ITensor (Unnamed Layer* 40) [ElementWise]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/2/conv_1/2/_to_copy_7],NoOp,0.0,0.0
[CONVOLUTION]-[aten_ops.convolution.default]-[/features/2/conv/2/convolution_5] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/2/conv/3/_native_batch_norm_legit_no_training_5],CaskConvolution,6066211.934227726,0.023366399854421616
[CONVOLUTION]-[aten_ops.convolution.default]-[/features/3/conv_0/0/convolution_6] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/3/conv_0/1/_native_batch_norm_legit_no_training_6],CaskConvolution,6062973.8249898255,0.03553920015692711
Forced Cast ITensor (Unnamed Layer* 45) [Scale]_output from DataType.FLOAT to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/3/conv_0/2/_to_copy_8],NoOp,0.0,0.0
"PWN(/features/3/conv_0/2/clamp_4_min_rhs + /features/3/conv_0/2/clamp_4_min_rhs_broadcast, PWN(PWN(/features/3/conv_0/2/clamp_4_max_rhs + /features/3/conv_0/2/clamp_4_max_rhs_broadcast, [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/3/conv_0/2/clamp_4_max]), [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/3/conv_0/2/clamp_4_min]))",PointWiseV2,6066469.793684211,0.02558720000088215
Forced Cast ITensor (Unnamed Layer* 52) [ElementWise]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/3/conv_0/2/_to_copy_9],NoOp,0.0,0.0
[CONVOLUTION]-[aten_ops.convolution.default]-[/features/3/conv_1/0/convolution_7] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/3/conv_1/1/_native_batch_norm_legit_no_training_7],CaskConvolution,6039407.615999999,0.06533759832382202
Forced Cast ITensor (Unnamed Layer* 55) [Scale]_output from DataType.FLOAT to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/3/conv_1/2/_to_copy_10],NoOp,0.0,0.0
"PWN(/features/3/conv_1/2/clamp_5_min_rhs + /features/3/conv_1/2/clamp_5_min_rhs_broadcast, PWN(PWN(/features/3/conv_1/2/clamp_5_max_rhs + /features/3/conv_1/2/clamp_5_max_rhs_broadcast, [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/3/conv_1/2/clamp_5_max]), [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/3/conv_1/2/clamp_5_min]))",PointWiseV2,6066533.052631578,0.024582399800419808
Forced Cast ITensor (Unnamed Layer* 62) [ElementWise]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/3/conv_1/2/_to_copy_11],NoOp,0.0,0.0
[CONVOLUTION]-[aten_ops.convolution.default]-[/features/3/conv/2/convolution_8] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/3/conv/3/_native_batch_norm_legit_no_training_8] + [ELEMENTWISE]-[aten_ops.add.Tensor]-[/features/3/add],CaskConvolution,6064634.581333333,0.03240319937467575
[CONVOLUTION]-[aten_ops.convolution.default]-[/features/4/conv_0/0/convolution_9] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/4/conv_0/1/_native_batch_norm_legit_no_training_9],CaskConvolution,6063189.880341881,0.03477759957313538
Forced Cast ITensor (Unnamed Layer* 68) [Scale]_output from DataType.FLOAT to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/4/conv_0/2/_to_copy_12],NoOp,0.0,0.0
"PWN(/features/4/conv_0/2/clamp_6_min_rhs + /features/4/conv_0/2/clamp_6_min_rhs_broadcast, PWN(PWN(/features/4/conv_0/2/clamp_6_max_rhs + /features/4/conv_0/2/clamp_6_max_rhs_broadcast, [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/4/conv_0/2/clamp_6_max]), [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/4/conv_0/2/clamp_6_min]))",PointWiseV2,6066111.326315789,0.024908799678087234
Forced Cast ITensor (Unnamed Layer* 75) [ElementWise]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/4/conv_0/2/_to_copy_13],NoOp,0.0,0.0
[CONVOLUTION]-[aten_ops.convolution.default]-[/features/4/conv_1/0/convolution_10] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/4/conv_1/1/_native_batch_norm_legit_no_training_10],CaskConvolution,6065863.037229437,0.028505599498748778
Forced Cast ITensor (Unnamed Layer* 78) [Scale]_output from DataType.FLOAT to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/4/conv_1/2/_to_copy_14],NoOp,0.0,0.0
"PWN(/features/4/conv_1/2/clamp_7_min_rhs + /features/4/conv_1/2/clamp_7_min_rhs_broadcast, PWN(PWN(/features/4/conv_1/2/clamp_7_max_rhs + /features/4/conv_1/2/clamp_7_max_rhs_broadcast, [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/4/conv_1/2/clamp_7_max]), [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/4/conv_1/2/clamp_7_min]))",PointWiseV2,6064799.288888888,0.012409600056707859
Forced Cast ITensor (Unnamed Layer* 85) [ElementWise]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/4/conv_1/2/_to_copy_15],NoOp,0.0,0.0
[CONVOLUTION]-[aten_ops.convolution.default]-[/features/4/conv/2/convolution_11] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/4/conv/3/_native_batch_norm_legit_no_training_11],CaskConvolution,6065727.756190476,0.019039999693632126
[CONVOLUTION]-[aten_ops.convolution.default]-[/features/5/conv_0/0/convolution_12] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/5/conv_0/1/_native_batch_norm_legit_no_training_12],CaskConvolution,6065956.693333333,0.02072959952056408
Forced Cast ITensor (Unnamed Layer* 90) [Scale]_output from DataType.FLOAT to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/5/conv_0/2/_to_copy_16],NoOp,0.0,0.0
"PWN(/features/5/conv_0/2/clamp_8_min_rhs + /features/5/conv_0/2/clamp_8_min_rhs_broadcast, PWN(PWN(/features/5/conv_0/2/clamp_8_max_rhs + /features/5/conv_0/2/clamp_8_max_rhs_broadcast, [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/5/conv_0/2/clamp_8_max]), [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/5/conv_0/2/clamp_8_min]))",PointWiseV2,6064815.476363636,0.01402880009263754
Forced Cast ITensor (Unnamed Layer* 97) [ElementWise]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/5/conv_0/2/_to_copy_17],NoOp,0.0,0.0
[CONVOLUTION]-[aten_ops.convolution.default]-[/features/5/conv_1/0/convolution_13] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/5/conv_1/1/_native_batch_norm_legit_no_training_13],CaskConvolution,6065531.244268775,0.02919680029153824
Forced Cast ITensor (Unnamed Layer* 100) [Scale]_output from DataType.FLOAT to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/5/conv_1/2/_to_copy_18],NoOp,0.0,0.0
"PWN(/features/5/conv_1/2/clamp_9_min_rhs + /features/5/conv_1/2/clamp_9_min_rhs_broadcast, PWN(PWN(/features/5/conv_1/2/clamp_9_max_rhs + /features/5/conv_1/2/clamp_9_max_rhs_broadcast, [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/5/conv_1/2/clamp_9_max]), [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/5/conv_1/2/clamp_9_min]))",PointWiseV2,6063463.822222223,0.013024000078439712
Forced Cast ITensor (Unnamed Layer* 107) [ElementWise]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/5/conv_1/2/_to_copy_19],NoOp,0.0,0.0
[CONVOLUTION]-[aten_ops.convolution.default]-[/features/5/conv/2/convolution_14] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/5/conv/3/_native_batch_norm_legit_no_training_14] + [ELEMENTWISE]-[aten_ops.add.Tensor]-[/features/5/add_1],CaskConvolution,6065308.038095238,0.018214400112628936
[CONVOLUTION]-[aten_ops.convolution.default]-[/features/6/conv_0/0/convolution_15] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/6/conv_0/1/_native_batch_norm_legit_no_training_15],CaskConvolution,6066056.8533333335,0.019942399859428406
Forced Cast ITensor (Unnamed Layer* 113) [Scale]_output from DataType.FLOAT to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/6/conv_0/2/_to_copy_20],NoOp,0.0,0.0
"PWN(/features/6/conv_0/2/clamp_10_min_rhs + /features/6/conv_0/2/clamp_10_min_rhs_broadcast, PWN(PWN(/features/6/conv_0/2/clamp_10_max_rhs + /features/6/conv_0/2/clamp_10_max_rhs_broadcast, [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/6/conv_0/2/clamp_10_max]), [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/6/conv_0/2/clamp_10_min]))",PointWiseV2,6064596.945454545,0.013273600116372108
Forced Cast ITensor (Unnamed Layer* 120) [ElementWise]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/6/conv_0/2/_to_copy_21],NoOp,0.0,0.0
[CONVOLUTION]-[aten_ops.convolution.default]-[/features/6/conv_1/0/convolution_16] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/6/conv_1/1/_native_batch_norm_legit_no_training_16],CaskConvolution,6065784.613438735,0.029254399985074998
Forced Cast ITensor (Unnamed Layer* 123) [Scale]_output from DataType.FLOAT to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/6/conv_1/2/_to_copy_22],NoOp,0.0,0.0
"PWN(/features/6/conv_1/2/clamp_11_min_rhs + /features/6/conv_1/2/clamp_11_min_rhs_broadcast, PWN(PWN(/features/6/conv_1/2/clamp_11_max_rhs + /features/6/conv_1/2/clamp_11_max_rhs_broadcast, [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/6/conv_1/2/clamp_11_max]), [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/6/conv_1/2/clamp_11_min]))",PointWiseV2,6064305.57090909,0.01331200022250414
Forced Cast ITensor (Unnamed Layer* 130) [ElementWise]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/6/conv_1/2/_to_copy_23],NoOp,0.0,0.0
[CONVOLUTION]-[aten_ops.convolution.default]-[/features/6/conv/2/convolution_17] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/6/conv/3/_native_batch_norm_legit_no_training_17] + [ELEMENTWISE]-[aten_ops.add.Tensor]-[/features/6/add_2],CaskConvolution,6065689.6,0.018144000321626663
[CONVOLUTION]-[aten_ops.convolution.default]-[/features/7/conv_0/0/convolution_18] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/7/conv_0/1/_native_batch_norm_legit_no_training_18],CaskConvolution,6065722.986666667,0.0200959999114275
Forced Cast ITensor (Unnamed Layer* 136) [Scale]_output from DataType.FLOAT to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/7/conv_0/2/_to_copy_24],NoOp,0.0,0.0
"PWN(/features/7/conv_0/2/clamp_12_min_rhs + /features/7/conv_0/2/clamp_12_min_rhs_broadcast, PWN(PWN(/features/7/conv_0/2/clamp_12_max_rhs + /features/7/conv_0/2/clamp_12_max_rhs_broadcast, [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/7/conv_0/2/clamp_12_max]), [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/7/conv_0/2/clamp_12_min]))",PointWiseV2,6064596.945454545,0.013574400171637534
Forced Cast ITensor (Unnamed Layer* 143) [ElementWise]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/7/conv_0/2/_to_copy_25],NoOp,0.0,0.0
[CONVOLUTION]-[aten_ops.convolution.default]-[/features/7/conv_1/0/convolution_19] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/7/conv_1/1/_native_batch_norm_legit_no_training_19],CaskConvolution,6066408.697435897,0.01696640029549599
Forced Cast ITensor (Unnamed Layer* 146) [Scale]_output from DataType.FLOAT to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/7/conv_1/2/_to_copy_26],NoOp,0.0,0.0
"PWN(/features/7/conv_1/2/clamp_13_min_rhs + /features/7/conv_1/2/clamp_13_min_rhs_broadcast, PWN(PWN(/features/7/conv_1/2/clamp_13_max_rhs + /features/7/conv_1/2/clamp_13_max_rhs_broadcast, [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/7/conv_1/2/clamp_13_max]), [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/7/conv_1/2/clamp_13_min]))",PointWiseV2,6064401.828571429,0.009791999869048596
Forced Cast ITensor (Unnamed Layer* 153) [ElementWise]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/7/conv_1/2/_to_copy_27],NoOp,0.0,0.0
[CONVOLUTION]-[aten_ops.convolution.default]-[/features/7/conv/2/convolution_20] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/7/conv/3/_native_batch_norm_legit_no_training_20],CaskConvolution,6065689.6,0.01687040030956268
[CONVOLUTION]-[aten_ops.convolution.default]-[/features/8/conv_0/0/convolution_21] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/8/conv_0/1/_native_batch_norm_legit_no_training_21],CaskGemmConvolution,6066129.863736264,0.018169599771499633
Forced Cast ITensor (Unnamed Layer* 158) [Scale]_output from DataType.FLOAT to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/8/conv_0/2/_to_copy_28],NoOp,0.0,0.0
"PWN(/features/8/conv_0/2/clamp_14_min_rhs + /features/8/conv_0/2/clamp_14_min_rhs_broadcast, PWN(PWN(/features/8/conv_0/2/clamp_14_max_rhs + /features/8/conv_0/2/clamp_14_max_rhs_broadcast, [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/8/conv_0/2/clamp_14_max]), [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/8/conv_0/2/clamp_14_min]))",PointWiseV2,6065422.506666666,0.011814399808645248
Forced Cast ITensor (Unnamed Layer* 165) [ElementWise]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/8/conv_0/2/_to_copy_29],NoOp,0.0,0.0
[CONVOLUTION]-[aten_ops.convolution.default]-[/features/8/conv_1/0/convolution_22] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/8/conv_1/1/_native_batch_norm_legit_no_training_22],CaskConvolution,6066367.152941177,0.021164800226688384
Forced Cast ITensor (Unnamed Layer* 168) [Scale]_output from DataType.FLOAT to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/8/conv_1/2/_to_copy_30],NoOp,0.0,0.0
"PWN(/features/8/conv_1/2/clamp_15_min_rhs + /features/8/conv_1/2/clamp_15_min_rhs_broadcast, PWN(PWN(/features/8/conv_1/2/clamp_15_max_rhs + /features/8/conv_1/2/clamp_15_max_rhs_broadcast, [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/8/conv_1/2/clamp_15_max]), [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/8/conv_1/2/clamp_15_min]))",PointWiseV2,6065467.022222223,0.01086719986051321
Forced Cast ITensor (Unnamed Layer* 175) [ElementWise]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/8/conv_1/2/_to_copy_31],NoOp,0.0,0.0
[CONVOLUTION]-[aten_ops.convolution.default]-[/features/8/conv/2/convolution_23] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/8/conv/3/_native_batch_norm_legit_no_training_23] + [ELEMENTWISE]-[aten_ops.add.Tensor]-[/features/8/add_3],CaskGemmConvolution,6066438.415238095,0.0194496002048254
[CONVOLUTION]-[aten_ops.convolution.default]-[/features/9/conv_0/0/convolution_24] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/9/conv_0/1/_native_batch_norm_legit_no_training_24],CaskGemmConvolution,6065821.679120879,0.017478400096297263
Forced Cast ITensor (Unnamed Layer* 181) [Scale]_output from DataType.FLOAT to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/9/conv_0/2/_to_copy_32],NoOp,0.0,0.0
"PWN(/features/9/conv_0/2/clamp_16_min_rhs + /features/9/conv_0/2/clamp_16_min_rhs_broadcast, PWN(PWN(/features/9/conv_0/2/clamp_16_max_rhs + /features/9/conv_0/2/clamp_16_max_rhs_broadcast, [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/9/conv_0/2/clamp_16_max]), [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/9/conv_0/2/clamp_16_min]))",PointWiseV2,6065467.022222223,0.010783999972045422
Forced Cast ITensor (Unnamed Layer* 188) [ElementWise]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/9/conv_0/2/_to_copy_33],NoOp,0.0,0.0
[CONVOLUTION]-[aten_ops.convolution.default]-[/features/9/conv_1/0/convolution_25] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/9/conv_1/1/_native_batch_norm_legit_no_training_25],CaskConvolution,6066347.51372549,0.020185599848628045
Forced Cast ITensor (Unnamed Layer* 191) [Scale]_output from DataType.FLOAT to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/9/conv_1/2/_to_copy_34],NoOp,0.0,0.0
"PWN(/features/9/conv_1/2/clamp_17_min_rhs + /features/9/conv_1/2/clamp_17_min_rhs_broadcast, PWN(PWN(/features/9/conv_1/2/clamp_17_max_rhs + /features/9/conv_1/2/clamp_17_max_rhs_broadcast, [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/9/conv_1/2/clamp_17_max]), [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/9/conv_1/2/clamp_17_min]))",PointWiseV2,6065467.022222223,0.010943999886512757
Forced Cast ITensor (Unnamed Layer* 198) [ElementWise]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/9/conv_1/2/_to_copy_35],NoOp,0.0,0.0
[CONVOLUTION]-[aten_ops.convolution.default]-[/features/9/conv/2/convolution_26] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/9/conv/3/_native_batch_norm_legit_no_training_26] + [ELEMENTWISE]-[aten_ops.add.Tensor]-[/features/9/add_4],CaskGemmConvolution,6065997.784615384,0.018169599771499633
[CONVOLUTION]-[aten_ops.convolution.default]-[/features/10/conv_0/0/convolution_27] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/10/conv_0/1/_native_batch_norm_legit_no_training_27],CaskGemmConvolution,6066790.259340659,0.017299200221896172
Forced Cast ITensor (Unnamed Layer* 204) [Scale]_output from DataType.FLOAT to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/10/conv_0/2/_to_copy_36],NoOp,0.0,0.0
"PWN(/features/10/conv_0/2/clamp_18_min_rhs + /features/10/conv_0/2/clamp_18_min_rhs_broadcast, PWN(PWN(/features/10/conv_0/2/clamp_18_max_rhs + /features/10/conv_0/2/clamp_18_max_rhs_broadcast, [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/10/conv_0/2/clamp_18_max]), [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/10/conv_0/2/clamp_18_min]))",PointWiseV2,6065689.6,0.01082880012691021
Forced Cast ITensor (Unnamed Layer* 211) [ElementWise]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/10/conv_0/2/_to_copy_37],NoOp,0.0,0.0
[CONVOLUTION]-[aten_ops.convolution.default]-[/features/10/conv_1/0/convolution_28] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/10/conv_1/1/_native_batch_norm_legit_no_training_28],CaskConvolution,6066591.039999999,0.020166400447487833
Forced Cast ITensor (Unnamed Layer* 214) [Scale]_output from DataType.FLOAT to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/10/conv_1/2/_to_copy_38],NoOp,0.0,0.0
"PWN(/features/10/conv_1/2/clamp_19_min_rhs + /features/10/conv_1/2/clamp_19_min_rhs_broadcast, PWN(PWN(/features/10/conv_1/2/clamp_19_max_rhs + /features/10/conv_1/2/clamp_19_max_rhs_broadcast, [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/10/conv_1/2/clamp_19_max]), [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/10/conv_1/2/clamp_19_min]))",PointWiseV2,6064799.288888888,0.010912000015377999
Forced Cast ITensor (Unnamed Layer* 221) [ElementWise]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/10/conv_1/2/_to_copy_39],NoOp,0.0,0.0
[CONVOLUTION]-[aten_ops.convolution.default]-[/features/10/conv/2/convolution_29] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/10/conv/3/_native_batch_norm_legit_no_training_29] + [ELEMENTWISE]-[aten_ops.add.Tensor]-[/features/10/add_5],CaskGemmConvolution,6065997.784615384,0.018047999963164328
[CONVOLUTION]-[aten_ops.convolution.default]-[/features/11/conv_0/0/convolution_30] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/11/conv_0/1/_native_batch_norm_legit_no_training_30],CaskGemmConvolution,6066790.259340659,0.017215999960899352
Forced Cast ITensor (Unnamed Layer* 227) [Scale]_output from DataType.FLOAT to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/11/conv_0/2/_to_copy_40],NoOp,0.0,0.0
"PWN(/features/11/conv_0/2/clamp_20_min_rhs + /features/11/conv_0/2/clamp_20_min_rhs_broadcast, PWN(PWN(/features/11/conv_0/2/clamp_20_max_rhs + /features/11/conv_0/2/clamp_20_max_rhs_broadcast, [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/11/conv_0/2/clamp_20_max]), [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/11/conv_0/2/clamp_20_min]))",PointWiseV2,6065689.6,0.010848000086843968
Forced Cast ITensor (Unnamed Layer* 234) [ElementWise]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/11/conv_0/2/_to_copy_41],NoOp,0.0,0.0
[CONVOLUTION]-[aten_ops.convolution.default]-[/features/11/conv_1/0/convolution_31] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/11/conv_1/1/_native_batch_norm_legit_no_training_31],CaskConvolution,6066357.333333334,0.020364800468087196
Forced Cast ITensor (Unnamed Layer* 237) [Scale]_output from DataType.FLOAT to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/11/conv_1/2/_to_copy_42],NoOp,0.0,0.0
"PWN(/features/11/conv_1/2/clamp_21_min_rhs + /features/11/conv_1/2/clamp_21_min_rhs_broadcast, PWN(PWN(/features/11/conv_1/2/clamp_21_max_rhs + /features/11/conv_1/2/clamp_21_max_rhs_broadcast, [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/11/conv_1/2/clamp_21_max]), [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/11/conv_1/2/clamp_21_min]))",PointWiseV2,6065689.6,0.010675199888646602
Forced Cast ITensor (Unnamed Layer* 244) [ElementWise]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/11/conv_1/2/_to_copy_43],NoOp,0.0,0.0
[CONVOLUTION]-[aten_ops.convolution.default]-[/features/11/conv/2/convolution_32] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/11/conv/3/_native_batch_norm_legit_no_training_32],CaskGemmConvolution,6066490.880000001,0.020083199813961984
[CONVOLUTION]-[aten_ops.convolution.default]-[/features/12/conv_0/0/convolution_33] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/12/conv_0/1/_native_batch_norm_legit_no_training_33],CaskConvolution,6066313.974025974,0.027980799600481988
Forced Cast ITensor (Unnamed Layer* 249) [Scale]_output from DataType.FLOAT to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/12/conv_0/2/_to_copy_44],NoOp,0.0,0.0
"PWN(/features/12/conv_0/2/clamp_22_min_rhs + /features/12/conv_0/2/clamp_22_min_rhs_broadcast, PWN(PWN(/features/12/conv_0/2/clamp_22_max_rhs + /features/12/conv_0/2/clamp_22_max_rhs_broadcast, [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/12/conv_0/2/clamp_22_max]), [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/12/conv_0/2/clamp_22_min]))",PointWiseV2,6065835.287272727,0.013318400084972381
Forced Cast ITensor (Unnamed Layer* 256) [ElementWise]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/12/conv_0/2/_to_copy_45],NoOp,0.0,0.0
[CONVOLUTION]-[aten_ops.convolution.default]-[/features/12/conv_1/0/convolution_34] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/12/conv_1/1/_native_batch_norm_legit_no_training_34],CaskConvolution,6066954.778947368,0.02473600022494793
Forced Cast ITensor (Unnamed Layer* 259) [Scale]_output from DataType.FLOAT to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/12/conv_1/2/_to_copy_46],NoOp,0.0,0.0
"PWN(/features/12/conv_1/2/clamp_23_min_rhs + /features/12/conv_1/2/clamp_23_min_rhs_broadcast, PWN(PWN(/features/12/conv_1/2/clamp_23_max_rhs + /features/12/conv_1/2/clamp_23_max_rhs_broadcast, [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/12/conv_1/2/clamp_23_max]), [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/12/conv_1/2/clamp_23_min]))",PointWiseV2,6064977.351111111,0.012057600170373916
Forced Cast ITensor (Unnamed Layer* 266) [ElementWise]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/12/conv_1/2/_to_copy_47],NoOp,0.0,0.0
[CONVOLUTION]-[aten_ops.convolution.default]-[/features/12/conv/2/convolution_35] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/12/conv/3/_native_batch_norm_legit_no_training_35] + [ELEMENTWISE]-[aten_ops.add.Tensor]-[/features/12/add_6],CaskGemmConvolution,6066936.690196078,0.021785599738359453
[CONVOLUTION]-[aten_ops.convolution.default]-[/features/13/conv_0/0/convolution_36] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/13/conv_0/1/_native_batch_norm_legit_no_training_36],CaskConvolution,6066638.484210527,0.02547840029001236
Forced Cast ITensor (Unnamed Layer* 272) [Scale]_output from DataType.FLOAT to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/13/conv_0/2/_to_copy_48],NoOp,0.0,0.0
"PWN(/features/13/conv_0/2/clamp_24_min_rhs + /features/13/conv_0/2/clamp_24_min_rhs_broadcast, PWN(PWN(/features/13/conv_0/2/clamp_24_max_rhs + /features/13/conv_0/2/clamp_24_max_rhs_broadcast, [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/13/conv_0/2/clamp_24_max]), [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/13/conv_0/2/clamp_24_min]))",PointWiseV2,6065511.537777778,0.012281600013375282
Forced Cast ITensor (Unnamed Layer* 279) [ElementWise]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/13/conv_0/2/_to_copy_49],NoOp,0.0,0.0
[CONVOLUTION]-[aten_ops.convolution.default]-[/features/13/conv_1/0/convolution_37] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/13/conv_1/1/_native_batch_norm_legit_no_training_37],CaskConvolution,6066697.057309941,0.02457600012421608
Forced Cast ITensor (Unnamed Layer* 282) [Scale]_output from DataType.FLOAT to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/13/conv_1/2/_to_copy_50],NoOp,0.0,0.0
"PWN(/features/13/conv_1/2/clamp_25_min_rhs + /features/13/conv_1/2/clamp_25_min_rhs_broadcast, PWN(PWN(/features/13/conv_1/2/clamp_25_max_rhs + /features/13/conv_1/2/clamp_25_max_rhs_broadcast, [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/13/conv_1/2/clamp_25_max]), [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/13/conv_1/2/clamp_25_min]))",PointWiseV2,6065578.311111111,0.011648000217974186
Forced Cast ITensor (Unnamed Layer* 289) [ElementWise]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/13/conv_1/2/_to_copy_51],NoOp,0.0,0.0
[CONVOLUTION]-[aten_ops.convolution.default]-[/features/13/conv/2/convolution_38] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/13/conv/3/_native_batch_norm_legit_no_training_38] + [ELEMENTWISE]-[aten_ops.add.Tensor]-[/features/13/add_7],CaskGemmConvolution,6066838.4941176465,0.02172800004482269
[CONVOLUTION]-[aten_ops.convolution.default]-[/features/14/conv_0/0/convolution_39] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/14/conv_0/1/_native_batch_norm_legit_no_training_39],CaskConvolution,6066427.621052632,0.025574399903416634
Forced Cast ITensor (Unnamed Layer* 295) [Scale]_output from DataType.FLOAT to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/14/conv_0/2/_to_copy_52],NoOp,0.0,0.0
"PWN(/features/14/conv_0/2/clamp_26_min_rhs + /features/14/conv_0/2/clamp_26_min_rhs_broadcast, PWN(PWN(/features/14/conv_0/2/clamp_26_max_rhs + /features/14/conv_0/2/clamp_26_max_rhs_broadcast, [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/14/conv_0/2/clamp_26_max]), [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/14/conv_0/2/clamp_26_min]))",PointWiseV2,6065578.311111111,0.011737600155174732
Forced Cast ITensor (Unnamed Layer* 302) [ElementWise]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/14/conv_0/2/_to_copy_53],NoOp,0.0,0.0
[CONVOLUTION]-[aten_ops.convolution.default]-[/features/14/conv_1/0/convolution_40] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/14/conv_1/1/_native_batch_norm_legit_no_training_40],CaskConvolution,6066570.127472528,0.01703039966523647
Forced Cast ITensor (Unnamed Layer* 305) [Scale]_output from DataType.FLOAT to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/14/conv_1/2/_to_copy_54],NoOp,0.0,0.0
"PWN(/features/14/conv_1/2/clamp_27_min_rhs + /features/14/conv_1/2/clamp_27_min_rhs_broadcast, PWN(PWN(/features/14/conv_1/2/clamp_27_max_rhs + /features/14/conv_1/2/clamp_27_max_rhs_broadcast, [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/14/conv_1/2/clamp_27_max]), [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/14/conv_1/2/clamp_27_min]))",PointWiseV2,6065498.81904762,0.009350399859249592
Forced Cast ITensor (Unnamed Layer* 312) [ElementWise]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/14/conv_1/2/_to_copy_55],NoOp,0.0,0.0
[CONVOLUTION]-[aten_ops.convolution.default]-[/features/14/conv/2/convolution_41] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/14/conv/3/_native_batch_norm_legit_no_training_41],CaskConvolution,6066490.88,0.018879999965429307
[CONVOLUTION]-[aten_ops.convolution.default]-[/features/15/conv_0/0/convolution_42] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/15/conv_0/1/_native_batch_norm_legit_no_training_42],CaskConvolution,6067193.205916753,0.023500799760222436
Forced Cast ITensor (Unnamed Layer* 317) [Scale]_output from DataType.FLOAT to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/15/conv_0/2/_to_copy_56],NoOp,0.0,0.0
"PWN(/features/15/conv_0/2/clamp_28_min_rhs + /features/15/conv_0/2/clamp_28_min_rhs_broadcast, PWN(PWN(/features/15/conv_0/2/clamp_28_max_rhs + /features/15/conv_0/2/clamp_28_max_rhs_broadcast, [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/15/conv_0/2/clamp_28_max]), [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/15/conv_0/2/clamp_28_min]))",PointWiseV2,6066548.114285714,0.010227200202643871
Forced Cast ITensor (Unnamed Layer* 324) [ElementWise]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/15/conv_0/2/_to_copy_57],NoOp,0.0,0.0
[CONVOLUTION]-[aten_ops.convolution.default]-[/features/15/conv_1/0/convolution_43] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/15/conv_1/1/_native_batch_norm_legit_no_training_43],CaskConvolution,6066951.689377289,0.01839359998703003
Forced Cast ITensor (Unnamed Layer* 327) [Scale]_output from DataType.FLOAT to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/15/conv_1/2/_to_copy_58],NoOp,0.0,0.0
"PWN(/features/15/conv_1/2/clamp_29_min_rhs + /features/15/conv_1/2/clamp_29_min_rhs_broadcast, PWN(PWN(/features/15/conv_1/2/clamp_29_max_rhs + /features/15/conv_1/2/clamp_29_max_rhs_broadcast, [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/15/conv_1/2/clamp_29_max]), [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/15/conv_1/2/clamp_29_min]))",PointWiseV2,6066548.114285714,0.009830399975180626
Forced Cast ITensor (Unnamed Layer* 334) [ElementWise]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/15/conv_1/2/_to_copy_59],NoOp,0.0,0.0
[CONVOLUTION]-[aten_ops.convolution.default]-[/features/15/conv/2/convolution_44] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/15/conv/3/_native_batch_norm_legit_no_training_44] + [ELEMENTWISE]-[aten_ops.add.Tensor]-[/features/15/add_8],CaskConvolution,6067025.066666666,0.02197120003402233
[CONVOLUTION]-[aten_ops.convolution.default]-[/features/16/conv_0/0/convolution_45] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/16/conv_0/1/_native_batch_norm_legit_no_training_45],CaskConvolution,6067025.066666666,0.021663999930024148
Forced Cast ITensor (Unnamed Layer* 340) [Scale]_output from DataType.FLOAT to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/16/conv_0/2/_to_copy_60],NoOp,0.0,0.0
"PWN(/features/16/conv_0/2/clamp_30_min_rhs + /features/16/conv_0/2/clamp_30_min_rhs_broadcast, PWN(PWN(/features/16/conv_0/2/clamp_30_max_rhs + /features/16/conv_0/2/clamp_30_max_rhs_broadcast, [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/16/conv_0/2/clamp_30_max]), [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/16/conv_0/2/clamp_30_min]))",PointWiseV2,6066548.114285714,0.010092800110578537
Forced Cast ITensor (Unnamed Layer* 347) [ElementWise]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/16/conv_0/2/_to_copy_61],NoOp,0.0,0.0
[CONVOLUTION]-[aten_ops.convolution.default]-[/features/16/conv_1/0/convolution_46] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/16/conv_1/1/_native_batch_norm_legit_no_training_46],CaskConvolution,6066643.5047619045,0.01854719966650009
Forced Cast ITensor (Unnamed Layer* 350) [Scale]_output from DataType.FLOAT to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/16/conv_1/2/_to_copy_62],NoOp,0.0,0.0
"PWN(/features/16/conv_1/2/clamp_31_min_rhs + /features/16/conv_1/2/clamp_31_min_rhs_broadcast, PWN(PWN(/features/16/conv_1/2/clamp_31_max_rhs + /features/16/conv_1/2/clamp_31_max_rhs_broadcast, [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/16/conv_1/2/clamp_31_max]), [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/16/conv_1/2/clamp_31_min]))",PointWiseV2,6066548.114285714,0.009804799966514111
Forced Cast ITensor (Unnamed Layer* 357) [ElementWise]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/16/conv_1/2/_to_copy_63],NoOp,0.0,0.0
[CONVOLUTION]-[aten_ops.convolution.default]-[/features/16/conv/2/convolution_47] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/16/conv/3/_native_batch_norm_legit_no_training_47] + [ELEMENTWISE]-[aten_ops.add.Tensor]-[/features/16/add_9],CaskConvolution,6067103.623529412,0.022246399894356728
[CONVOLUTION]-[aten_ops.convolution.default]-[/features/17/conv_0/0/convolution_48] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/17/conv_0/1/_native_batch_norm_legit_no_training_48],CaskConvolution,6067192.0,0.02157440036535263
Forced Cast ITensor (Unnamed Layer* 363) [Scale]_output from DataType.FLOAT to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/17/conv_0/2/_to_copy_64],NoOp,0.0,0.0
"PWN(/features/17/conv_0/2/clamp_32_min_rhs + /features/17/conv_0/2/clamp_32_min_rhs_broadcast, PWN(PWN(/features/17/conv_0/2/clamp_32_max_rhs + /features/17/conv_0/2/clamp_32_max_rhs_broadcast, [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/17/conv_0/2/clamp_32_max]), [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/17/conv_0/2/clamp_32_min]))",PointWiseV2,6065689.6,0.009062400087714195
Forced Cast ITensor (Unnamed Layer* 370) [ElementWise]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/17/conv_0/2/_to_copy_65],NoOp,0.0,0.0
[CONVOLUTION]-[aten_ops.convolution.default]-[/features/17/conv_1/0/convolution_49] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/17/conv_1/1/_native_batch_norm_legit_no_training_49],CaskConvolution,6066490.88,0.018566399812698364
Forced Cast ITensor (Unnamed Layer* 373) [Scale]_output from DataType.FLOAT to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features/17/conv_1/2/_to_copy_66],NoOp,0.0,0.0
"PWN(/features/17/conv_1/2/clamp_33_min_rhs + /features/17/conv_1/2/clamp_33_min_rhs_broadcast, PWN(PWN(/features/17/conv_1/2/clamp_33_max_rhs + /features/17/conv_1/2/clamp_33_max_rhs_broadcast, [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/17/conv_1/2/clamp_33_max]), [ELEMENTWISE]-[aten_ops.clamp.default]-[/features/17/conv_1/2/clamp_33_min]))",PointWiseV2,6066548.114285714,0.009113599732518195
Forced Cast ITensor (Unnamed Layer* 380) [ElementWise]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features/17/conv_1/2/_to_copy_67],NoOp,0.0,0.0
[CONVOLUTION]-[aten_ops.convolution.default]-[/features/17/conv/2/convolution_50] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features/17/conv/3/_native_batch_norm_legit_no_training_50],CaskGemmConvolution,6066279.286580087,0.027583999559283257
[CONVOLUTION]-[aten_ops.convolution.default]-[/features_18/0/convolution_51] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/features_18/1/_native_batch_norm_legit_no_training_51],CaskGemmConvolution,6064833.15942029,0.031084800511598586
Forced Cast ITensor (Unnamed Layer* 385) [Scale]_output from DataType.FLOAT to DataType.FLOAT - [aten_ops.torch.ops.aten._to_copy.default]-[/features_18/2/_to_copy_68],NoOp,0.0,0.0
"PWN(/features_18/2/clamp_34_min_rhs + /features_18/2/clamp_34_min_rhs_broadcast, PWN(PWN(/features_18/2/clamp_34_max_rhs + /features_18/2/clamp_34_max_rhs_broadcast, [ELEMENTWISE]-[aten_ops.clamp.default]-[/features_18/2/clamp_34_max]), [ELEMENTWISE]-[aten_ops.clamp.default]-[/features_18/2/clamp_34_min]))",PointWiseV2,6066023.466666667,0.011270399950444699
Forced Cast ITensor (Unnamed Layer* 392) [ElementWise]_output_clamp.default from DataType.FLOAT to DataType.HALF - [aten_ops.torch.ops.aten._to_copy.default]-[/features_18/2/_to_copy_69],NoOp,0.0,0.0
[REDUCE]-[aten_ops.mean.dim]-[__/mean],CaskPooling,6067219.316363636,0.013612799905240535
Reformatting CopyNode for Input Tensor 0 to [SHUFFLE]-[aten_ops.reshape.default]-[reshape_default],NoOp,0.0,0.0
[SHUFFLE]-[aten_ops.reshape.default]-[reshape_default],NoOp,0.0,0.0
Forced Cast ITensor (Unnamed Layer* 395) [Shuffle]_output from DataType.FLOAT to DataType.FLOAT - [aten_ops.torch.ops.aten.clone.default]-[/classifier/0/clone],NoOp,0.0,0.0
reshape_before_[MATRIX_MULTIPLY]-[aten_ops.addmm.default]-[/classifier/1/addmm_mm],NoOp,0.0,0.0
Reformatting CopyNode for Input Tensor 0 to [MATRIX_MULTIPLY]-[aten_ops.addmm.default]-[/classifier/1/addmm_mm] + /classifier/1/addmm_constant_0 + /classifier/1/addmm_add_lhs_broadcast + unsqueeze_node_after_/classifier/1/addmm_constant_0 + /classifier/1/addmm_add_lhs_broadcast_(Unnamed Layer* 400) [Shuffle]_output + [ELEMENTWISE]-[aten_ops.addmm.default]-[/classifier/1/addmm_add],NoOp,0.0,0.0
[MATRIX_MULTIPLY]-[aten_ops.addmm.default]-[/classifier/1/addmm_mm] + /classifier/1/addmm_constant_0 + /classifier/1/addmm_add_lhs_broadcast + unsqueeze_node_after_/classifier/1/addmm_constant_0 + /classifier/1/addmm_add_lhs_broadcast_(Unnamed Layer* 400) [Shuffle]_output + [ELEMENTWISE]-[aten_ops.addmm.default]-[/classifier/1/addmm_add],CaskGemmConvolution,6040680.948257786,0.06036479994654655
Reformatting CopyNode for Input Tensor 0 to copied_squeeze_after_[ELEMENTWISE]-[aten_ops.addmm.default]-[/classifier/1/addmm_add],NoOp,0.0,0.0
copied_squeeze_after_[ELEMENTWISE]-[aten_ops.addmm.default]-[/classifier/1/addmm_add],NoOp,0.0,0.0
