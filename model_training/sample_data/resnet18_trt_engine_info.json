{
    "Layers": [
        {
            "Name": "Reformatting CopyNode for Input Tensor 0 to [CONVOLUTION]-[aten_ops.convolution.default]-[/conv1/convolution] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/bn1/_native_batch_norm_legit_no_training] + [RELU]-[aten_ops.relu.default]-[/relu/relu]",
            "LayerType": "Reformat",
            "Inputs": [
                {
                    "Name": "x",
                    "Location": "Device",
                    "Dimensions": [
                        1,
                        3,
                        224,
                        224
                    ],
                    "Format/Datatype": "Row major linear FP16 format"
                }
            ],
            "Outputs": [
                {
                    "Name": "Reformatted Input Tensor 0 to [CONVOLUTION]-[aten_ops.convolution.default]-[/conv1/convolution] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/bn1/_native_batch_norm_legit_no_training] + [RELU]-[aten_ops.relu.default]-[/relu/relu]",
                    "Location": "Device",
                    "Dimensions": [
                        1,
                        3,
                        224,
                        224
                    ],
                    "Format/Datatype": "Channel major FP16 format where channel % 4 == 0"
                }
            ],
            "ParameterType": "Reformat",
            "Origin": "REFORMAT",
            "TacticValue": "0x00000000000003ea",
            "StreamId": 0,
            "Metadata": ""
        },
        {
            "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/conv1/convolution] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/bn1/_native_batch_norm_legit_no_training] + [RELU]-[aten_ops.relu.default]-[/relu/relu]",
            "LayerType": "CaskConvolution",
            "Inputs": [
                {
                    "Name": "Reformatted Input Tensor 0 to [CONVOLUTION]-[aten_ops.convolution.default]-[/conv1/convolution] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/bn1/_native_batch_norm_legit_no_training] + [RELU]-[aten_ops.relu.default]-[/relu/relu]",
                    "Location": "Device",
                    "Dimensions": [
                        1,
                        3,
                        224,
                        224
                    ],
                    "Format/Datatype": "Channel major FP16 format where channel % 4 == 0"
                }
            ],
            "Outputs": [
                {
                    "Name": "(Unnamed Layer* 2) [Activation]_output",
                    "Location": "Device",
                    "Dimensions": [
                        1,
                        64,
                        112,
                        112
                    ],
                    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
                }
            ],
            "ParameterType": "Convolution",
            "Kernel": [
                7,
                7
            ],
            "PaddingMode": "kEXPLICIT_ROUND_DOWN",
            "PrePadding": [
                3,
                3
            ],
            "PostPadding": [
                3,
                3
            ],
            "Stride": [
                2,
                2
            ],
            "Dilation": [
                1,
                1
            ],
            "OutMaps": 64,
            "Groups": 1,
            "Weights": {
                "Type": "Half",
                "Count": 9408
            },
            "Bias": {
                "Type": "Half",
                "Count": 64
            },
            "HasSparseWeights": 0,
            "HasDynamicFilter": 0,
            "HasDynamicBias": 0,
            "HasResidual": 0,
            "ConvXAsActInputIdx": -1,
            "BiasAsActInputIdx": -1,
            "ResAsActInputIdx": -1,
            "Activation": "RELU",
            "HasBias": 1,
            "HasReLU": 1,
            "TacticName": "sm80_xmma_fprop_image_first_layer_f16f16_f32_f16_nhwckrsc_nhwc_hmma_k64c4r7s7_stride2x2_tile16x64x64_tensor1688",
            "TacticValue": "0x4341b9cbb7197a9b",
            "StreamId": 0,
            "Metadata": ""
        },
        {
            "Name": "[MAX]-[aten_ops.max_pool2d.default]-[max_pool2d_default]",
            "LayerType": "CaskPooling",
            "Inputs": [
                {
                    "Name": "(Unnamed Layer* 2) [Activation]_output",
                    "Location": "Device",
                    "Dimensions": [
                        1,
                        64,
                        112,
                        112
                    ],
                    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
                }
            ],
            "Outputs": [
                {
                    "Name": "(Unnamed Layer* 3) [Pooling]_output",
                    "Location": "Device",
                    "Dimensions": [
                        1,
                        64,
                        56,
                        56
                    ],
                    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
                }
            ],
            "ParameterType": "Pooling",
            "PoolingType": "MAX",
            "WindowSize": [
                3,
                3
            ],
            "PaddingMode": "kEXPLICIT_ROUND_DOWN",
            "PrePadding": [
                1,
                1
            ],
            "PostPadding": [
                1,
                1
            ],
            "Stride": [
                2,
                2
            ],
            "BlendFactor": 0,
            "AverageCountExcludesPadding": 1,
            "TacticName": "sm50_xmma_pooling_coalescedC_NHWC_kMAX_3_False",
            "TacticValue": "0xdb415cba6b0e9137",
            "StreamId": 0,
            "Metadata": ""
        },
        {
            "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/layer1/0/conv1/convolution_1] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/layer1/0/bn1/_native_batch_norm_legit_no_training_1] + [RELU]-[aten_ops.relu.default]-[/layer1/0/relu/relu_1]",
            "LayerType": "CaskConvolution",
            "Inputs": [
                {
                    "Name": "(Unnamed Layer* 3) [Pooling]_output",
                    "Location": "Device",
                    "Dimensions": [
                        1,
                        64,
                        56,
                        56
                    ],
                    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
                }
            ],
            "Outputs": [
                {
                    "Name": "(Unnamed Layer* 6) [Activation]_output",
                    "Location": "Device",
                    "Dimensions": [
                        1,
                        64,
                        56,
                        56
                    ],
                    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
                }
            ],
            "ParameterType": "Convolution",
            "Kernel": [
                3,
                3
            ],
            "PaddingMode": "kEXPLICIT_ROUND_DOWN",
            "PrePadding": [
                1,
                1
            ],
            "PostPadding": [
                1,
                1
            ],
            "Stride": [
                1,
                1
            ],
            "Dilation": [
                1,
                1
            ],
            "OutMaps": 64,
            "Groups": 1,
            "Weights": {
                "Type": "Half",
                "Count": 36864
            },
            "Bias": {
                "Type": "Half",
                "Count": 64
            },
            "HasSparseWeights": 0,
            "HasDynamicFilter": 0,
            "HasDynamicBias": 0,
            "HasResidual": 0,
            "ConvXAsActInputIdx": -1,
            "BiasAsActInputIdx": -1,
            "ResAsActInputIdx": -1,
            "Activation": "RELU",
            "HasBias": 1,
            "HasReLU": 1,
            "TacticName": "sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3",
            "TacticValue": "0x529f4431bdae94f5",
            "StreamId": 0,
            "Metadata": ""
        },
        {
            "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/layer1/0/conv2/convolution_2] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/layer1/0/bn2/_native_batch_norm_legit_no_training_2] + [ELEMENTWISE]-[aten_ops.add.Tensor]-[/layer1/0/add] + [RELU]-[aten_ops.relu.default]-[/layer1/0/relu/relu_2]",
            "LayerType": "CaskConvolution",
            "Inputs": [
                {
                    "Name": "(Unnamed Layer* 6) [Activation]_output",
                    "Location": "Device",
                    "Dimensions": [
                        1,
                        64,
                        56,
                        56
                    ],
                    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
                },
                {
                    "Name": "(Unnamed Layer* 3) [Pooling]_output",
                    "Location": "Device",
                    "Dimensions": [
                        1,
                        64,
                        56,
                        56
                    ],
                    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
                }
            ],
            "Outputs": [
                {
                    "Name": "(Unnamed Layer* 10) [Activation]_output",
                    "Location": "Device",
                    "Dimensions": [
                        1,
                        64,
                        56,
                        56
                    ],
                    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
                }
            ],
            "ParameterType": "Convolution",
            "Kernel": [
                3,
                3
            ],
            "PaddingMode": "kEXPLICIT_ROUND_DOWN",
            "PrePadding": [
                1,
                1
            ],
            "PostPadding": [
                1,
                1
            ],
            "Stride": [
                1,
                1
            ],
            "Dilation": [
                1,
                1
            ],
            "OutMaps": 64,
            "Groups": 1,
            "Weights": {
                "Type": "Half",
                "Count": 36864
            },
            "Bias": {
                "Type": "Half",
                "Count": 64
            },
            "HasSparseWeights": 0,
            "HasDynamicFilter": 0,
            "HasDynamicBias": 0,
            "HasResidual": 1,
            "ConvXAsActInputIdx": -1,
            "BiasAsActInputIdx": -1,
            "ResAsActInputIdx": -1,
            "Activation": "RELU",
            "HasBias": 1,
            "HasReLU": 1,
            "TacticName": "sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3",
            "TacticValue": "0x529f4431bdae94f5",
            "StreamId": 0,
            "Metadata": ""
        },
        {
            "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/layer1/1/conv1/convolution_3] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/layer1/1/bn1/_native_batch_norm_legit_no_training_3] + [RELU]-[aten_ops.relu.default]-[/layer1/1/relu/relu_3]",
            "LayerType": "CaskConvolution",
            "Inputs": [
                {
                    "Name": "(Unnamed Layer* 10) [Activation]_output",
                    "Location": "Device",
                    "Dimensions": [
                        1,
                        64,
                        56,
                        56
                    ],
                    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
                }
            ],
            "Outputs": [
                {
                    "Name": "(Unnamed Layer* 13) [Activation]_output",
                    "Location": "Device",
                    "Dimensions": [
                        1,
                        64,
                        56,
                        56
                    ],
                    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
                }
            ],
            "ParameterType": "Convolution",
            "Kernel": [
                3,
                3
            ],
            "PaddingMode": "kEXPLICIT_ROUND_DOWN",
            "PrePadding": [
                1,
                1
            ],
            "PostPadding": [
                1,
                1
            ],
            "Stride": [
                1,
                1
            ],
            "Dilation": [
                1,
                1
            ],
            "OutMaps": 64,
            "Groups": 1,
            "Weights": {
                "Type": "Half",
                "Count": 36864
            },
            "Bias": {
                "Type": "Half",
                "Count": 64
            },
            "HasSparseWeights": 0,
            "HasDynamicFilter": 0,
            "HasDynamicBias": 0,
            "HasResidual": 0,
            "ConvXAsActInputIdx": -1,
            "BiasAsActInputIdx": -1,
            "ResAsActInputIdx": -1,
            "Activation": "RELU",
            "HasBias": 1,
            "HasReLU": 1,
            "TacticName": "sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3",
            "TacticValue": "0x529f4431bdae94f5",
            "StreamId": 0,
            "Metadata": ""
        },
        {
            "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/layer1/1/conv2/convolution_4] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/layer1/1/bn2/_native_batch_norm_legit_no_training_4] + [ELEMENTWISE]-[aten_ops.add.Tensor]-[/layer1/1/add_1] + [RELU]-[aten_ops.relu.default]-[/layer1/1/relu/relu_4]",
            "LayerType": "CaskConvolution",
            "Inputs": [
                {
                    "Name": "(Unnamed Layer* 13) [Activation]_output",
                    "Location": "Device",
                    "Dimensions": [
                        1,
                        64,
                        56,
                        56
                    ],
                    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
                },
                {
                    "Name": "(Unnamed Layer* 10) [Activation]_output",
                    "Location": "Device",
                    "Dimensions": [
                        1,
                        64,
                        56,
                        56
                    ],
                    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
                }
            ],
            "Outputs": [
                {
                    "Name": "(Unnamed Layer* 17) [Activation]_output",
                    "Location": "Device",
                    "Dimensions": [
                        1,
                        64,
                        56,
                        56
                    ],
                    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
                }
            ],
            "ParameterType": "Convolution",
            "Kernel": [
                3,
                3
            ],
            "PaddingMode": "kEXPLICIT_ROUND_DOWN",
            "PrePadding": [
                1,
                1
            ],
            "PostPadding": [
                1,
                1
            ],
            "Stride": [
                1,
                1
            ],
            "Dilation": [
                1,
                1
            ],
            "OutMaps": 64,
            "Groups": 1,
            "Weights": {
                "Type": "Half",
                "Count": 36864
            },
            "Bias": {
                "Type": "Half",
                "Count": 64
            },
            "HasSparseWeights": 0,
            "HasDynamicFilter": 0,
            "HasDynamicBias": 0,
            "HasResidual": 1,
            "ConvXAsActInputIdx": -1,
            "BiasAsActInputIdx": -1,
            "ResAsActInputIdx": -1,
            "Activation": "RELU",
            "HasBias": 1,
            "HasReLU": 1,
            "TacticName": "sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize256x64x32_stage3_warpsize4x1x1_g1_tensor16x8x16_t1r3s3",
            "TacticValue": "0x529f4431bdae94f5",
            "StreamId": 0,
            "Metadata": ""
        },
        {
            "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/layer2/0/conv1/convolution_5] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/layer2/0/bn1/_native_batch_norm_legit_no_training_5] + [RELU]-[aten_ops.relu.default]-[/layer2/0/relu/relu_5]",
            "LayerType": "CaskConvolution",
            "Inputs": [
                {
                    "Name": "(Unnamed Layer* 17) [Activation]_output",
                    "Location": "Device",
                    "Dimensions": [
                        1,
                        64,
                        56,
                        56
                    ],
                    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
                }
            ],
            "Outputs": [
                {
                    "Name": "(Unnamed Layer* 20) [Activation]_output",
                    "Location": "Device",
                    "Dimensions": [
                        1,
                        128,
                        28,
                        28
                    ],
                    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
                }
            ],
            "ParameterType": "Convolution",
            "Kernel": [
                3,
                3
            ],
            "PaddingMode": "kEXPLICIT_ROUND_DOWN",
            "PrePadding": [
                1,
                1
            ],
            "PostPadding": [
                1,
                1
            ],
            "Stride": [
                2,
                2
            ],
            "Dilation": [
                1,
                1
            ],
            "OutMaps": 128,
            "Groups": 1,
            "Weights": {
                "Type": "Half",
                "Count": 73728
            },
            "Bias": {
                "Type": "Half",
                "Count": 128
            },
            "HasSparseWeights": 0,
            "HasDynamicFilter": 0,
            "HasDynamicBias": 0,
            "HasResidual": 0,
            "ConvXAsActInputIdx": -1,
            "BiasAsActInputIdx": -1,
            "ResAsActInputIdx": -1,
            "Activation": "RELU",
            "HasBias": 1,
            "HasReLU": 1,
            "TacticName": "sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3",
            "TacticValue": "0x60c3421152ef8e10",
            "StreamId": 0,
            "Metadata": ""
        },
        {
            "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/layer2/0/downsample/0/convolution_7] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/layer2/0/downsample/1/_native_batch_norm_legit_no_training_7]",
            "LayerType": "CaskConvolution",
            "Inputs": [
                {
                    "Name": "(Unnamed Layer* 17) [Activation]_output",
                    "Location": "Device",
                    "Dimensions": [
                        1,
                        64,
                        56,
                        56
                    ],
                    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
                }
            ],
            "Outputs": [
                {
                    "Name": "(Unnamed Layer* 24) [Scale]_output",
                    "Location": "Device",
                    "Dimensions": [
                        1,
                        128,
                        28,
                        28
                    ],
                    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
                }
            ],
            "ParameterType": "Convolution",
            "Kernel": [
                1,
                1
            ],
            "PaddingMode": "kEXPLICIT_ROUND_DOWN",
            "PrePadding": [
                0,
                0
            ],
            "PostPadding": [
                0,
                0
            ],
            "Stride": [
                2,
                2
            ],
            "Dilation": [
                1,
                1
            ],
            "OutMaps": 128,
            "Groups": 1,
            "Weights": {
                "Type": "Half",
                "Count": 8192
            },
            "Bias": {
                "Type": "Half",
                "Count": 128
            },
            "HasSparseWeights": 0,
            "HasDynamicFilter": 0,
            "HasDynamicBias": 0,
            "HasResidual": 0,
            "ConvXAsActInputIdx": -1,
            "BiasAsActInputIdx": -1,
            "ResAsActInputIdx": -1,
            "Activation": "NONE",
            "HasBias": 1,
            "HasReLU": 0,
            "TacticName": "sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16",
            "TacticValue": "0xafd1e8bf6bd3d638",
            "StreamId": 0,
            "Metadata": ""
        },
        {
            "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/layer2/0/conv2/convolution_6] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/layer2/0/bn2/_native_batch_norm_legit_no_training_6] + [ELEMENTWISE]-[aten_ops.add.Tensor]-[/layer2/0/add_2] + [RELU]-[aten_ops.relu.default]-[/layer2/0/relu/relu_6]",
            "LayerType": "CaskConvolution",
            "Inputs": [
                {
                    "Name": "(Unnamed Layer* 20) [Activation]_output",
                    "Location": "Device",
                    "Dimensions": [
                        1,
                        128,
                        28,
                        28
                    ],
                    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
                },
                {
                    "Name": "(Unnamed Layer* 24) [Scale]_output",
                    "Location": "Device",
                    "Dimensions": [
                        1,
                        128,
                        28,
                        28
                    ],
                    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
                }
            ],
            "Outputs": [
                {
                    "Name": "(Unnamed Layer* 26) [Activation]_output",
                    "Location": "Device",
                    "Dimensions": [
                        1,
                        128,
                        28,
                        28
                    ],
                    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
                }
            ],
            "ParameterType": "Convolution",
            "Kernel": [
                3,
                3
            ],
            "PaddingMode": "kEXPLICIT_ROUND_DOWN",
            "PrePadding": [
                1,
                1
            ],
            "PostPadding": [
                1,
                1
            ],
            "Stride": [
                1,
                1
            ],
            "Dilation": [
                1,
                1
            ],
            "OutMaps": 128,
            "Groups": 1,
            "Weights": {
                "Type": "Half",
                "Count": 147456
            },
            "Bias": {
                "Type": "Half",
                "Count": 128
            },
            "HasSparseWeights": 0,
            "HasDynamicFilter": 0,
            "HasDynamicBias": 0,
            "HasResidual": 1,
            "ConvXAsActInputIdx": -1,
            "BiasAsActInputIdx": -1,
            "ResAsActInputIdx": -1,
            "Activation": "RELU",
            "HasBias": 1,
            "HasReLU": 1,
            "TacticName": "sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3",
            "TacticValue": "0x60c3421152ef8e10",
            "StreamId": 0,
            "Metadata": ""
        },
        {
            "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/layer2/1/conv1/convolution_8] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/layer2/1/bn1/_native_batch_norm_legit_no_training_8] + [RELU]-[aten_ops.relu.default]-[/layer2/1/relu/relu_7]",
            "LayerType": "CaskConvolution",
            "Inputs": [
                {
                    "Name": "(Unnamed Layer* 26) [Activation]_output",
                    "Location": "Device",
                    "Dimensions": [
                        1,
                        128,
                        28,
                        28
                    ],
                    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
                }
            ],
            "Outputs": [
                {
                    "Name": "(Unnamed Layer* 29) [Activation]_output",
                    "Location": "Device",
                    "Dimensions": [
                        1,
                        128,
                        28,
                        28
                    ],
                    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
                }
            ],
            "ParameterType": "Convolution",
            "Kernel": [
                3,
                3
            ],
            "PaddingMode": "kEXPLICIT_ROUND_DOWN",
            "PrePadding": [
                1,
                1
            ],
            "PostPadding": [
                1,
                1
            ],
            "Stride": [
                1,
                1
            ],
            "Dilation": [
                1,
                1
            ],
            "OutMaps": 128,
            "Groups": 1,
            "Weights": {
                "Type": "Half",
                "Count": 147456
            },
            "Bias": {
                "Type": "Half",
                "Count": 128
            },
            "HasSparseWeights": 0,
            "HasDynamicFilter": 0,
            "HasDynamicBias": 0,
            "HasResidual": 0,
            "ConvXAsActInputIdx": -1,
            "BiasAsActInputIdx": -1,
            "ResAsActInputIdx": -1,
            "Activation": "RELU",
            "HasBias": 1,
            "HasReLU": 1,
            "TacticName": "sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3",
            "TacticValue": "0x60c3421152ef8e10",
            "StreamId": 0,
            "Metadata": ""
        },
        {
            "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/layer2/1/conv2/convolution_9] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/layer2/1/bn2/_native_batch_norm_legit_no_training_9] + [ELEMENTWISE]-[aten_ops.add.Tensor]-[/layer2/1/add_3] + [RELU]-[aten_ops.relu.default]-[/layer2/1/relu/relu_8]",
            "LayerType": "CaskConvolution",
            "Inputs": [
                {
                    "Name": "(Unnamed Layer* 29) [Activation]_output",
                    "Location": "Device",
                    "Dimensions": [
                        1,
                        128,
                        28,
                        28
                    ],
                    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
                },
                {
                    "Name": "(Unnamed Layer* 26) [Activation]_output",
                    "Location": "Device",
                    "Dimensions": [
                        1,
                        128,
                        28,
                        28
                    ],
                    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
                }
            ],
            "Outputs": [
                {
                    "Name": "(Unnamed Layer* 33) [Activation]_output",
                    "Location": "Device",
                    "Dimensions": [
                        1,
                        128,
                        28,
                        28
                    ],
                    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
                }
            ],
            "ParameterType": "Convolution",
            "Kernel": [
                3,
                3
            ],
            "PaddingMode": "kEXPLICIT_ROUND_DOWN",
            "PrePadding": [
                1,
                1
            ],
            "PostPadding": [
                1,
                1
            ],
            "Stride": [
                1,
                1
            ],
            "Dilation": [
                1,
                1
            ],
            "OutMaps": 128,
            "Groups": 1,
            "Weights": {
                "Type": "Half",
                "Count": 147456
            },
            "Bias": {
                "Type": "Half",
                "Count": 128
            },
            "HasSparseWeights": 0,
            "HasDynamicFilter": 0,
            "HasDynamicBias": 0,
            "HasResidual": 1,
            "ConvXAsActInputIdx": -1,
            "BiasAsActInputIdx": -1,
            "ResAsActInputIdx": -1,
            "Activation": "RELU",
            "HasBias": 1,
            "HasReLU": 1,
            "TacticName": "sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x128x32_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3",
            "TacticValue": "0x60c3421152ef8e10",
            "StreamId": 0,
            "Metadata": ""
        },
        {
            "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/layer3/0/conv1/convolution_10] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/layer3/0/bn1/_native_batch_norm_legit_no_training_10] + [RELU]-[aten_ops.relu.default]-[/layer3/0/relu/relu_9]",
            "LayerType": "CaskConvolution",
            "Inputs": [
                {
                    "Name": "(Unnamed Layer* 33) [Activation]_output",
                    "Location": "Device",
                    "Dimensions": [
                        1,
                        128,
                        28,
                        28
                    ],
                    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
                }
            ],
            "Outputs": [
                {
                    "Name": "(Unnamed Layer* 36) [Activation]_output",
                    "Location": "Device",
                    "Dimensions": [
                        1,
                        256,
                        14,
                        14
                    ],
                    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
                }
            ],
            "ParameterType": "Convolution",
            "Kernel": [
                3,
                3
            ],
            "PaddingMode": "kEXPLICIT_ROUND_DOWN",
            "PrePadding": [
                1,
                1
            ],
            "PostPadding": [
                1,
                1
            ],
            "Stride": [
                2,
                2
            ],
            "Dilation": [
                1,
                1
            ],
            "OutMaps": 256,
            "Groups": 1,
            "Weights": {
                "Type": "Half",
                "Count": 294912
            },
            "Bias": {
                "Type": "Half",
                "Count": 256
            },
            "HasSparseWeights": 0,
            "HasDynamicFilter": 0,
            "HasDynamicBias": 0,
            "HasResidual": 0,
            "ConvXAsActInputIdx": -1,
            "BiasAsActInputIdx": -1,
            "ResAsActInputIdx": -1,
            "Activation": "RELU",
            "HasBias": 1,
            "HasReLU": 1,
            "TacticName": "sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage3_warpsize2x2x1_g1_tensor16x8x16_t1r3s3_aACCESS",
            "TacticValue": "0x263a38afd75e3a43",
            "StreamId": 0,
            "Metadata": ""
        },
        {
            "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/layer3/0/downsample/0/convolution_12] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/layer3/0/downsample/1/_native_batch_norm_legit_no_training_12]",
            "LayerType": "CaskConvolution",
            "Inputs": [
                {
                    "Name": "(Unnamed Layer* 33) [Activation]_output",
                    "Location": "Device",
                    "Dimensions": [
                        1,
                        128,
                        28,
                        28
                    ],
                    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
                }
            ],
            "Outputs": [
                {
                    "Name": "(Unnamed Layer* 40) [Scale]_output",
                    "Location": "Device",
                    "Dimensions": [
                        1,
                        256,
                        14,
                        14
                    ],
                    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
                }
            ],
            "ParameterType": "Convolution",
            "Kernel": [
                1,
                1
            ],
            "PaddingMode": "kEXPLICIT_ROUND_DOWN",
            "PrePadding": [
                0,
                0
            ],
            "PostPadding": [
                0,
                0
            ],
            "Stride": [
                2,
                2
            ],
            "Dilation": [
                1,
                1
            ],
            "OutMaps": 256,
            "Groups": 1,
            "Weights": {
                "Type": "Half",
                "Count": 32768
            },
            "Bias": {
                "Type": "Half",
                "Count": 256
            },
            "HasSparseWeights": 0,
            "HasDynamicFilter": 0,
            "HasDynamicBias": 0,
            "HasResidual": 0,
            "ConvXAsActInputIdx": -1,
            "BiasAsActInputIdx": -1,
            "ResAsActInputIdx": -1,
            "Activation": "NONE",
            "HasBias": 1,
            "HasReLU": 0,
            "TacticName": "sm80_xmma_fprop_implicit_gemm_indexed_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x128x32_stage5_warpsize2x2x1_g1_tensor16x8x16",
            "TacticValue": "0xafd1e8bf6bd3d638",
            "StreamId": 0,
            "Metadata": ""
        },
        {
            "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/layer3/0/conv2/convolution_11] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/layer3/0/bn2/_native_batch_norm_legit_no_training_11] + [ELEMENTWISE]-[aten_ops.add.Tensor]-[/layer3/0/add_4] + [RELU]-[aten_ops.relu.default]-[/layer3/0/relu/relu_10]",
            "LayerType": "CaskConvolution",
            "Inputs": [
                {
                    "Name": "(Unnamed Layer* 36) [Activation]_output",
                    "Location": "Device",
                    "Dimensions": [
                        1,
                        256,
                        14,
                        14
                    ],
                    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
                },
                {
                    "Name": "(Unnamed Layer* 40) [Scale]_output",
                    "Location": "Device",
                    "Dimensions": [
                        1,
                        256,
                        14,
                        14
                    ],
                    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
                }
            ],
            "Outputs": [
                {
                    "Name": "(Unnamed Layer* 42) [Activation]_output",
                    "Location": "Device",
                    "Dimensions": [
                        1,
                        256,
                        14,
                        14
                    ],
                    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
                }
            ],
            "ParameterType": "Convolution",
            "Kernel": [
                3,
                3
            ],
            "PaddingMode": "kEXPLICIT_ROUND_DOWN",
            "PrePadding": [
                1,
                1
            ],
            "PostPadding": [
                1,
                1
            ],
            "Stride": [
                1,
                1
            ],
            "Dilation": [
                1,
                1
            ],
            "OutMaps": 256,
            "Groups": 1,
            "Weights": {
                "Type": "Half",
                "Count": 589824
            },
            "Bias": {
                "Type": "Half",
                "Count": 256
            },
            "HasSparseWeights": 0,
            "HasDynamicFilter": 0,
            "HasDynamicBias": 0,
            "HasResidual": 1,
            "ConvXAsActInputIdx": -1,
            "BiasAsActInputIdx": -1,
            "ResAsActInputIdx": -1,
            "Activation": "RELU",
            "HasBias": 1,
            "HasReLU": 1,
            "TacticName": "sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage5_warpsize2x1x2_g1_tensor16x8x16_aACCESS",
            "TacticValue": "0x8bfc020aee55171f",
            "StreamId": 0,
            "Metadata": ""
        },
        {
            "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/layer3/1/conv1/convolution_13] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/layer3/1/bn1/_native_batch_norm_legit_no_training_13] + [RELU]-[aten_ops.relu.default]-[/layer3/1/relu/relu_11]",
            "LayerType": "CaskConvolution",
            "Inputs": [
                {
                    "Name": "(Unnamed Layer* 42) [Activation]_output",
                    "Location": "Device",
                    "Dimensions": [
                        1,
                        256,
                        14,
                        14
                    ],
                    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
                }
            ],
            "Outputs": [
                {
                    "Name": "(Unnamed Layer* 45) [Activation]_output",
                    "Location": "Device",
                    "Dimensions": [
                        1,
                        256,
                        14,
                        14
                    ],
                    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
                }
            ],
            "ParameterType": "Convolution",
            "Kernel": [
                3,
                3
            ],
            "PaddingMode": "kEXPLICIT_ROUND_DOWN",
            "PrePadding": [
                1,
                1
            ],
            "PostPadding": [
                1,
                1
            ],
            "Stride": [
                1,
                1
            ],
            "Dilation": [
                1,
                1
            ],
            "OutMaps": 256,
            "Groups": 1,
            "Weights": {
                "Type": "Half",
                "Count": 589824
            },
            "Bias": {
                "Type": "Half",
                "Count": 256
            },
            "HasSparseWeights": 0,
            "HasDynamicFilter": 0,
            "HasDynamicBias": 0,
            "HasResidual": 0,
            "ConvXAsActInputIdx": -1,
            "BiasAsActInputIdx": -1,
            "ResAsActInputIdx": -1,
            "Activation": "RELU",
            "HasBias": 1,
            "HasReLU": 1,
            "TacticName": "sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage5_warpsize2x1x2_g1_tensor16x8x16_aACCESS",
            "TacticValue": "0x8bfc020aee55171f",
            "StreamId": 0,
            "Metadata": ""
        },
        {
            "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/layer3/1/conv2/convolution_14] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/layer3/1/bn2/_native_batch_norm_legit_no_training_14] + [ELEMENTWISE]-[aten_ops.add.Tensor]-[/layer3/1/add_5] + [RELU]-[aten_ops.relu.default]-[/layer3/1/relu/relu_12]",
            "LayerType": "CaskConvolution",
            "Inputs": [
                {
                    "Name": "(Unnamed Layer* 45) [Activation]_output",
                    "Location": "Device",
                    "Dimensions": [
                        1,
                        256,
                        14,
                        14
                    ],
                    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
                },
                {
                    "Name": "(Unnamed Layer* 42) [Activation]_output",
                    "Location": "Device",
                    "Dimensions": [
                        1,
                        256,
                        14,
                        14
                    ],
                    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
                }
            ],
            "Outputs": [
                {
                    "Name": "(Unnamed Layer* 49) [Activation]_output",
                    "Location": "Device",
                    "Dimensions": [
                        1,
                        256,
                        14,
                        14
                    ],
                    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
                }
            ],
            "ParameterType": "Convolution",
            "Kernel": [
                3,
                3
            ],
            "PaddingMode": "kEXPLICIT_ROUND_DOWN",
            "PrePadding": [
                1,
                1
            ],
            "PostPadding": [
                1,
                1
            ],
            "Stride": [
                1,
                1
            ],
            "Dilation": [
                1,
                1
            ],
            "OutMaps": 256,
            "Groups": 1,
            "Weights": {
                "Type": "Half",
                "Count": 589824
            },
            "Bias": {
                "Type": "Half",
                "Count": 256
            },
            "HasSparseWeights": 0,
            "HasDynamicFilter": 0,
            "HasDynamicBias": 0,
            "HasResidual": 1,
            "ConvXAsActInputIdx": -1,
            "BiasAsActInputIdx": -1,
            "ResAsActInputIdx": -1,
            "Activation": "RELU",
            "HasBias": 1,
            "HasReLU": 1,
            "TacticName": "sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize128x64x64_stage5_warpsize2x1x2_g1_tensor16x8x16_aACCESS",
            "TacticValue": "0x8bfc020aee55171f",
            "StreamId": 0,
            "Metadata": ""
        },
        {
            "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/layer4/0/conv1/convolution_15] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/layer4/0/bn1/_native_batch_norm_legit_no_training_15] + [RELU]-[aten_ops.relu.default]-[/layer4/0/relu/relu_13]",
            "LayerType": "CaskConvolution",
            "Inputs": [
                {
                    "Name": "(Unnamed Layer* 49) [Activation]_output",
                    "Location": "Device",
                    "Dimensions": [
                        1,
                        256,
                        14,
                        14
                    ],
                    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
                }
            ],
            "Outputs": [
                {
                    "Name": "(Unnamed Layer* 52) [Activation]_output",
                    "Location": "Device",
                    "Dimensions": [
                        1,
                        512,
                        7,
                        7
                    ],
                    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
                }
            ],
            "ParameterType": "Convolution",
            "Kernel": [
                3,
                3
            ],
            "PaddingMode": "kEXPLICIT_ROUND_DOWN",
            "PrePadding": [
                1,
                1
            ],
            "PostPadding": [
                1,
                1
            ],
            "Stride": [
                2,
                2
            ],
            "Dilation": [
                1,
                1
            ],
            "OutMaps": 512,
            "Groups": 1,
            "Weights": {
                "Type": "Half",
                "Count": 1179648
            },
            "Bias": {
                "Type": "Half",
                "Count": 512
            },
            "HasSparseWeights": 0,
            "HasDynamicFilter": 0,
            "HasDynamicBias": 0,
            "HasResidual": 0,
            "ConvXAsActInputIdx": -1,
            "BiasAsActInputIdx": -1,
            "ResAsActInputIdx": -1,
            "Activation": "RELU",
            "HasBias": 1,
            "HasReLU": 1,
            "TacticName": "sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3",
            "TacticValue": "0x31d93dc22d2af081",
            "StreamId": 0,
            "Metadata": ""
        },
        {
            "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/layer4/0/downsample/0/convolution_17] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/layer4/0/downsample/1/_native_batch_norm_legit_no_training_17]",
            "LayerType": "CaskConvolution",
            "Inputs": [
                {
                    "Name": "(Unnamed Layer* 49) [Activation]_output",
                    "Location": "Device",
                    "Dimensions": [
                        1,
                        256,
                        14,
                        14
                    ],
                    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
                }
            ],
            "Outputs": [
                {
                    "Name": "(Unnamed Layer* 56) [Scale]_output",
                    "Location": "Device",
                    "Dimensions": [
                        1,
                        512,
                        7,
                        7
                    ],
                    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
                }
            ],
            "ParameterType": "Convolution",
            "Kernel": [
                1,
                1
            ],
            "PaddingMode": "kEXPLICIT_ROUND_DOWN",
            "PrePadding": [
                0,
                0
            ],
            "PostPadding": [
                0,
                0
            ],
            "Stride": [
                2,
                2
            ],
            "Dilation": [
                1,
                1
            ],
            "OutMaps": 512,
            "Groups": 1,
            "Weights": {
                "Type": "Half",
                "Count": 131072
            },
            "Bias": {
                "Type": "Half",
                "Count": 512
            },
            "HasSparseWeights": 0,
            "HasDynamicFilter": 0,
            "HasDynamicBias": 0,
            "HasResidual": 0,
            "ConvXAsActInputIdx": -1,
            "BiasAsActInputIdx": -1,
            "ResAsActInputIdx": -1,
            "Activation": "NONE",
            "HasBias": 1,
            "HasReLU": 0,
            "TacticName": "sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x1x2_g1_tensor16x8x16_aACCESS",
            "TacticValue": "0x841c601dec2a75bc",
            "StreamId": 0,
            "Metadata": ""
        },
        {
            "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/layer4/0/conv2/convolution_16] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/layer4/0/bn2/_native_batch_norm_legit_no_training_16] + [ELEMENTWISE]-[aten_ops.add.Tensor]-[/layer4/0/add_6] + [RELU]-[aten_ops.relu.default]-[/layer4/0/relu/relu_14]",
            "LayerType": "CaskConvolution",
            "Inputs": [
                {
                    "Name": "(Unnamed Layer* 52) [Activation]_output",
                    "Location": "Device",
                    "Dimensions": [
                        1,
                        512,
                        7,
                        7
                    ],
                    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
                },
                {
                    "Name": "(Unnamed Layer* 56) [Scale]_output",
                    "Location": "Device",
                    "Dimensions": [
                        1,
                        512,
                        7,
                        7
                    ],
                    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
                }
            ],
            "Outputs": [
                {
                    "Name": "(Unnamed Layer* 58) [Activation]_output",
                    "Location": "Device",
                    "Dimensions": [
                        1,
                        512,
                        7,
                        7
                    ],
                    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
                }
            ],
            "ParameterType": "Convolution",
            "Kernel": [
                3,
                3
            ],
            "PaddingMode": "kEXPLICIT_ROUND_DOWN",
            "PrePadding": [
                1,
                1
            ],
            "PostPadding": [
                1,
                1
            ],
            "Stride": [
                1,
                1
            ],
            "Dilation": [
                1,
                1
            ],
            "OutMaps": 512,
            "Groups": 1,
            "Weights": {
                "Type": "Half",
                "Count": 2359296
            },
            "Bias": {
                "Type": "Half",
                "Count": 512
            },
            "HasSparseWeights": 0,
            "HasDynamicFilter": 0,
            "HasDynamicBias": 0,
            "HasResidual": 1,
            "ConvXAsActInputIdx": -1,
            "BiasAsActInputIdx": -1,
            "ResAsActInputIdx": -1,
            "Activation": "RELU",
            "HasBias": 1,
            "HasReLU": 1,
            "TacticName": "sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3_aACCESS",
            "TacticValue": "0x30e8a8d7a953e5e9",
            "StreamId": 0,
            "Metadata": ""
        },
        {
            "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/layer4/1/conv1/convolution_18] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/layer4/1/bn1/_native_batch_norm_legit_no_training_18] + [RELU]-[aten_ops.relu.default]-[/layer4/1/relu/relu_15]",
            "LayerType": "CaskConvolution",
            "Inputs": [
                {
                    "Name": "(Unnamed Layer* 58) [Activation]_output",
                    "Location": "Device",
                    "Dimensions": [
                        1,
                        512,
                        7,
                        7
                    ],
                    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
                }
            ],
            "Outputs": [
                {
                    "Name": "(Unnamed Layer* 61) [Activation]_output",
                    "Location": "Device",
                    "Dimensions": [
                        1,
                        512,
                        7,
                        7
                    ],
                    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
                }
            ],
            "ParameterType": "Convolution",
            "Kernel": [
                3,
                3
            ],
            "PaddingMode": "kEXPLICIT_ROUND_DOWN",
            "PrePadding": [
                1,
                1
            ],
            "PostPadding": [
                1,
                1
            ],
            "Stride": [
                1,
                1
            ],
            "Dilation": [
                1,
                1
            ],
            "OutMaps": 512,
            "Groups": 1,
            "Weights": {
                "Type": "Half",
                "Count": 2359296
            },
            "Bias": {
                "Type": "Half",
                "Count": 512
            },
            "HasSparseWeights": 0,
            "HasDynamicFilter": 0,
            "HasDynamicBias": 0,
            "HasResidual": 0,
            "ConvXAsActInputIdx": -1,
            "BiasAsActInputIdx": -1,
            "ResAsActInputIdx": -1,
            "Activation": "RELU",
            "HasBias": 1,
            "HasReLU": 1,
            "TacticName": "sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x1x2_g1_tensor16x8x16_aACCESS",
            "TacticValue": "0x841c601dec2a75bc",
            "StreamId": 0,
            "Metadata": ""
        },
        {
            "Name": "[CONVOLUTION]-[aten_ops.convolution.default]-[/layer4/1/conv2/convolution_19] + [SCALE]-[aten_ops._native_batch_norm_legit_no_training.default]-[/layer4/1/bn2/_native_batch_norm_legit_no_training_19] + [ELEMENTWISE]-[aten_ops.add.Tensor]-[/layer4/1/add_7] + [RELU]-[aten_ops.relu.default]-[/layer4/1/relu/relu_16]",
            "LayerType": "CaskConvolution",
            "Inputs": [
                {
                    "Name": "(Unnamed Layer* 61) [Activation]_output",
                    "Location": "Device",
                    "Dimensions": [
                        1,
                        512,
                        7,
                        7
                    ],
                    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
                },
                {
                    "Name": "(Unnamed Layer* 58) [Activation]_output",
                    "Location": "Device",
                    "Dimensions": [
                        1,
                        512,
                        7,
                        7
                    ],
                    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
                }
            ],
            "Outputs": [
                {
                    "Name": "(Unnamed Layer* 65) [Activation]_output",
                    "Location": "Device",
                    "Dimensions": [
                        1,
                        512,
                        7,
                        7
                    ],
                    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
                }
            ],
            "ParameterType": "Convolution",
            "Kernel": [
                3,
                3
            ],
            "PaddingMode": "kEXPLICIT_ROUND_DOWN",
            "PrePadding": [
                1,
                1
            ],
            "PostPadding": [
                1,
                1
            ],
            "Stride": [
                1,
                1
            ],
            "Dilation": [
                1,
                1
            ],
            "OutMaps": 512,
            "Groups": 1,
            "Weights": {
                "Type": "Half",
                "Count": 2359296
            },
            "Bias": {
                "Type": "Half",
                "Count": 512
            },
            "HasSparseWeights": 0,
            "HasDynamicFilter": 0,
            "HasDynamicBias": 0,
            "HasResidual": 1,
            "ConvXAsActInputIdx": -1,
            "BiasAsActInputIdx": -1,
            "ResAsActInputIdx": -1,
            "Activation": "RELU",
            "HasBias": 1,
            "HasReLU": 1,
            "TacticName": "sm80_xmma_fprop_implicit_gemm_f16f16_f16f16_f16_nhwckrsc_nhwc_tilesize64x64x64_stage4_warpsize2x2x1_g1_tensor16x8x16_t1r3s3_aACCESS",
            "TacticValue": "0x30e8a8d7a953e5e9",
            "StreamId": 0,
            "Metadata": ""
        },
        {
            "Name": "[REDUCE]-[aten_ops.mean.dim]-[/avgpool/mean]",
            "LayerType": "CaskPooling",
            "Inputs": [
                {
                    "Name": "(Unnamed Layer* 65) [Activation]_output",
                    "Location": "Device",
                    "Dimensions": [
                        1,
                        512,
                        7,
                        7
                    ],
                    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
                }
            ],
            "Outputs": [
                {
                    "Name": "(Unnamed Layer* 66) [Reduce]_output",
                    "Location": "Device",
                    "Dimensions": [
                        1,
                        512,
                        1,
                        1
                    ],
                    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
                }
            ],
            "ParameterType": "Pooling",
            "PoolingType": "AVERAGE",
            "WindowSize": [
                7,
                7
            ],
            "PaddingMode": "kEXPLICIT_ROUND_DOWN",
            "PrePadding": [
                0,
                0
            ],
            "PostPadding": [
                0,
                0
            ],
            "Stride": [
                1,
                1
            ],
            "BlendFactor": 0,
            "AverageCountExcludesPadding": 1,
            "TacticName": "sm50_xmma_pooling_fw_4d_FP16FP32NHWC_Average_FastDiv_CAlign4",
            "TacticValue": "0x56d7b61f084f251e",
            "StreamId": 0,
            "Metadata": ""
        },
        {
            "Name": "[MATRIX_MULTIPLY]-[aten_ops.addmm.default]-[/fc/addmm_mm] + /fc/addmm_constant_0 + /fc/addmm_add_lhs_broadcast + unsqueeze_node_after_/fc/addmm_constant_0 + /fc/addmm_add_lhs_broadcast_(Unnamed Layer* 71) [Shuffle]_output + [ELEMENTWISE]-[aten_ops.addmm.default]-[/fc/addmm_add]",
            "LayerType": "CaskGemmConvolution",
            "Inputs": [
                {
                    "Name": "(Unnamed Layer* 66) [Reduce]_output",
                    "Location": "Device",
                    "Dimensions": [
                        1,
                        512,
                        1,
                        1
                    ],
                    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
                }
            ],
            "Outputs": [
                {
                    "Name": "[ELEMENTWISE]-[aten_ops.addmm.default]-[/fc/addmm_add]_out_tensor",
                    "Location": "Device",
                    "Dimensions": [
                        1,
                        1000,
                        1,
                        1
                    ],
                    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
                }
            ],
            "ParameterType": "Convolution",
            "Kernel": [
                1,
                1
            ],
            "PaddingMode": "kEXPLICIT_ROUND_DOWN",
            "PrePadding": [
                0,
                0
            ],
            "PostPadding": [
                0,
                0
            ],
            "Stride": [
                1,
                1
            ],
            "Dilation": [
                1,
                1
            ],
            "OutMaps": 1000,
            "Groups": 1,
            "Weights": {
                "Type": "Half",
                "Count": 512000
            },
            "Bias": {
                "Type": "Half",
                "Count": 1000
            },
            "HasSparseWeights": 0,
            "HasDynamicFilter": 0,
            "HasDynamicBias": 0,
            "HasResidual": 0,
            "ConvXAsActInputIdx": -1,
            "BiasAsActInputIdx": -1,
            "ResAsActInputIdx": -1,
            "Activation": "NONE",
            "TacticName": "sm70_xmma_gemm_as_conv1x1_f16f16_f16_f16_tn_n_simt_small_batch_bias_relu",
            "TacticValue": "0x00000000000202e2",
            "StreamId": 0,
            "Metadata": ""
        },
        {
            "Name": "Reformatting CopyNode for Input Tensor 0 to copied_squeeze_after_[ELEMENTWISE]-[aten_ops.addmm.default]-[/fc/addmm_add]",
            "LayerType": "NoOp",
            "Inputs": [
                {
                    "Name": "[ELEMENTWISE]-[aten_ops.addmm.default]-[/fc/addmm_add]_out_tensor",
                    "Location": "Device",
                    "Dimensions": [
                        1,
                        1000,
                        1,
                        1
                    ],
                    "Format/Datatype": "Channel major FP16 format where channel % 8 == 0"
                }
            ],
            "Outputs": [
                {
                    "Name": "Reformatted Input Tensor 0 to copied_squeeze_after_[ELEMENTWISE]-[aten_ops.addmm.default]-[/fc/addmm_add]",
                    "Location": "Device",
                    "Dimensions": [
                        1,
                        1000,
                        1,
                        1
                    ],
                    "Format/Datatype": "Row major linear FP16 format"
                }
            ],
            "TacticValue": "0x0000000000000000",
            "StreamId": 0,
            "Metadata": ""
        },
        {
            "Name": "copied_squeeze_after_[ELEMENTWISE]-[aten_ops.addmm.default]-[/fc/addmm_add]",
            "LayerType": "NoOp",
            "Inputs": [
                {
                    "Name": "Reformatted Input Tensor 0 to copied_squeeze_after_[ELEMENTWISE]-[aten_ops.addmm.default]-[/fc/addmm_add]",
                    "Location": "Device",
                    "Dimensions": [
                        1,
                        1000,
                        1,
                        1
                    ],
                    "Format/Datatype": "Row major linear FP16 format"
                }
            ],
            "Outputs": [
                {
                    "Name": "output0",
                    "Location": "Device",
                    "Dimensions": [
                        1,
                        1000
                    ],
                    "Format/Datatype": "Row major linear FP16 format"
                }
            ],
            "TacticValue": "0x0000000000000000",
            "StreamId": 0,
            "Metadata": ""
        }
    ],
    "Bindings": [
        "x",
        "output0"
    ]
}