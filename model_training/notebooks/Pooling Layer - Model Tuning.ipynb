{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add directory above current directory to path\n",
    "import sys; sys.path.insert(0, '..')\n",
    "\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "import optuna\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "from config.pooling_features import *\n",
    "from data_preparation.io_utils import read_yaml_file\n",
    "from dataset.dataset_builder import DatasetBuilder\n",
    "from model.model_builder import ModelBuilder\n",
    "from model.model_tuning import OptunaOptimizer\n",
    "from pipeline.trainer import Trainer\n",
    "\n",
    "CONFIG_PATH = Path('../config/config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Configuration\n",
    "config = read_yaml_file(CONFIG_PATH)\n",
    "data_config = config['data']\n",
    "print(data_config)\n",
    "conv_pattern = \"**/pooling.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_builder = DatasetBuilder(features=POOLING_FEATURES)\n",
    "pooling_dataset = dataset_builder.create_dataset(\n",
    "            data_dir=Path('../training_data'),\n",
    "            test_models=data_config[\"test_models\"],\n",
    "            pattern=conv_pattern,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of training samples: {len(pooling_dataset.train.input_features)}\")\n",
    "print(f\"Number of testing samples: {len(pooling_dataset.test.input_features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Baseline Models\n",
    "\n",
    "\n",
    "Baseline models for power and runtime models, we will use the mean of train dataset as prediction.\n",
    "\n",
    "\n",
    "### Baseline Result\n",
    "\n",
    "Test dataset RMSPE Power : 148.92%\n",
    "\n",
    "Test dataset RMSPE Runtime: 119.05%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(data_config=data_config, model_config=config['model'], features=POOLING_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_power = pooling_dataset.train.power.mean()\n",
    "target = pooling_dataset.test.power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(trainer.eval_metrics(actual=target, pred=[mean_power]*len(target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_runtime = pooling_dataset.train.runtime.mean()\n",
    "target = pooling_dataset.test.runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(trainer.eval_metrics(actual=target, pred=[mean_runtime]*len(target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Power\n",
    "\n",
    "[Optuna](https://optuna.org/) library is used to perform hyperparameter tuning for power model.\n",
    "\n",
    "Best trial configuration\n",
    "\n",
    "```json\n",
    "FrozenTrial(number=95, state=1, values=[0.6680917520358511], datetime_start=datetime.datetime(2024, 11, 26, 17, 8, 9, 332736), datetime_complete=datetime.datetime(2024, 11, 26, 17, 8, 9, 523217), params={'degree': 1, 'log_scale': False, 'special_features': True, 'scalers': 'minmax', 'max_iter': 30832, 'n_alphas': 218, 'fit_intercept': True, 'positive': True}, user_attrs={'testing_mean_absolute_error': 1.219418214248221, 'testing_mean_absolute_percentage_error': 0.39163211567035033, 'testing_mean_squared_error': 2.4084354893996065, 'testing_r2_score': 0.6680917520358511, 'testing_root_mean_squared_error': 1.5519134928853497, 'testing_root_mean_squared_percentage_error': 62.51547421471385}, system_attrs={}, intermediate_values={}, distributions={'degree': IntDistribution(high=4, log=False, low=1, step=1), 'log_scale': CategoricalDistribution(choices=(True, False)), 'special_features': CategoricalDistribution(choices=(True, False)), 'scalers': CategoricalDistribution(choices=('minmax', 'standard', 'robust')), 'max_iter': IntDistribution(high=50000, log=True, low=1000, step=1), 'n_alphas': IntDistribution(high=1000, log=True, low=100, step=1), 'fit_intercept': CategoricalDistribution(choices=(True, False)), 'positive': CategoricalDistribution(choices=(True, False))}, trial_id=96, value=None)\n",
    "```\n",
    "\n",
    "Test dataset metrics of best trial\n",
    "\n",
    "```json\n",
    "{\n",
    "    'testing_mean_absolute_error': 1.219418214248221, \n",
    "    'testing_mean_absolute_percentage_error': 0.39163211567035033, \n",
    "    'testing_mean_squared_error': 2.4084354893996065, \n",
    "    'testing_r2_score': 0.6680917520358511, \n",
    "    'testing_root_mean_squared_error': 1.5519134928853497, \n",
    "    'testing_root_mean_squared_percentage_error': 62.51547421471385\n",
    "}\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pooling_dataset.train.input_features.values\n",
    "y_power_train = pooling_dataset.train.power.values\n",
    "print(f\"Training shape: {X_train.shape}, {y_power_train.shape}\")\n",
    "\n",
    "X_test = pooling_dataset.test.input_features.values\n",
    "y_power_test = pooling_dataset.test.power.values\n",
    "print(f\"Testing shape: {X_test.shape}, {y_power_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_builder = ModelBuilder()\n",
    "optimizer = OptunaOptimizer(X_train=X_train, y_train=y_power_train, X_test=X_test, y_test=y_power_test, model_builder=model_builder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Ignore ConvergenceWarning from sklearn to avoid tab crash\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "# Maximise the test R^2 score during tuning\n",
    "power_study = optuna.create_study(study_name='pooling_power_model_tuning', direction=\"maximize\", storage=\"sqlite:///pooling_power_model_tuning.db\")\n",
    "# Run study for 50 trials\n",
    "power_study.optimize(partial(optimizer.objective, \n",
    "                             features_mapping=dataset_builder.features_mapping, \n",
    "                             special_terms_list=[TOTAL_POOLING_INPUT_FEATURES, TOTAL_POOLING_OUTPUT_FEATURES, TOTAL_POOLING_NO_OPS]), \n",
    "               n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the best performing pipeline\n",
    "pprint(power_study.best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.visualization import plot_optimization_history\n",
    "\n",
    "plot_optimization_history(power_study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Runtime\n",
    "\n",
    "[Optuna](https://optuna.org/) library is used to perform hyperparameter tuning for runtime model.\n",
    "\n",
    "Best trial configuration\n",
    "\n",
    "```json\n",
    "FrozenTrial(number=66, state=1, values=[0.9985231887973071], datetime_start=datetime.datetime(2024, 11, 26, 17, 11, 12, 676146), datetime_complete=datetime.datetime(2024, 11, 26, 17, 11, 19, 457365), params={'degree': 4, 'log_scale': False, 'special_features': False, 'scalers': 'minmax', 'max_iter': 36553, 'n_alphas': 441, 'fit_intercept': True, 'positive': False}, user_attrs={'testing_mean_absolute_error': 0.001255648137913211, 'testing_mean_absolute_percentage_error': 0.06084164858645989, 'testing_mean_squared_error': 2.4765212416187023e-06, 'testing_r2_score': 0.9985231887973071, 'testing_root_mean_squared_error': 0.0015736966803099961, 'testing_root_mean_squared_percentage_error': 8.505752819296054}, system_attrs={}, intermediate_values={}, distributions={'degree': IntDistribution(high=4, log=False, low=1, step=1), 'log_scale': CategoricalDistribution(choices=(True, False)), 'special_features': CategoricalDistribution(choices=(True, False)), 'scalers': CategoricalDistribution(choices=('minmax', 'standard', 'robust')), 'max_iter': IntDistribution(high=50000, log=True, low=1000, step=1), 'n_alphas': IntDistribution(high=1000, log=True, low=100, step=1), 'fit_intercept': CategoricalDistribution(choices=(True, False)), 'positive': CategoricalDistribution(choices=(True, False))}, trial_id=67, value=None)\n",
    "```\n",
    "\n",
    "Test data metrics on best trial\n",
    "\n",
    "```json\n",
    "{\n",
    "    'testing_mean_absolute_error': 0.001255648137913211, \n",
    "    'testing_mean_absolute_percentage_error': 0.06084164858645989, \n",
    "    'testing_mean_squared_error': 2.4765212416187023e-06, \n",
    "    'testing_r2_score': 0.9985231887973071, \n",
    "    'testing_root_mean_squared_error': 0.0015736966803099961, \n",
    "    'testing_root_mean_squared_percentage_error': 8.505752819296054\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pooling_dataset.train.input_features.values\n",
    "y_runtime_train = pooling_dataset.train.runtime.values\n",
    "print(f\"Training shape: {X_train.shape}, {y_runtime_train.shape}\")\n",
    "\n",
    "X_test = pooling_dataset.test.input_features.values\n",
    "y_runtime_test = pooling_dataset.test.runtime.values\n",
    "print(f\"Testing shape: {X_test.shape}, {y_runtime_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_builder = ModelBuilder()\n",
    "optimizer = OptunaOptimizer(X_train=X_train, y_train=y_runtime_train, X_test=X_test, y_test=y_runtime_test, model_builder=model_builder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Ignore ConvergenceWarning from sklearn to avoid tab crash\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "# Maximise the test R^2 score during tuning\n",
    "runtime_study = optuna.create_study(study_name='pooling_runtime_model_tuning', direction=\"maximize\", storage=\"sqlite:///pooling_runtime_model_tuning.db\")\n",
    "# Run study for 100 trials\n",
    "runtime_study.optimize(partial(optimizer.objective, \n",
    "                               features_mapping=dataset_builder.features_mapping, \n",
    "                               special_terms_list=[TOTAL_POOLING_INPUT_FEATURES, TOTAL_POOLING_OUTPUT_FEATURES, TOTAL_POOLING_NO_OPS]), \n",
    "               n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the best performing pipeline\n",
    "pprint(runtime_study.best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.visualization import plot_optimization_history\n",
    "\n",
    "plot_optimization_history(runtime_study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
