{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add directory above current directory to path\n",
    "import sys; sys.path.insert(0, '..')\n",
    "\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "import optuna\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "from config.convolutional_features import *\n",
    "from data_preparation.io_utils import read_yaml_file\n",
    "from dataset.dataset_builder import DatasetBuilder\n",
    "from model.model_builder import ModelBuilder\n",
    "from model.model_tuning import OptunaOptimizer\n",
    "from pipeline.trainer import Trainer\n",
    "\n",
    "CONFIG_PATH = Path('../config/config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Configuration\n",
    "config = read_yaml_file(CONFIG_PATH)\n",
    "data_config = config['data']\n",
    "print(data_config)\n",
    "conv_pattern = \"**/convolutional.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_builder = DatasetBuilder(features=CONV_FEATURES)\n",
    "conv_dataset = dataset_builder.create_dataset(\n",
    "            data_dir=Path('../training_data'),\n",
    "            test_models=data_config[\"test_models\"],\n",
    "            pattern=conv_pattern,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of training samples: {len(conv_dataset.train.input_features)}\")\n",
    "print(f\"Number of testing samples: {len(conv_dataset.test.input_features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Baseline Models\n",
    "\n",
    "\n",
    "Baseline models for power and runtime models, we will use the mean of train dataset as prediction.\n",
    "\n",
    "\n",
    "### Baseline Result\n",
    "\n",
    "Test dataset RMSPE Power : 85.87%\n",
    "\n",
    "Test dataset RMSPE Runtime: 110.50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(data_config=data_config, model_config=config['model'], features=CONV_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_power = conv_dataset.train.power.mean()\n",
    "target = conv_dataset.test.power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(trainer.eval_metrics(actual=target, pred=[mean_power]*len(target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_runtime = conv_dataset.train.runtime.mean()\n",
    "target = conv_dataset.test.runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(trainer.eval_metrics(actual=target, pred=[mean_runtime]*len(target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Power\n",
    "\n",
    "[Optuna](https://optuna.org/) library is used to perform hyperparameter tuning for power model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = conv_dataset.train.input_features.values\n",
    "y_power_train = conv_dataset.train.power.values\n",
    "print(f\"Training shape: {X_train.shape}, {y_power_train.shape}\")\n",
    "\n",
    "X_test = conv_dataset.test.input_features.values\n",
    "y_power_test = conv_dataset.test.power.values\n",
    "print(f\"Testing shape: {X_test.shape}, {y_power_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_builder = ModelBuilder()\n",
    "optimizer = OptunaOptimizer(X_train=X_train, y_train=y_power_train, X_test=X_test, y_test=y_power_test, model_builder=model_builder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Ignore ConvergenceWarning from sklearn to avoid tab crash\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "# Maximize the test R^2 score during tuning\n",
    "power_study = optuna.create_study(study_name='conv_power_model_tuning', direction=\"maximize\", storage=\"sqlite:///conv_power_model_tuning.db\")\n",
    "# Run study for 100 trials\n",
    "power_study.optimize(partial(optimizer.objective, \n",
    "                             features_mapping=dataset_builder.features_mapping, \n",
    "                             special_terms_list=[TOTAL_CONV_OPS_PER_INPUT, TOTAL_CONV_OPS_PER_BATCH]), \n",
    "               n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the best performing pipeline\n",
    "pprint(power_study.best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.visualization import plot_optimization_history\n",
    "\n",
    "plot_optimization_history(power_study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Runtime\n",
    "\n",
    "[Optuna](https://optuna.org/) library is used to perform hyperparameter tuning for runtime model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = conv_dataset.train.input_features.values\n",
    "y_runtime_train = conv_dataset.train.runtime.values\n",
    "print(f\"Training shape: {X_train.shape}, {y_runtime_train.shape}\")\n",
    "\n",
    "X_test = conv_dataset.test.input_features.values\n",
    "y_runtime_test = conv_dataset.test.runtime.values\n",
    "print(f\"Testing shape: {X_test.shape}, {y_runtime_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_builder = ModelBuilder()\n",
    "optimizer = OptunaOptimizer(X_train=X_train, y_train=y_runtime_train, X_test=X_test, y_test=y_runtime_test, model_builder=model_builder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Ignore ConvergenceWarning from sklearn to avoid tab crash\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "# Maximize the test R^2 score during tuning\n",
    "runtime_study = optuna.create_study(study_name='conv_runtime_model_tuning', direction=\"maximize\", storage=\"sqlite:///conv_runtime_model_tuning.db\")\n",
    "# Run study for 100 trials\n",
    "runtime_study.optimize(partial(optimizer.objective, \n",
    "                               features_mapping=dataset_builder.features_mapping, \n",
    "                               special_terms_list=[TOTAL_CONV_OPS_PER_INPUT, TOTAL_CONV_OPS_PER_BATCH]), \n",
    "               n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the best performing pipeline\n",
    "pprint(runtime_study.best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from optuna.visualization import plot_optimization_history\n",
    "\n",
    "plot_optimization_history(runtime_study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
