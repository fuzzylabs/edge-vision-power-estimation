{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add directory above current directory to path\n",
    "import sys; sys.path.insert(0, '..')\n",
    "\n",
    "from pathlib import Path\n",
    "from dataset.dataset_builder import DatasetBuilder\n",
    "from IPython.display import display\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "def get_model_layer_statistics(dataset_builder, layer_type, file_paths):\n",
    "    layers, model_names = [], []\n",
    "    col1, col2 = 'Model Name',  f'Number of {layer_type} Layer'\n",
    "    for file in file_paths:\n",
    "        layers.append(len(dataset_builder.read_csv_and_convert_power(file)))\n",
    "        model_names.append(file.parent.stem)\n",
    "    df = pd.DataFrame({col1: model_names, col2: layers})\n",
    "    sorted_df = df.sort_values(by=col2, ascending=False, ignore_index=True)\n",
    "    display(sorted_df)\n",
    "    return sorted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Configuration\n",
    "\n",
    "data_dir_path = Path('../training_data')\n",
    "test_models = [\"lenet\", \"resnet18\", \"vgg16\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [folder.name for folder in data_dir_path.iterdir() if folder.is_dir()]\n",
    "\n",
    "print(f\"Models: {models}\")\n",
    "print(f\"Total models: {len(models)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## Convolutional Layer\n",
    "\n",
    "- There are 21 models with Convolutional layers.\n",
    "- **googlenet** models looks fishy as it has only 1 CNN layer.\n",
    "\n",
    "\n",
    "Insights into Data\n",
    "\n",
    "- There are total 585 datapoints with 15 features (including power and runtime) for Convolutional Layers.\n",
    "- Power:  `mean = 5.24` `max = 7.83` and `min = 1.18`\n",
    "- Runtime: `mean = 0.08` `max = 0.64` and `min = 0.01`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.convolutional_features import CONV_FEATURES\n",
    "conv_files = list(data_dir_path.rglob(\"**/convolutional.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_dataset = DatasetBuilder(features=CONV_FEATURES)\n",
    "conv_df = get_model_layer_statistics(conv_dataset, layer_type='Convolutional', file_paths=conv_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_conv_data = conv_dataset.merge_feature_data(conv_files)\n",
    "\n",
    "print(\"Convolutional Layers data summary\")\n",
    "combined_conv_df = pd.concat([combined_conv_data.input_features, combined_conv_data.power, combined_conv_data.runtime], axis=1)\n",
    "display(combined_conv_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Pooling Layer\n",
    "\n",
    "- Not all models have **Pooling Layers**.\n",
    "- There are only 17 models with Pooling layers compared to 21 models with Convolutional layers.\n",
    "\n",
    "Insights into Data\n",
    "\n",
    "- There are total 61 datapoints with 13 features (including power and runtime) for Pooling Layers.\n",
    "- Power:  `mean = 4.95` `max = 7.82` and `min = 1.18`\n",
    "- Runtime: `mean = 0.03` `max = 0.14` and `min = 0.009`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.pooling_features import POOLING_FEATURES\n",
    "pooling_files = list(data_dir_path.rglob(\"**/pooling.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_dataset = DatasetBuilder(features=POOLING_FEATURES)\n",
    "pool_df = get_model_layer_statistics(pool_dataset, layer_type='Pooling', file_paths=pooling_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_pool_data = pool_dataset.merge_feature_data(pooling_files)\n",
    "\n",
    "print(\"Pooling Layers data summary\")\n",
    "combined_pool_df = pd.concat([combined_pool_data.input_features, combined_pool_data.power, combined_pool_data.runtime], axis=1)\n",
    "display(combined_pool_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Dense Layer\n",
    "\n",
    "- Not all models have **Dense Layers**.\n",
    "- There are only 17 models with Dense layers compared to 21 models with Convolutional layers.\n",
    "- There can be models with 1 dense layers usually the last FC layer.\n",
    "\n",
    "\n",
    "Insights into Data\n",
    "\n",
    "- There are total 398 datapoints with 5 features (including power and runtime) for Dense Layers.\n",
    "- Power:  `mean = 5.55` `max = 7.82` and `min = 1.18`\n",
    "- Runtime: `mean = 0.09` `max = 3.37` and `min = 0.01`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.dense_features import DENSE_FEATURES\n",
    "dense_files = list(data_dir_path.rglob(\"**/dense.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_dataset = DatasetBuilder(features=DENSE_FEATURES)\n",
    "dense_df = get_model_layer_statistics(dense_dataset, layer_type='Dense', file_paths=dense_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_dense_data = dense_dataset.merge_feature_data(dense_files)\n",
    "\n",
    "print(\"Dense Layers data summary\")\n",
    "combined_dense_df = pd.concat([combined_dense_data.input_features, combined_dense_data.power, combined_dense_data.runtime], axis=1)\n",
    "display(combined_dense_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## Overall Summary\n",
    "\n",
    "### Power\n",
    "\n",
    "Both dense and convolutional layers have almost the same characteritics for power values. Pooling layer also have almost the same characteristics with a bit lower mean compared to above 2.\n",
    "\n",
    "Diggging a bit deeper, there is quite a bit variation in percentage quantiles for each layer.\n",
    "\n",
    "### Runtime\n",
    "\n",
    "Although the min and mean of dense and convolution layers is same, the dense layers have a quite larger maximum value for runtime compared to convolutional layers.\n",
    "\n",
    "Pooling layers are the quickest amongst the 3."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
